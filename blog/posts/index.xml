<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on Kelly Shortridge</title>
        <link>https://swagitda.com/blog/posts/</link>
        <description>Recent content in Posts on Kelly Shortridge</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.</copyright>
        <lastBuildDate>Tue, 22 Dec 2020 16:13:58 -0500</lastBuildDate>
        <atom:link href="https://swagitda.com/blog/posts/index.xml" rel="self" type="application/rss+xml" />
        
        <item>
            <title>My 2020 Reading List</title>
            <link>https://swagitda.com/blog/posts/2020-reading-list/</link>
            <pubDate>Tue, 22 Dec 2020 16:13:58 -0500</pubDate>
            
            <guid>https://swagitda.com/blog/posts/2020-reading-list/</guid>
            <description>Every year, I publish my reading list for those seeking inspo. This is my reading list for 2020, featuring a wide variety of fantasy, sci-fi, and non-fiction books.</description>
            <content type="html"><![CDATA[<p>This year, I relished the newfound time beget by the social distancing paradigm to indulge in even more books than usual. To wit, I averaged around 3.7 books per month in 2020 compared to 2.7 books per month in 2019 &ndash; and approximately tripled what I achieved each year from 2016 to 2018.</p>
<p>Notably, I also published my first book: the Security Chaos Engineering e-book (non-fiction) published via O&rsquo;Reilly Media. It&rsquo;s <a href="https://www.verica.io/sce-book/">available for free download</a> if you want to check it out and add some brain-stimulating non-fiction to your reading queue.</p>
<p>If you’re looking for more science fiction, speculative fiction, or non-fiction recommendations, check out <a href="/blog/posts/2019-reading-list">my 2019</a>, <a href="/blog/posts/2018-reading-list">my 2018</a>, <a href="/blog/posts/2017-reading-list">my 2017</a>, and <a href="/blog/posts/2016-reading-list">my 2016</a> reading lists.</p>
<h2 id="fiction">Fiction</h2>
<p><a href="https://www.amazon.com/Akata-Warrior-Nnedi-Okorafor/dp/067078561X">Akata Warrior</a> by Nnedi Okorafor</p>
<p><a href="https://www.amazon.com/Akata-Witch-Nnedi-Okorafor/dp/0670011967">Akata Witch</a> by Nnedi Okorafor</p>
<p><a href="https://www.amazon.com/Shall-Machines-Surrender-Benjanun-Sriduangkaew-ebook/dp/B07SJWJ7VB">And Shall Machines Surrender (Machine Mandate Book 1)</a> by Benjanun Sriduangkaew</p>
<p><a href="https://www.amazon.com/gp/product/B075DGHHQL">Artificial Condition: The Murderbot Diaries</a> by Martha Wells</p>
<p><a href="https://www.tor.com/2020/05/20/beyond-the-dragons-gate-yoon-ha-lee/">Beyond the Dragon&rsquo;s Gate</a> by Yoon Ha Lee</p>
<p><a href="https://www.amazon.com/Black-Sun-Between-Earth-Sky/dp/1534437673">Black Sun (Between Earth and Sky)</a> by Rebecca Roanhorse</p>
<p><a href="https://www.tor.com/2019/07/24/blood-is-another-word-for-hunger-rivers-solomon/">Blood Is Another Word for Hunger</a> by Rivers Solomon</p>
<p><a href="https://www.amazon.com/Children-Virtue-Vengeance-Legacy-Orisha/dp/1250170990">Children of Virtue and Vengeance (Legacy of Orisha, 2)</a> by Tomi Adeyemi</p>
<p><a href="https://www.amazon.com/Crying-Lot-Perennial-Fiction-Library/dp/006091307X/">The Crying of Lot 49</a> by Thomas Pynchon</p>
<p><a href="https://www.amazon.com/Dark-Forest-Remembrance-Earths-Past/dp/0765386690">The Dark Forest (The Three-Body Problem Series, 2)</a> by Cixin Liu</p>
<p><a href="https://www.amazon.com/Despair-Vladimir-Nabokov/dp/0679723439/">Despair</a> by Vladimir Nabokov</p>
<p><a href="https://www.amazon.com/Dream-Quest-Vellitt-Boe-Kij-Johnson-ebook/dp/B01DJ0NARW">The Dream-Quest of Vellitt Boe</a> by Kij Johnson</p>
<p><a href="https://www.amazon.com/gp/product/B078X1N8VF">Exit Strategy: The Murderbot Diaries</a> by Martha Wells</p>
<p><a href="https://www.amazon.com/Flights-Olga-Tokarczuk/dp/0525534202/">Flights</a> by Olga Tokarczuk</p>
<p><a href="https://www.amazon.com/Gurkha-Lord-Tuesday-Saad-Hossain/dp/1250209110">The Gurkha and the Lord of Tuesday</a> by Saad Z. Hossain</p>
<p><a href="https://www.amazon.com/Harrow-Ninth-Locked-Tomb-Trilogy/dp/1250313228">Harrow the Ninth (The Locked Tomb Trilogy, 2)</a> by Tamsyn Muir</p>
<p><a href="https://www.amazon.com/Hour-Star-New-Directions-Paperbook/dp/0811211908">The Hour of the Star</a> by Clarice Lispector</p>
<p><a href="https://www.amazon.com/Lathe-Heaven-Ursula-K-Guin/dp/1416556966">The Lathe Of Heaven: A Novel</a> by Ursula K. Le Guin</p>
<p><a href="https://www.amazon.com/Love-Beyond-Body-Space-Time-ebook/dp/B01L0HRHMU">Love Beyond Body, Space, and Time: An LGBT and two-spirit sci-fi anthology</a> featuring Cherie Dimaline, Gwen Benaway, David Robertson, Richard Van Camp, Nathan Adler, Daniel Heath Justice, Darcie Little Badger, and Cleo Keahna</p>
<p><a href="https://www.gutenberg.org/files/5200/5200-h/5200-h.htm">The Metamorphosis</a> by Franz Kafka (re-read)</p>
<p><a href="https://www.amazon.com/Network-Effect-Murderbot-Novel-Diaries-ebook/dp/B07WZ7SB5D/">Network Effect: A Murderbot Novel (The Murderbot Diaries Book 5)</a> by Martha Wells</p>
<p><a href="https://www.serialbox.com/serials/ninth-step-station">Ninth Step Station</a> by Malka Older, Fran Wilde, Jacqueline Koyanagi, and Curtis C. Chen</p>
<p><a href="https://www.amazon.com/Null-States-Book-Centenal-Cycle/dp/0765393387">Null States (The Centenal Cycle, 2)</a> by Malka Older</p>
<p><a href="https://www.amazon.com/Plague-Albert-Camus/dp/0679720219">The Plague</a> by Albert Camus</p>
<p><a href="https://www.amazon.com/Pnin-Vladimir-Nabokov/dp/0679723412">Pnin</a> by Vladimir Nabokov</p>
<p><a href="https://www.amazon.com/Queen-Conquered-Islands-Blood-Storm/dp/0316454931">Queen of the Conquered (Islands of Blood and Storm, 1)</a> by Kacen Callender</p>
<p><a href="https://www.amazon.com/Realm-Ash-Books-Ambha-Book-ebook/dp/B07P8LM4Y4/">Realm of Ash (The Books of Ambha Book 2)</a> by Tasha Suri</p>
<p><a href="https://www.amazon.com/Ring-Shout-P-Dj%C3%A8l%C3%AD-Clark/dp/1250767024">Ring Shout</a> by P. Djèlí Clark</p>
<p><a href="https://www.amazon.com/gp/product/B0756JSWGL">Rogue Protocol: The Murderbot Diaries</a> by Martha Wells</p>
<p><a href="https://www.amazon.com/State-Tectonics-Centenal-Cycle-Malka/dp/0765399474">State Tectonics (The Centenal Cycle)</a> by Malka Older</p>
<p><a href="https://www.tor.com/2009/07/14/the-cat-who-walked-a-thousand-miles/">The Cat Who Walked a Thousand Miles</a> by Kij Johnson</p>
<p><a href="https://www.amazon.com/This-How-You-Lose-Time/dp/1534431004">This Is How You Lose the Time War</a> by Amal El-Mohtar and Max Gladstone</p>
<p><a href="https://www.tor.com/2019/12/04/the-time-invariance-of-snow-e-lily-yu/">The Time Invariance of Snow</a> by E. Lily Yu</p>
<p><a href="https://www.amazon.com/Say-Nothing-Dog-Connie-Willis/dp/0553575384">To Say Nothing of the Dog</a> by Connie Willis</p>
<p><a href="https://www.amazon.com/Thus-Were-Their-Faces-Selected/dp/1590177673">Thus Were Their Faces: Selected Stories</a> by Silvina Ocampo</p>
<hr>
<h2 id="non-fiction">Non-Fiction</h2>
<p><a href="https://static.googleusercontent.com/media/sre.google/en//static/pdf/building_secure_and_reliable_systems.pdf">Building Secure &amp; Reliable Systems: Best Practices for Designing, Implementing and Maintaining Systems</a> by Heather Adkins, Betsy Beyer, Paul Blankinship, Piotr Lewandowski, Ana Oprea, and Adam Stubblefield (I&rsquo;m honored to have been a reviewer for it!)</p>
<p><a href="https://www.amazon.com/Cosmic-Revolutionarys-Handbook-Beat-Bang/dp/1108486703/">The Cosmic Revolutionary&rsquo;s Handbook (Or: How to Beat the Big Bang)</a> by Luke A. Barnes and Geraint F. Lewis</p>
<p><a href="https://www.amazon.com/End-Everything-Astrophysically-Speaking/dp/198210354X">The End of Everything (Astrophysically Speaking)</a> by Katie Mack</p>
<p><a href="https://www.amazon.com/How-Be-Antiracist-Ibram-Kendi/dp/0525509283/">How to Be an Antiracist</a> by Ibram X. Kendi</p>
<p><a href="https://www.amazon.com/Human-Condition-2nd-Hannah-Arendt/dp/0226025985">The Human Condition</a> by Hannah Arendt</p>
<p><a href="https://www.amazon.com/Invisible-Agents-Espionage-Seventeenth-Century-Britain/dp/0198823010">Invisible Agents: Women and Espionage in Seventeenth-Century Britain</a> by Nadine Akkerman</p>
<p><a href="https://www.amazon.com/Lost-Math-Beauty-Physics-Astray/dp/0465094252">Lost in Math</a> by Sabine Hossenfelder</p>
<p><a href="https://mitpress.mit.edu/books/mechanizing-proof">Mechanizing Proof</a> by Donald MacKenzie</p>
<p><a href="https://www.amazon.com/Monolith-Microservices-Evolutionary-Patterns-Transform/dp/1492047848">Monolith to Microservices: Evolutionary Patterns to Transform Your Monolith</a> by Sam Newman</p>
<p><a href="https://www.amazon.com/Venices-Secret-Service-Intelligence-Renaissance/dp/0198791313/">Venice&rsquo;s Secret Service: Organising Intelligence in the Renaissance</a> by Ioanna Iordanou</p>
]]></content>
        </item>
        
        <item>
            <title>IBM &#43; Red Hat: Bamboozles, Foozles, and the Hybrid Cloud Chimera</title>
            <link>https://swagitda.com/blog/posts/ibm-red-hat-bamboozles-foozles-and-the-hybrid-cloud-chimera/</link>
            <pubDate>Mon, 14 Dec 2020 08:00:00 -0500</pubDate>
            
            <guid>https://swagitda.com/blog/posts/ibm-red-hat-bamboozles-foozles-and-the-hybrid-cloud-chimera/</guid>
            <description>This post explores how IBM is bamboozling the world (and possibly themselves) with their Red Hat-driven hybrid cloud &amp;lsquo;strategy&amp;rsquo; and heralded spinoff, featuring examination of the technological, financial, and market foozles of the past and of the forseeable future.</description>
            <content type="html"><![CDATA[<figure>
    <img src="/blog/img/ibm-hybrid-cloud/alexander-mokhov-chimera.jpg"
         alt="Mythgard. Sideshow Chimera by Alexander Mokhov"/> <figcaption>
            <p><a href="https://www.artstation.com/artwork/6aVRB5">Mythgard. Sideshow Chimera by Alexander Mokhov</a></p>
        </figcaption>
</figure>
<p><a href="https://newsroom.ibm.com/2020-10-08-IBM-To-Accelerate-Hybrid-Cloud-Growth-Strategy-And-Execute-Spin-Off-Of-Market-Leading-Managed-Infrastructure-Services-Unit">IBM recently announced</a> that it is spinning off its “IT infrastructure services” unit so that it can streamline its focus solely towards IBM’s “open hybrid cloud platform” by the end of 2021. Leveraging this aggressive assertion, I’ll be referring to this rebranded IBM as “IBM Hybrid Cloud” (vs. current IBM as just “IBM”) throughout this post for clarity.</p>
<p>I think most people – whether tech workers or investors – would agree that cloud stuff in general is far more riveting than IT services both intellectually and from a growth prospects perspective. With that said, public investors seem relatively unimpressed; while there was <a href="https://www.cnbc.com/2020/10/08/ibm-shares-surge-on-plans-to-spin-off-unit-into-separate-publicly-traded-company-.html">an initial stock price bump upon the announcement</a>, the price is back to where it was pre-announcement<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. In this post, I want to explore the answer to the question that seems to be floating around the market mindshare: what is IBM Hybrid Cloud’s future, really?</p>
<p>The best place to start this peregrination is probably to evaluate the existing IBM Cloud offering in the context of the public cloud providers. IBM, as you all are assuredly aware, is not one of the “Big Three,” the moniker given to Amazon Web Services (AWS), Google Cloud Platform (GCP), and Microsoft Azure due to their outsized share of the market. Perhaps most inauspiciously, Gartner places IBM Public Cloud on their Magic Quadrant (MQ) for Cloud IaaS in the pitiable &ldquo;niche&rdquo; quadrant. To add insult to injury, IBM rests behind Oracle Cloud both in “Ability to Execute” and in “Completeness of Vision” – and IBM’s position as a languishing laggard on the MQ <a href="https://twitter.com/QuinnyPig/status/1303409576587309056">hasn&rsquo;t budged for three years</a>.</p>
<p>Thus, we arrive at our next line of inquiry: What went wrong? How did IBM totally whiff execution on cloud offerings? Could they not discern the blindingly obvious writing in the stars<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>?</p>
<hr>
<h2 id="the-bare-metal-blunder">The Bare Metal Blunder</h2>
<p>At least one ingredient in IBM&rsquo;s stew of ineptitude was (and still is) their predilection for all things Watson, which clouded<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> their judgment around the IaaS market.</p>
<p>IBM simultaneously rebuffed public cloud by insisting on pursuing the bare metal opportunity – the market for single tenant (unshared) physical servers – while also neglecting it, attempting to eke out greater profitability by decreasing engineering spend at a time when competitors were firing their proverbial money cannons at the IaaS market. IBM pursued the bare metal opportunity vis a vis their acquisition of SoftLayer in 2013 for $2 billion, which perhaps added a salty sprinkle of <a href="https://en.wikipedia.org/wiki/Sunk_cost">sunk cost fallacy</a> to their clumsy calculus.</p>
<p>Unfortunately, IBM betting on SoftLayer was like buying a racehorse which you simultaneously neglect and “transform” via bureaucracy so irresponsibly that by the day of the race, its hoofs have downgraded into flippers and the horse is “racing” so slowly that the spectators are confused whether to laugh or cry.</p>
<p>Let’s set some quantitative context around this debacle. SoftLayer reportedly generated $335 million in revenue in 2012<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup> (pre-acquisition) and its revenue is now bundled into IBM Cloud’s “Infrastructure-as-a-Service” offering within the (relatively) newly defined “Cloud and Cognitive Software” segment<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>. Given the segment’s overall revenue was $4.2 billion in 2019<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> and Red Hat’s most recent fiscal year revenue pre-acquisition (more on that deal in a bit) was $3.4 billion<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>, the maximum revenue SoftLayer could have contributed in 2019 was around $1 billion.</p>
<p><img src="/blog/img/ibm-hybrid-cloud/chart1.png" alt="A pie chart showing IBM&rsquo;s Cloud and Cognitive revenue in 2019. 81% for Red Hat and 19% for SoftLayer? Watson? Underpants Gnomes?"></p>
<p>That is an impressively mediocre growth story. To wit, in 2013 (the same year as the SoftLayer acquisition), annual AWS revenues reached $3.8 billion<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup> and grew to $35 billion in 2019<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> — reflecting a healthy compound annual growth rate (CAGR) of 44.8%. IBM’s bare metal bet via SoftLayer reflects, at best, a 13.2% CAGR<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> — only 0.2% higher than the CAGR for the Trucking industry<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>. That is, as the kids say, a big oof.</p>
<hr>
<h2 id="red-hat-redemption">Red Hat Redemption?</h2>
<p>While IBM was off hobbling its racehorse, their repudiation of the cloud opportunity led to a power vacuum in the “trustworthy provider with reliable long-term support” domain, which Microsoft was voracious and primed to fill. This is partially why, despite chatter of Azure presenting inferior value across a variety of facets relative to AWS or GCP, sales are still quite stellar<sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>.</p>
<p>Presumably sensing their nebulous<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup> prospects in the cloud market, IBM completed the acquisition of Red Hat for a staggering <a href="https://www.redhat.com/en/about/press-releases/ibm-closes-landmark-acquisition-red-hat-34-billion-defines-open-hybrid-cloud-future">$34 billion</a> in summer 2019. This purchase price reflected a stock price premium of approximately 60%, which is double the typical premium<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup> and perhaps a rare moment of lucidity at IBM in recognizing that no one wants to be acquired by them.</p>
<p>The surface rationale of the deal is that IBM can cross-sell Red Hat&rsquo;s offerings to its customers, which is&hellip; quite a bit harder without the managed infrastructure services business, especially given this was the rationale highlighted in <a href="https://www.ibm.com/investor/att/pdf/ibm-2019-investor-briefing-presentation.pdf">the investor presentation on the deal</a>. But we will pull on that paradox’s thread soon enough.</p>
<p>What did IBM receive from Red Hat to cross-sell? Thankfully, Red Hat was publicly traded prior to the IBM acquisition, so we can delve into its financial profile by leveraging relatively recent data.</p>
<p>Red Hat is a predominately subscription business – it was 88% of fiscal year (FY) 2019 revenue<sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>, growing by 14.6% year-over-year (y-o-y) – with the rest of revenue coming from “Training and Services.” The latter category is pretty self-explanatory and is growing at a decent rate (19.3% y-o-y), evidently due to customers needing some handholding around adopting OpenShift and Ansible.</p>
<p>Red Hat’s subscription revenue is primarily generated by “Infrastructure-related” subscriptions, which made up 72.3% of all subscription revenue as of FY 2019. The critical driver of the “Infrastructure-related” category is almost assuredly subscriptions for Red Hat Enterprise Linux (RHEL), a Linux operating system (OS) favored by enterprises over the numerous open source Linux OSes due to the support provided with the subscription. With that said, “Infrastructure-related offerings” also includes Red Hat Satellite and Red Hat Virtualization and they don’t provide a further revenue breakdown.</p>
<p>The remaining 27.7% of subscription revenue is from “Application Development-related and other emerging technology subscription,” which is a ridiculous mouthful and belies the importance of the offerings for Red Hat’s growth strategy. “Application Development-related” explicitly refers to Red Hat Middleware, whose most notable offering is JBoss, an open source Java application server. Red Hat’s definition of “Emerging Technology” explicitly defines it as tools to “build and manage hybrid IT computing environments,”<sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup> and includes Red Hat OpenShift, Red Hat Cloud Infrastructure, Red Hat OpenStack Platform, Red Hat Ansible Automation, Red Hat CloudForms and Red Hat Storage technologies.</p>
<p><img src="/blog/img/ibm-hybrid-cloud/chart2.png" alt="A pie chart showing Red Hat&rsquo;s Fiscal Year 2019 revenue breakdown. 64% for infrastructure-releated subscriptions, 24% for app development and &ldquo;emerging technology&rdquo; subscriptions, and 12% for training and services."></p>
<p>Of those emerging technologies, OpenShift, Ansible, and OpenStack are, by my estimation, the highest sources of revenue growth. For instance, infrastructure-related subscription revenue grew 9.3% y-o-y from FY 2018 to FY 2019 – which certainly doesn’t count as “high growth” – while app dev-related &amp; other emerging tech subscription grew 30.9% y-o-y (double Red Hat&rsquo;s total revenue growth of 15.1% y-o-y). And it really is the emerging tech part of that second category fomenting that higher growth.</p>
<p>The “emerging technology” offerings are actually cannibalizing the “application development-related” offerings<sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>. As more of the market leverages containerized environments for app development, they want a platform like OpenShift with orchestration capabilities, leading customers to replace JBoss spend with OpenShift spend<sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup>.</p>
<p>We now need to dig a little deeper into OpenShift to set the stage for spelunking through IBM’s hybrid cloud-dominated spinoff strategy. OpenShift is a container orchestration platform like Kubernetes, but provides professional support services around things like updates, patches, and integrations. Both OpenShift and Kubernetes manage clusters – groups of containers – to automatically handle the operations required to keep services running smoothly, like restarting failed containers, distributing network traffic across containers, mounting storage systems, optimizing resource usage, rolling out new container images, and so forth.</p>
<p>How does this fit in with “hybrid cloud”? Containers package all the stuff (like libraries, dependencies, configuration files, etc.) needed for an application to run. By putting all this stuff in one package, the application is no longer dependent on specific infrastructure and can be run in different computing environments. So, a containerized application can run just as well on-prem or in a private or public cloud and on top of any Linux distribution – which means that containers are sufficiently flexible to work with whatever mix of systems an organization operates that constitute their “hybrid cloud.”</p>
<p>This means OpenShift is perfect for “hybrid cloud,” right? Not quite. While Kubernetes works with any Linux distro and basically any cloud platform, OpenShift only works with CentOS<sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup>, Fedora, or <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux_atomic_host/7/html/installation_and_configuration_guide/introduction_to_atomic_host">Red Hat Enterprise Linux Atomic Host (RHELAH)</a>. Those distros are supported by AWS, Azure, and GCP, but it still obviously constrains one’s options and is discordant with the flexibility-first ethos of “hybrid cloud.” Similarly dissonant is the fact that OpenShift’s templates, a collection of files that define the resources needed to run an app, like a package manager, are largely unable to handle more complex deployments – and complex deployments are pretty common in a “hybrid cloud” environment.</p>
<p>There are notable benefits of OpenShift relative to Kubernetes – like better security defaults and container image management – but the dream orchestration solution for “hybrid cloud” it is not.</p>
<hr>
<h2 id="ibms-hybrid-cloud-chimera">IBM&rsquo;s Hybrid Cloud Chimera</h2>
<p>Now we arrive back to IBM’s grand ambitions around an unfettered IBM Hybrid Cloud business. In the <a href="https://www.ibm.com/investor/att/pdf/IBM-Strategic-Update-2020-charts.pdf">“Strategic Update” presentation</a> announcing the spinoff, IBM touts that they are “positioned for success in the hybrid cloud and AI market.”<sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup> Given the rest of the presentation is almost exclusively focused on the hybrid cloud opportunity – for which they assign a $1 <em>trillion</em> total addressable market (TAM) – I suspect the “AI” portion of that proclamation is to save face regarding all the Watson investments.</p>
<p>Before we dissect their hybrid cloud reveries, let’s solidify our notion of “hybrid cloud” beyond buzzphrasedom. “Hybrid cloud” is an environment that uses a mix of infrastructure, like on-prem servers, private or public clouds, containers, serverless functions, etc. In the spirit of vagueness that plagues all buzzphrases, “hybrid cloud” greedily represents the spectrum between “purely on-prem and bare metal” to “purely public cloud and containers.”</p>
<p>IBM pretty clearly includes “multi-cloud” as part of the “hybrid cloud” opportunity given their mention of &ldquo;regardless of vendor&rdquo; in <a href="https://newsroom.ibm.com/2020-10-08-IBM-To-Accelerate-Hybrid-Cloud-Growth-Strategy-And-Execute-Spin-Off-Of-Market-Leading-Managed-Infrastructure-Services-Unit">the press release</a>. “Multi-cloud” refers to organizations using multiple cloud providers to support their software delivery – like using AWS S3 and EC2 with Google Compute Engine VMs with Azure Storage. As a beloved engineering VP friend quipped, &ldquo;Only a masochist voluntarily goes multi-cloud.&quot;<sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup></p>
<p>So, what should we make of this $1 trillion TAM?<sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup> As is tradition in glossy corporate investor decks, no sources are cited for that figure in IBM’s presentation. Nevertheless, their TAM calculation includes $450 billion for “Cloud Software &amp; Platforms” (addressed by Red Hat and Cloud Paks<sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>), $300 billion for “Cloud Transformational Services” (addressed by “OpenShift Everywhere”), and $230 billion for “Cloud Infrastructure” (addressed by OpenShift on Z and Regulated Industry Clouds). Without any citations for those numbers, it’s impossible to tell whether this is truly the “<em>hybrid</em> cloud” opportunity or IBM performing Fantasy Math™<sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup> with overall cloud market figures to kindle excitement among investors.</p>
<p>Interestingly and farcically enough, IBM’s hybrid cloud TAM has decreased by $200 billion<sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup> from 2019 until now! The breakdown back in 2019 was $550 billion for “Services for Cloud,” $350 billion for “Cloud Software,” $150 billion for “Infrastructure,” and $100 billion for “Component tech sold to Cloud Service Providers.” If we compare to the more recent breakdown, the TAM for “Cloud Software” increased by $100 billion and added <em>platforms</em> to the mix, “Cloud Services” added <em>transformational</em> to its name and shrunk by $250 billion, “Infrastructure” grew by $80 billion, and “Component tech” disappeared or perhaps represents the $100 billion added into “Cloud Software.” As I said: this is Fantasy Math™, where facts are discouraged and hand-waving an artform.</p>
<p>To beleaguer the point, the TAM a still-independent Red Hat identified in 2018 for itself was $69 billion<sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup>, which is a teensy-weensy 6.9%<sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup> of the TAM that IBM boasts for what is largely just Red Hat-rebranded-as-IBM-Cloud. Red Hat’s breakdown of that TAM<sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup> included $18.0 billion for Middleware, $16.0 billion for Storage, $17.6 billion for Operating System, $5.8 billion for “Cloud Management (including OpenStack)”, $4.7 billion for PaaS, $4.8 billion for Virtualization, and $1.9 billion for Infrastructure Management.</p>
<p>Is the right lesson to learn here that the difference between a $30 billion company and a $110 billion company is held in your ability to abstract away market categories and inflate TAMs to the point of meaninglessness? Can you 3x your market cap by replacing “various analyst estimates” as the source of your TAM figures with no citations whatsoever? I’m sure we’ll see a pay-for-publication Forbes article about this inspiring finding soon.</p>
<p>IBM claims that a hybrid cloud approach provides 2.5x the client value of an approach with “public-only cloud structures” – without citing any source data again, naturally<sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup>. Red Hat OpenShift is called out specifically as the “hybrid cloud platform” that will deliver this “generational leap in client value.” This suggests that OpenShift is the essential element to secure success from the spinoff; unfortunately for IBM, I suspect that this element will be more like Unobtanium for them when executing on the opportunity. Even with Kubernetes’ deficiencies and the legitimate market need for a more enterprise-flavored orchestration solution, there is simply no way OpenShift can fulfill the astronomical aspirations a $1 trillion TAM imparts.</p>
<p>Even if we assume that OpenShift – or even Red Hat’s “emerging technology” offerings more broadly – is indeed sufficiently promising to seize the platform part of the hybrid cloud market opportunity, successful realization of those prospects rests upon the assumption of IBM not being IBM. And, well, perhaps the only thing that IBM consistently does well is being reliably IBM about things. Would it really be a surprise if the same fate befalls Red Hat that befell SoftLayer?</p>
<p>Undoing IBM’s calcified culture of cash grab contracts while minimizing engineering effort seems preposterously unlikely, despite it being an inherent necessity if they’re aiming to grab a sufficiently succulent bite of the $1 trillion total addressable market (TAM) pie<sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup> <a href="https://www.ibm.com/investor/att/pdf/IBM-Strategic-Update-2020-charts.pdf">they&rsquo;ve plated</a> for public market investors.</p>
<p>The assumption of efficient execution is also incongruent with IBM’s modus operandi of Standard Oil-style vertical integration – so do we expect them to deviate from their standard, stifling strategy? Because the success of this breakup – let alone the Red Hat acquisition – hinges upon that. If IBM Hybrid Cloud cannot play nicely in other clouds and with other tools – for instance, with organizations using Kubernetes instead of OpenShift – it seems reasonable to suggest that they will fall on their ass. And this, of course, is exacerbated by OpenShift&rsquo;s critical importance to IBM in the hybrid cloud Thunderdome, because it helps them capitalize on companies wanting to fluctuate between the big three providers.</p>
<hr>
<h2 id="what-could-have-been">What Could Have Been</h2>
<p>If I had a time machine and eventually reached a mind-melting level of boredom (seems unlikely, but pretend with me), I could go back even a mere five years ago and give advice to those in charge of IBM&rsquo;s cloud strategy, which would simply be: just be yourself! Lean into the fact that people buy you because you’re the safe choice rather than pretending like you’re going to be the face of the hybrid cloud or AI revolution.</p>
<p>There are plenty of organizations who want handholding, helmets, and full body armor just to tricycle their way into Baby’s First Container, and IBM can and should help them out rather than courting the sour, sulky engineer market who, like the stereotypical angsty teen, would rather, like, literally die than be seen in such dorky protective gear.</p>
<p>Aside from the “Bubble Boy, but cloud native” opportunity, serving the needs of regulated industries was and still is an appropriate opportunity. IBM did mention in the strategic announcement that it would pursue the “regulated industry clouds” opportunity and that feels like the (only) appropriate fit out of the $1 trillion TAM they outline. Organizations in regulated industries may have no choice but to shun public clouds, needing instead to store and process data on-prem, and IBM (primarily vis a vis OpenShift) could help them still “modernize” applications within those confines.</p>
<hr>
<h2 id="its-just-a-flesh-wound">&ldquo;It&rsquo;s just a flesh wound!&rdquo;</h2>
<p>With all that said, I think we need to take a step back and look at the splitting up of the two businesses in the first place… because is it really the right move? Are there any IBM Cloud customers who are there without IBM’s I.T. services involved? My hunch is that the managed services arm is IBM’s biggest lead gen for their cloud offerings – because product quality certainly isn’t generating the fledgling interest that exists – so what will they do when that arm is severed?</p>
<p>Despite IBM’s cloying marketing hype around the birth of IBM 2: Hybrid Cloud Boogaloo<sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup>, IBM <em>isn’t</em> fully amputating its services arm – nor even fully divesting the Global Technology Services (GTS) segment that will be deemed “New Co”. Despite the spinoff announcement theatrics boasting the sloughing of low-growth “managed infrastructure services,” the cloudified new IBM will still include:</p>
<ul>
<li>Technology Support Services (TSS): a wing of GTS (yes, the one being spun off…) that offers support and maintenance services for IBM’s hardware and software offerings – think if you need installation or troubleshooting help</li>
<li>Global Business Services: consultants help customers figure out how to build things, which gets implemented by GBS’s Systems Integration and Application Management Services arms</li>
<li>Global Financing: the home of IBM Credit<sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup>, which helps customers figure out how to pay for the stuff they want (or that is being pushed on them by the consultants), including refurbished hardware<sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup></li>
<li>Systems: not a services segment, but it’s the home of IBM’s mainframes, semiconductors, power systems, and other hardware – which is also decidedly not cloud-flavored<sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup></li>
</ul>
<p>If we put all the pieces of the “revitalized” IBM together, we can see the following year-over-year growth profile (from 2018 to 2019)<sup id="fnref:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup> and proportion of IBM Hybrid Cloud revenue made up of cloud software vs. services vs. hardware:</p>
<p><img src="/blog/img/ibm-hybrid-cloud/chart3.png" alt="A bar chart showing the rebranded IBM&rsquo;s FY 2018 to 2019 revenue growth, in billions. Cloud & Cognitive Software grew 4.5% year over year. Global Business Services grew 0.2% year over year. Systems grew negative 5.4% year over year. TSS grew negative 4.8% year over year. Global Financing grew negative 11.9% year over year."></p>
<p><img src="/blog/img/ibm-hybrid-cloud/chart4.png" alt="A pie chart showing the rebranded IBM&rsquo;s FY 2019 revenue breakdown. 46% for Snoozville Services, 42% for Cloud and Cognitive, 12% for Old-skool Hardware."></p>
<p>This is hardly what one would picture when envisioning a plan to “accelerate hybrid cloud growth strategy” and reveals the fragility of IBM’s spinoff justification – because it’s difficult to claim that this is a refocused IBM dedicated to growthy hybrid cloud software offerings. As if that isn’t lame enough, this anemic portfolio is disgraceful in context of the revenue growth profiles of real cloud companies during the same period of time (FY 2018 to FY 2019), like 84% at Alibaba Cloud<sup id="fnref:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup>, 72% at Azure<sup id="fnref:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup>, 53% at Google Cloud<sup id="fnref:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup>, and 37% at AWS<sup id="fnref:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup>.</p>
<p>It’s already plenty confusing from a strategic perspective that IBM is keeping a non-trivial amount of services for IBM Hybrid Cloud. But confounding matters further, the portion of the GTS business that IBM <em>is</em> severing seems like it was pretty critical in selling infrastructure solutions to customers, which, as foreshadowed earlier, was what IBM touted for ~*synergies*~ when buying RedHat.</p>
<p>With that services-as-sales-engine strategy kaput, IBM’s self-described alternative for creating more opportunities for Red Hat is by&hellip; &lt;checks notes&gt;<sup id="fnref:40"><a href="#fn:40" class="footnote-ref" role="doc-noteref">40</a></sup> &hellip; “strategic solutioning,” which is an awe-inspiring level of linguistic inanity<sup id="fnref:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup>. To avoid the shame of dignifying such a vacuous and frivolous statement, I will simply say that “strategic solutioning” sounds like it begets neither strategy nor solutions.</p>
<p>Ultimately, it feels like IBM is both attempting to focus on Red Hat’s stuff – which is legitimately the most promising opportunity in IBM’s gargantuan portfolio – while still very much attempting to suckle at the frothy teat of customers via services the same way it always has. In the perspicacious words of Ron Swanson, “Never half-ass two things, whole-ass one thing.”<sup id="fnref:42"><a href="#fn:42" class="footnote-ref" role="doc-noteref">42</a></sup></p>
<hr>
<h2 id="in-conclusion">In Conclusion</h2>
<p>Sometimes it’s difficult to tell if an organization is purposefully bamboozling external parties or just temerariously bamboozling themselves. In the case of this rebranded IBM, perhaps they actually believe that IBM Hybrid Cloud has a future once it can shed the leaden snakeskin of (some of) the legacy IBM business – like someone freed of a parasitic partner, IBM Hybrid Cloud can finally pursue their dreams and live, laugh, love, loathe, launder (money), liquidate (assets, not people) and whatever else substitutes for introspection in those wearisome Journey to Find Oneself stories<sup id="fnref:43"><a href="#fn:43" class="footnote-ref" role="doc-noteref">43</a></sup>.</p>
<p>If IBM leadership doesn’t actually believe that this rebranded IBM has a real future, and it is indeed a bamboozle targeted at shareholders and whatever customers remain, then it’s a huge waste of everyone’s time and also a colossal amount of money, and I wish it was socially acceptable for them to be like,</p>
<blockquote>
<p>“Yep, we totally foozled execution on this cloud thing and what we have sucks. This IBM Hybrid Cloud thing is just going to be RedHat and we’re going to let them run the show now because that’s really better for everyone involved. And you’ll probably make more money off it anyway than the continuously-burning money-filled <a href="https://en.wikipedia.org/wiki/Darvaza_gas_crater">gas crater</a> of a business we would’ve created.”</p>
</blockquote>
<p>However, I kind of feel like IBM’s best use case for the tech industry at this point is to keep milking its despondent legacy business for cash and use it towards corporate VC into startups that can execute more efficiently and effectively with the capital than a provably languid behemoth like IBM. But my even spicier take is that abandoning the IBM Hybrid Cloud endeavor entirely might engender the most net-positive utility on a societal scale.</p>
<p>There’s a macro point here that it’s kind of a shame there isn’t a feasible mechanism for companies to just give up because they realize continuing operations is pointless. Much like many of my ill-fated DIY projects, sometimes it’s far healthier to realize you are wholly unequipped and seriously outclassed by others’ skills<sup id="fnref:44"><a href="#fn:44" class="footnote-ref" role="doc-noteref">44</a></sup> so you can proceed to things that you can successfully execute rather than immolating more irreplaceable seconds of your life.</p>
<p>I’m not necessarily saying trying to make IBM Hybrid Cloud a real thing is like trying to redo your own bathroom plumbing&hellip; but in both cases, shit is likely to go wrong.</p>
<hr>
<p>Thank you shoutouts to Halvar Flake and Ryan Petrich.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>The closing price of IBM’s stock on October 7 (the day before the announcement) was $124.07. The closing price on December 11 was $124.27, which is only 0.16% higher. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Pun very much intended. <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>This pun is also very much intended. <a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>Frier, S. (2013, June 4). IBM to Buy Cloud-Computing Firm SoftLayer for $2 Billion. <em>Bloomberg</em>. <a href="https://www.bloomberg.com/news/articles/2013-06-04/ibm-to-acquire-cloud-computing-provider-softlayer-technologies">https://www.bloomberg.com/news/articles/2013-06-04/ibm-to-acquire-cloud-computing-provider-softlayer-technologies</a> <a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p>IBM. <em>IBM Updates Reporting Segments in 2019</em>. <a href="https://www.ibm.com/investor/att/pdf/IBM_Updates_Reporting_Segments_March_2019.pdf">https://www.ibm.com/investor/att/pdf/IBM_Updates_Reporting_Segments_March_2019.pdf</a> <a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6" role="doc-endnote">
<p>Vellante, D. (2020, May 2). Big Blue in the cloud? IBM’s future rests on its innovation agenda. <em>SiliconANGLE</em>. <a href="https://siliconangle.com/2020/05/02/big-blue-cloud-ibms-future-rests-innovation-agenda/">https://siliconangle.com/2020/05/02/big-blue-cloud-ibms-future-rests-innovation-agenda/</a> <a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7" role="doc-endnote">
<p>Red Hat, Inc. (2019, March 25). <em>Red Hat Reports Fourth Quarter and Fiscal Year 2019 Results</em> [Press Release]. <a href="https://www.redhat.com/en/about/press-releases/red-hat-reports-fourth-quarter-and-fiscal-year-2019-results">https://www.redhat.com/en/about/press-releases/red-hat-reports-fourth-quarter-and-fiscal-year-2019-results</a> <a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8" role="doc-endnote">
<p>Dignan, L. (2013, January 7). Amazon&rsquo;s AWS: $3.8 billion revenue in 2013, says analyst. <em>ZDNet</em>. <a href="https://www.zdnet.com/article/amazons-aws-3-8-billion-revenue-in-2013-says-analyst/">https://www.zdnet.com/article/amazons-aws-3-8-billion-revenue-in-2013-says-analyst/</a> <a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9" role="doc-endnote">
<p>Amazon.com, Inc. (2020, January 30). <em>Amazon.com Announces Fourth Quarter Sales up 21% to $87.4 Billion</em> [Press Release]. <a href="https://press.aboutamazon.com/news-releases/news-release-details/amazoncom-announces-fourth-quarter-sales-21-874-billion">https://press.aboutamazon.com/news-releases/news-release-details/amazoncom-announces-fourth-quarter-sales-21-874-billion</a> <a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10" role="doc-endnote">
<p>Given “Cloud &amp; Cognitive Software” also includes “transaction processing platforms” and “cognitive applications” (which presumably are all the Watson things), SoftLayer’s revenue contribution is almost assuredly less than $1 billion. I suspect it is quite likely less than $650 million, which enters the territory of a sub-10% CAGR – the territory of industries like Broadcasting, Home Furnishings, Hotel &amp; Gaming, Shipbuilding &amp; Marine, etc. but certainly not software (which has an average CAGR of 30.9%). Professor Aswath Damodaran of NYU Stern helpfully hosts this page full of revenue and net income CAGRs across industries: <a href="http://pages.stern.nyu.edu/~adamodar/New_Home_Page/datafile/histgr.html">http://pages.stern.nyu.edu/~adamodar/New_Home_Page/datafile/histgr.html</a> <a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11" role="doc-endnote">
<p>This is entirely shade at IBM, not the Trucking sector. The Trucking sector is vital to our economy, but is also not known for being high-growth. Thanks again to Professor Damodaran’s helpful page for these stats: <a href="http://pages.stern.nyu.edu/~adamodar/New_Home_Page/datafile/histgr.html">http://pages.stern.nyu.edu/~adamodar/New_Home_Page/datafile/histgr.html</a> <a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12" role="doc-endnote">
<p>Pun intended. Source: Microsoft Corporation. (2020). <em>Form 10-Q for the Quarter Ended September 30, 2020</em>. <a href="https://view.officeapps.live.com/op/view.aspx?src=https://c.s-microsoft.com/en-us/CMSFiles/MSFT_FY21Q1_10Q.docx?version=e37388fe-99fe-6c5e-deb3-ae5b4fd8b16f">https://view.officeapps.live.com/op/view.aspx?src=https://c.s-microsoft.com/en-us/CMSFiles/MSFT_FY21Q1_10Q.docx?version=e37388fe-99fe-6c5e-deb3-ae5b4fd8b16f</a> (yes, Microsoft seems to now host their SEC filings as .docx rather than as PDFs like everyone else, because they think not enough people know about Microsoft Office???) <a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13" role="doc-endnote">
<p>Can’t stop, won’t stop with the cloud puns. <a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14" role="doc-endnote">
<p>I recalled from my earlier investment banking years that the average stock price premium is usually around 20%, and a variety of online sources seem to confirm that the typical range is 20% - 30%. For instance: <a href="https://merger.com/ma-question-dont/">https://merger.com/ma-question-dont/</a> <a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15" role="doc-endnote">
<p>Red Hat, Inc. (2019). <em>Form 10-K for Fiscal Year 2019</em>. <a href="https://www.sec.gov/ix?doc=/Archives/edgar/data/1087423/000108742319000012/rht-10kq4fy19.htm#s6FE105CDD1C05A3794E63D0DE6C598B5">https://www.sec.gov/ix?doc=/Archives/edgar/data/1087423/000108742319000012/rht-10kq4fy19.htm#s6FE105CDD1C05A3794E63D0DE6C598B5</a> <a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16" role="doc-endnote">
<p>&lt;foreshadowing intensifies&gt; <a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17" role="doc-endnote">
<p>While no doubt tinted by hindsight bias, the 2010 acquisition of Makara – which included the fledgling seeds of OpenShift – was a prescient move, given they would not need to hedge against the dwindling Middleware business for nearly a decade. <a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18" role="doc-endnote">
<p>Literal quote from Red Hat: “We believe revenue growth in our Middleware portfolio has moderated as customers shift their workloads from traditional Java deployments to containerized environments with middleware-as-a-service on OpenShift.” See citation 15 for source. <a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19" role="doc-endnote">
<p>The CentOS Project, owned by Red Hat (owned by IBM), <a href="https://blog.centos.org/2020/12/future-is-centos-stream/">recently announced</a> that CentOS is being end-of-life’d <a href="https://en.wikipedia.org/wiki/End-of-life_product">(EoL’d)</a> – so the distros that OpenShift supports will be even further restricted. CentOS Stream will take CentOS’s place, except rather than being a true replacement as a free alternative to RHEL, its new purpose will be to serve as the upstream branch of RHEL. Technically, this means CentOS 8 will be EoL before CentOS 7, presumably because IBM is confused by distributed systems and thus does not understand the importance of consistency in software, in life, in love. <a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20" role="doc-endnote">
<p>The appropriate meme for this proclamation is <a href="https://knowyourmeme.com/memes/la-noire-doubt-press-x-to-doubt">“Press X to doubt.”</a> <a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21" role="doc-endnote">
<p>If you want elaboration on why I, my friend, and a good many others cringe at “multi-cloud,” I recommend Corey Quinn’s post, <a href="https://www.lastweekinaws.com/blog/multi-cloud-is-the-worst-practice/">“Multi-Cloud is the Worst Practice.”</a> <a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22" role="doc-endnote">
<p>Hopefully someone sent Russ Hanneman the memo that “quatro commas” is the new sexy. Or, perhaps, to keep the alliteration from “Tequila Tres Comas” consistent, Mr. Hanneman should consider “Cognac Quatre Virgules.” I am presuming Mr. Hanneman is unaware that non-English languages generally separate large numbers with a period or non-breaking space rather than a comma, given “tres comas.” <a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23" role="doc-endnote">
<p>I had no idea what Cloud Paks were and discovered one of the worst sentences written on the modern internet when I <a href="https://www.ibm.com/cloud/paks">looked them up</a>, which now, quite like the videotape in the film &ldquo;The Ring&rdquo;, I must share with others lest the curse take me: “IBM Cloud Pak® offerings are an integrated set of AI-infused software solutions for hybrid cloud that help you fully implement intelligent workflows in your business to accelerate digital transformation.” <a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24" role="doc-endnote">
<p>One of my guilty pleasures is referring to TAM calculations as Fantasy Math™. As a former i-banker, I can attest that TAMs are a game in which the goal is to produce as high a number as possible while preserving at least one silken microfiber of plausibility. I doubt anyone within IBM, nor any investor, actually believes this is IBM Cloud’s real TAM, but I acknowledge that humans routinely redefine the depths to which the bar of critical thinking can go. <a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25" role="doc-endnote">
<p>Page 14 of <a href="https://www.ibm.com/investor/att/pdf/ibm-2019-investor-briefing-presentation.pdf">IBM’s Investor Briefing</a> on the Red Hat deal that cites a $1.2 trillion TAM. <a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26" role="doc-endnote">
<p>Nice. <a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27" role="doc-endnote">
<p>Nice. <a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28" role="doc-endnote">
<p>Red Hat’s TAM breakdown can be found on page 8 of this “Red Hat Value Proposition” presentation: <a href="http://people.redhat.com/~duboyd/CO_RHUG/DEN/12_2016/RHT_Value_Prop_for_CORHUG.pdf">http://people.redhat.com/~duboyd/CO_RHUG/DEN/12_2016/RHT_Value_Prop_for_CORHUG.pdf</a> <a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29" role="doc-endnote">
<p>IBM. (2020, October 8). <em>IBM Strategic Update</em>. <a href="https://www.ibm.com/investor/att/pdf/IBM-Strategic-Update-2020-charts.pdf">https://www.ibm.com/investor/att/pdf/IBM-Strategic-Update-2020-charts.pdf</a> <a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30" role="doc-endnote">
<p>Given this TAM is exaggerated to a near-childish extent, I presume IBM baked their hybrid cloud market pie in an Easy-Bake Oven. <a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31" role="doc-endnote">
<p>For the boomers among you, I am referencing this meme: <a href="https://knowyourmeme.com/memes/electric-boogaloo">https://knowyourmeme.com/memes/electric-boogaloo</a> <a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32" role="doc-endnote">
<p>I like to think of IBM Credit as the payday loans of cloud computing. In the spirit of fairness, I must note that AWS also quietly offers <a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9mZWVkcy50cmFuc2lzdG9yLmZtL3NjcmVhbWluZy1pbi10aGUtY2xvdWQ&amp;ep=14&amp;episode=NTgzNjhhMzQtM2FkNi00ODMwLTk4NTEtMTc3NzJlOTMxMjIw&amp;pe=1&amp;pep=0">bespoke contract structuring</a>. <a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33" role="doc-endnote">
<p>Global Financing also includes cursed projects, such as this purposeless blockchain: <a href="https://github.com/IBM/global-financing-blockchain">https://github.com/IBM/global-financing-blockchain</a> <a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:34" role="doc-endnote">
<p>My headcanon is now that IBM retained the Systems division so the name International Business <em>Machines</em> still has relevance. <a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:35" role="doc-endnote">
<p>IBM. (2019). <em>2019 Annual Report</em>. <a href="https://www.ibm.com/annualreport/assets/downloads/IBM_Annual_Report_2019.pdf">https://www.ibm.com/annualreport/assets/downloads/IBM_Annual_Report_2019.pdf</a> <a href="#fnref:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:36" role="doc-endnote">
<p>Alibaba Group Holding Limited. (2019). <em>Form 20-F</em>. <a href="https://otp.investis.com/clients/us/alibaba/SEC/sec-show.aspx?FilingId=13476929&amp;Cik=0001577552&amp;Type=PDF&amp;hasPdf=1">https://otp.investis.com/clients/us/alibaba/SEC/sec-show.aspx?FilingId=13476929&amp;Cik=0001577552&amp;Type=PDF&amp;hasPdf=1</a> <a href="#fnref:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:37" role="doc-endnote">
<p>Microsoft Corporation. (2019). <em>Form 10-K</em>. <a href="https://microsoft.gcs-web.com/static-files/7c96b326-33bc-4b84-8abb-7afd7a517ea3">https://microsoft.gcs-web.com/static-files/7c96b326-33bc-4b84-8abb-7afd7a517ea3</a> <a href="#fnref:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:38" role="doc-endnote">
<p>Alphabet Inc. (2019). <em>Form 10-K</em>. <a href="https://abc.xyz/investor/static/pdf/20200204_alphabet_10K.pdf?cache=cdd6dbf">https://abc.xyz/investor/static/pdf/20200204_alphabet_10K.pdf?cache=cdd6dbf</a> <a href="#fnref:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:39" role="doc-endnote">
<p>Amazon.com, Inc. (2019). <em>Form 10-K</em>. <a href="https://d18rn0p25nwr6d.cloudfront.net/CIK-0001018724/4d39f579-19d8-4119-b087-ee618abf82d6.pdf">https://d18rn0p25nwr6d.cloudfront.net/CIK-0001018724/4d39f579-19d8-4119-b087-ee618abf82d6.pdf</a> <a href="#fnref:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:40" role="doc-endnote">
<p>The notes I checked were, in fact, just a single PDF of IBM’s <em>Investor Briefing 2019</em>: <a href="https://www.ibm.com/investor/att/pdf/ibm-2019-investor-briefing-presentation.pdf">https://www.ibm.com/investor/att/pdf/ibm-2019-investor-briefing-presentation.pdf</a> <a href="#fnref:40" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:41" role="doc-endnote">
<p>Not to mention that a company who infamously collaborated with Nazis should probably avoid inventing new stupid phrases that abbreviate to “SS”. <a href="#fnref:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:42" role="doc-endnote">
<p>Parks and Recreation. (2019, November 12). <em>Ron Tells Leslie &ldquo;Never Half-Ass Two Things&rdquo; - Parks and Recreation</em> [Video]. YouTube. <a href="https://www.youtube.com/watch?v=k6hZ9KdG1QU">https://www.youtube.com/watch?v=k6hZ9KdG1QU</a> <a href="#fnref:42" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:43" role="doc-endnote">
<p>True introspection does not come from diving into high-calorie food or being a spiritual tourist in a foreign land, see also <a href="https://tvtropes.org/pmwiki/pmwiki.php/Main/JourneyToFindOneself">https://tvtropes.org/pmwiki/pmwiki.php/Main/JourneyToFindOneself</a> <a href="#fnref:43" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:44" role="doc-endnote">
<p>If you wanted a nuclear take in this post, here you go: Imagine if IBM could recapture the same ability to execute that they had when they helped the Nazis execute humans. <a href="#fnref:44" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content>
        </item>
        
        <item>
            <title>On YOLOsec and FOMOsec</title>
            <link>https://swagitda.com/blog/posts/on-yolosec-and-fomosec/</link>
            <pubDate>Tue, 22 Sep 2020 08:00:41 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/on-yolosec-and-fomosec/</guid>
            <description>This post will explore why both YOLO security (YOLOsec) and FOMO security (FOMOsec) are pernicious disservices to infosec defense and how you can spot them so that you may yeet them from your organization’s security strategy.</description>
            <content type="html"><![CDATA[<p>Possibly my finest contribution to the infosec industry is introducing the concept of #yolosec, first discussed when I introduced decision trees as a threat modelling device in my Black Hat talk back in 2017<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. Not one to let a solid shitpost go to waste<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>, I want to expand and expound on that concept, and introduce its ideological opposite: #fomosec. Most security efforts are hilariously inefficient, but only one end of the spectrum (#yolosec) is typically called out. That changes today.</p>
<p>This post will explore why both YOLO security (YOLOsec) and FOMO security (FOMOsec) are pernicious disservices to infosec defense and how you can spot them so that you may yeet them from your organization’s security strategy.</p>
<p>The tl;dr is that #yolosec and #fomosec are disconnected from the goals and needs of the business, forsaking pragmatism and prudence in favor of fanatical flavors of recklessness. YOLOsec reflects a security strategy driven by a “you only live once” mentality – one that emboldens people to ignore future concerns around security to achieve today’s gratification. FOMOsec reflects a security strategy driven by a fear of missing out – one that frightens people into misallocating resources towards what makes them <em>feel</em> better about their security efforts.</p>
<p>If you imagine your organization as a sea-faring vessel, infosec’s goal is to ensure the boat can survive krakens or canon-wielding pirates and successfully complete its journey. If you ignore the existence of sea terrors (#yolosec), you may not make it to your destination unless Poseidon grants you merciful passage. If you prioritize defense above your vessel’s mission (#fomosec), you will find yourself aboard a battleship that is entirely inadequate for transporting revenue-generating cargo.</p>
<figure>
    <img src="/blog/img/foyo/russell-marks-kraken-by-russellmarks-d98vq57.jpg"
         alt="Kraken by Russell Marks"/> <figcaption>
            <p><a href="https://www.artstation.com/artwork/XNdkY">Kraken by Russell Marks</a></p>
        </figcaption>
</figure>
<h2 id="first-does-security-matter">First, does security matter?</h2>
<p>Before we dig into defining #yolosec and #fomosec, I want to establish the appropriate context for these concepts. The potential peril inherent in these two “strategic” approaches rests on understanding security’s relevance to private-sector organizations<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. The not-so-dirty and not-so-secret dirty secret is that information security does not matter nearly as much as the infosec industry proselytizes. In the grand scheme of business risks, it is solidly in the bottom half, if not the bottom quartile<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>.</p>
<p>Your organization is far more concerned with attracting and retaining customers, successfully competing in an evolving market, macroeconomic factors relevant to their industry (especially right now, amid the COVID-19 slowdown), operational interruptions and downtime, commodity price fluctuations, failure to maintain brand image and public perception, inadequate financial forecasting, changes in product mix impacting profitability, maintaining relationships with supply chain partners, impacts of seasonality, their litigation and regulatory risk profile, changes in international trade relations, climate change impacts, exchange and interest rate fluctuations, inability to access external financing, ability to anticipate consumer preferences, and, well, you hopefully get the idea by now<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>.</p>
<p>As far as tech stuff goes, organizations are primarily concerned about the interruption or inadequacy of IT systems, since those systems power ongoing business operations and, to varying degrees, fuel their revenue growth. To the ops readers among you, congrats, you are critical to modern business operations across most industries! To my infosec readers, I am certainly not saying you are unimportant, but, rather, that it is vital to be self-aware of one’s influence on the reality around you<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>.</p>
<p>With that said, infosec is not completely useless<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>. Attackers can absolutely cause operational interruption and downtime, most obviously through things like DDoS attacks, ransomware, or overloading cloud compute to eke out computercoins. Beyond those examples, security incidents in general necessitate recovery and response efforts which require money, time, and, frequently, system downtime (so money, money, and frequently money). There is limited evidence that security incidents lead to damaged public perception<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup> or public market valuation<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>.</p>
<p>Therefore, one can consider infosec important to organizations insofar that it either: 1) minimizes negative operational impact engendered by attacker actions 2) enhances qualities that improve business operations, such as the speed, stability, or scale of IT systems. To be clear, there is scant evidence of infosec achieving this second axiom in any meaningful fashion. Security teams encouraging the adoption of standardized APIs or base images is perhaps the only strongly justifiable example. Nevertheless, it remains an equally important, albeit contemporarily theoretical, justification for infosec’s relevancy to businesses.</p>
<p>Now we can explore #yolosec and #fomosec and why their manifestations are so magnificently monstrous.</p>
<h2 id="what-is-yolosec">What is YOLOsec?</h2>
<figure>
    <img src="/blog/img/foyo/mile-micic-parkour-zalazak.jpg"
         alt="Parkour by Mile Mićić"/> <figcaption>
            <p><a href="https://www.artstation.com/artwork/6eRd0">Parkour by Mile Mićić</a></p>
        </figcaption>
</figure>
<p><a href="https://en.wikipedia.org/wiki/YOLO_(aphorism)">YOLO</a> is an acronym for “You Only Live Once,” the modern <em>carpe diem</em> and mostly ironic millennial catchphrase meant to express the unbridled living of life to its fullest in the present, believing the current moment to be vital and unique<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>, with scant regard to the future. YOLO-driven actions tend to manifest as risk-seeking activities, such as skydiving or, in the case of Napoleon Bonaparte’s <a href="https://en.wikipedia.org/wiki/Hundred_Days">Hundred Days</a>, sneaking into France during exile, ripping your coat open and daring your former troops to shoot you, marching on Paris with said troops, reclaiming your title as emperor, engaging in a war against Europe’s major powers, losing at Waterloo, and returning to exile.</p>
<p>YOLOsec, and my irony-flavored hashtag #yolosec, is a term meant to describe a security strategy that embodies the “you only live once” mentality. A yolosec strategy says, “Setting our S3 bucket full of customer data to public will let us deploy our service faster, what could go wrong?” YOLOsec whispers sweet deceits in your ear, telling you that basic security countermeasures like privilege separation and access control are <em>tomorrow</em> problems – knowing full well that tomorrow will distend into months or years. And this temptation can metastasize across your systems and organization.</p>
<p>#yolosec is rarely instigated by a refutation of security’s importance; its wellspring is often found in an arguably myopic attention on specific business goals that are more easily or quickly achieved by ignoring or dismissing security considerations<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>. True to <a href="https://en.wikipedia.org/wiki/Hanlon%27s_razor">Hanlon’s razor</a>, #yolosec is almost assuredly due to incompetence rather than malice.</p>
<p>For instance, developers are not specifically aiming to write code so riddled with bugs that swamps are jealous, nor are they storing API keys in plaintext as an expression of their love for hackers – although both constitute #yolosec. Or, in organizations with high turnover, fresh engineering teams may barely understand how a legacy system works, rendering the exercise of upgrading or migrating it from its current insecure conditions clearly intimidating <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>.</p>
<p>It is thus understandable, albeit undesirable, that the default state of engineering teams is to overlook or neglect infosec concerns when performing their work. This is rarely due to succumbence to temptation, but simply the dearth of pragmatic security wisdom among engineering teams<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>.</p>
<h2 id="what-is-fomosec">What is FOMOsec?</h2>
<figure>
    <img src="/blog/img/foyo/patrycja-wojcik-where-am-i-final.jpg"
         alt="WHERE_AM_I by Patrycja Wójcik"/> <figcaption>
            <p><a href="https://www.artstation.com/artwork/xwK1m">WHERE_AM_I by Patrycja Wójcik</a></p>
        </figcaption>
</figure>
<p><a href="https://en.wikipedia.org/wiki/Fear_of_missing_out">FOMO</a> is an acronym for “Fear of Missing Out,” the modern <em>“keeping up with the Joneses”</em> meant to express the anxiety and regret borne from not participating in experiences in which others are involved – usually examined in the context of witnessing those experiences via social media. FOMO revolves around the basic human desire to understand what is going on, especially the impulse to stay connected with other humans’ experiences<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>.</p>
<p>FOMO can represent a sensation that others are living life better than you are, that you are outside of a social loop, that you are behind in life relative to others, or that everything is beautiful and nothing hurts<sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup> for everyone but you. Human brains are wired to judge outcomes relative to a perceived status quo<sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup> and to feel bad when experiencing a perceived loss<sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>, so FOMO quite unfortunately presents a “buy one cognitive bias, get one free” deal. In a nutshell, there are two primary dimensions driving FOMO: a desire for belonging<sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup> and anxiety about isolation<sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup>.</p>
<p>FOMOsec, and the corresponding hashtag #fomosec, is a term meant to describe a security strategy that is driven by a fear of missing out and its psychological underpinnings<sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>. A #fomosec strategy says, “If you aren’t perfectly protecting literally all the things, what are you even doing?” FOMOsec cackles in your face, mocking your impotent control over the security of your organization’s systems and the flaccidity of your defense relative to the potency of your adversaries and the adulations showered upon your I.T. peers in engineering and operations.</p>
<p>Prioritization and pragmatism fade into the background under FOMOsec; what gains the spotlight is escaping the <em>feeling</em> of inadequacy – regaining a sense of autonomy and control irrespective of outcomes. Under #fomosec, you cry happy tears as your teeth clench and your knuckles whiten from the domspace ecstasy of gripping the wheel, euphorically ignoring that the wheel is not attached to anything and that your supposed steering is relegating you to stagnation.</p>
<p>Defenders, from security engineers to CISOs, are not deliberately sabotaging and impeding organizational operations because of a hatred for business growth or improvement. Every human longs to belong<sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>. Defenders are not immune to this basic human need nor immune to its capacity to desecrate strategic thinking<sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup>.</p>
<p>The human desire for approval and acceptance from groups who share their social identity is what most foments FOMO – seeking inclusion is even more powerful than avoiding exclusion<sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>. Both urges result in largely the same outcomes, however, as humans who feel excluded aim to strengthen their connections with social groups and more tightly enmesh their group membership with their self-identity<sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>. Ultimately, FOMO drives humans to alter their own behavior to imitate others within their chosen social group<sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup>, regardless of specific underlying motivator.</p>
<p>Even mere tourists of the infosec industry are likely aware of the shockingly borgish tendencies of its constituents, culminating in boldly defined shared identities that glut themselves on in-group signaling mechanisms. Whether the identity of the misunderstood Nostradamus who must save the feeble users from themselves or those who treat a piece of software as “completely broken” if there is a vulnerability requiring local access, special configuration settings, and dolphins jumping through ring 0, the nature of infosec culture and cliques certainly suggests the presence of imitation towards the aim of cementing group identity and gaining group approval. And this, in turn, supports the credibility of #fomosec’s existence.</p>
<h3 id="envy--fomo-security">Envy + FOMO Security</h3>
<figure>
    <img src="/blog/img/foyo/mong-cherng-lee-l5-a5-final-web.jpg"
         alt="Matte Painting by Mong Cherng Lee"/> <figcaption>
            <p><a href="https://www.artstation.com/artwork/b2gDn">Matte Painting by Mong Cherng Lee</a></p>
        </figcaption>
</figure>
<p>I believe envy waters the roots of #fomosec. Envy is best described as the painful feeling of hostility, inferiority, and resentment resting upon a foundation of admiration.<sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup> When you admire or respect someone else’s situation and compare it against your own, FOMO and envy mix together into an especially potent poison<sup id="fnref:27"><a href="#fn:27" class="footnote-ref" role="doc-noteref">27</a></sup>.</p>
<p>The targets of infosec’s envy are attackers and software engineers – that both possess measurable and meaningful goals that result in tangibly meaningful work. For attackers, the obvious goal is “did you get in?” For engineers, the obvious goal is “did you deliver software customers will buy and use?” Offense attains swaggering victory and software engineers attain lucrative accolades. Infosec’s goals are nebulous or self-serving, its metrics either non-existent or inconsequential, its success abstract and bittersweet at best.</p>
<p>In response to my own work<sup id="fnref:28"><a href="#fn:28" class="footnote-ref" role="doc-noteref">28</a></sup>, I have witnessed infosec professionals bristle at the notion of adopting ops metrics like mean time to recovery (MTTR) to inform their own work. Infosec seemingly wants its own special metrics, despite the obvious logic of adopting metrics that align with operational objectives. This palpably inefficient priority of feeling special over pursuing more meaningful work is not only driven by FOMO-via-envy, but FOMO-via-social-identity, too.</p>
<p>Envy is made even stronger by a need to belong<sup id="fnref:29"><a href="#fn:29" class="footnote-ref" role="doc-noteref">29</a></sup>. Social identity can even be thought of as blossoming from FOMO, which is also made stronger by the longing for belonging<sup id="fnref:30"><a href="#fn:30" class="footnote-ref" role="doc-noteref">30</a></sup>. Extending this to infosec, FOMOsec is perhaps the catalyst for the stark, shared identities found across the industry. In fact, the infosec community, in many ways, is not unlike online gaming communities – featuring guilds (like CISO cliques and SecEng sects), server-wide events (like conferences), and highly active chat channels (like Twitter and Slack groups). And, much like online gaming addiction, the human need to belong perhaps fuels infosec’s obsession with adhering to the shared identity of “outsider.”</p>
<h3 id="fomo-security-budgets">FOMO Security Budgets</h3>
<p>Unfortunately, #fomosec discourages practitioners from pragmatic budget decisions towards choices that make them feel accepted by their desired social group, whether fellow CISOs or security engineers. This desire for praise and prestige from others leads to consumption behavior based an expectation of how others will perceive the consumption, rather than prioritizing product quality<sup id="fnref:31"><a href="#fn:31" class="footnote-ref" role="doc-noteref">31</a></sup>. Driven by the fundamental need for social inclusion, humans purchase and use products that are symbolic of the groups with which they desire connection – and they are willing to sacrifice “personal and financial well-being for the sake of social well-being.”<sup id="fnref:32"><a href="#fn:32" class="footnote-ref" role="doc-noteref">32</a></sup></p>
<p>The purchasing of tools such as threat hunting, fancy threat intel reports, or protection against niche, nation-state threats can be thought of as luxury goods that serve as costly signaling mechanisms to generate interpersonal acceptance<sup id="fnref:33"><a href="#fn:33" class="footnote-ref" role="doc-noteref">33</a></sup>. Adopting frameworks trendy among the in-group – such as MITRE ATT&amp;CK is currently – is a less expensive signaling mechanism, until you factor in opportunity cost. Security engineers building their own SIEM, rivalling children’s attempts at building majestic towers with popsicle sticks and glue sticks, is costly both in people hours and opportunity cost incurred by the organization. However, it represents a feat worthy of admiration from their peers despite the substantial downsides, true to #fomosec’s essence.</p>
<p>FOMO not only drives people to spend excessively and forget their true needs, but also leads people to consult their peers when making purchasing decisions for goods or services – the combination of both leading to impulse purchases that are far from strategic.<sup id="fnref:34"><a href="#fn:34" class="footnote-ref" role="doc-noteref">34</a></sup> While there are few studies on how security leaders make purchases, anecdata suggests that peers are one of the stronger influences in decision-making, especially if you include indirect peer influence through research analysis firms.</p>
<p>As a result, #fomosec creates the consummate conditions for snakeoilism to spread. FOMOsec germinates from defenders’ fears of being the outcast sheep of the I.T. family, fears of always being one step behind of attackers, fears of their work being meaningless in light of the inevitability of failure, and fears of looking foolish to peers when an incident is emblazoned in public headlines. Rather than promote mindfulness on business objectives, the industry encourages their dismissal, shaming and guilting and goading defenders into throwing away budget towards products that pursue perfection – the unattainable ideal that tacitly stokes the ego’s lust for heroism.</p>
<h2 id="horseshoe-theory--foyo-security35">Horseshoe Theory &amp; FOYO Security<sup id="fnref:35"><a href="#fn:35" class="footnote-ref" role="doc-noteref">35</a></sup></h2>
<p><img src="/blog/img/foyo/horseshoe-theory-security-strategy.png" alt="The Horseshoe Theory of Security Strategy by Kelly Shortridge"></p>
<p>Despite #yolosec suggesting a blistering lack of attention on security and, on the other end of the spectrum, #fomosec suggesting a desperate and egoistic obsession on security, they both result in poignantly poor security outcomes. I argue that they represent the two ends of a Security Strategy Horseshoe, and, in their extreme forms, are nearly indistinguishable in their outcomes.</p>
<p>When you FOMOsec, you are prone to treat the security of all assets, and threats to those assets, equally – or worse, overcorrect for niche threats (like 0day or nation state actors) under the “gotta catch ‘em all” mentality. In the former case, even the largest teams with the highest budgets cannot perfectly secure all systems against all types of incidents. One result is spreading efforts far too thinly in order to maximize breadth of coverage or concentrating on what <em>feels</em> like the biggest gap and neglecting others.</p>
<h3 id="desperate-for-data">Desperate for Data</h3>
<blockquote>
<p><em>They were all in love with data</em><br>
<em>They were drinking from a fountain</em><br>
<em>That was pouring like an avalanche</em><br>
<em>Coming down the mountain<sup id="fnref:36"><a href="#fn:36" class="footnote-ref" role="doc-noteref">36</a></sup></em></p>
</blockquote>
<figure>
    <img src="/blog/img/foyo/louise-meijer-deathrace5.jpg"
         alt="Avalanche death race by Louise Meijer"/> <figcaption>
            <p><a href="https://www.artstation.com/artwork/A9QwYN">Avalanche death race by Louise Meijer</a></p>
        </figcaption>
</figure>
<p>Those who #fomosec believe that one must collect all of the data possible, as missing the one clue indicating an incident will be catastrophic, embarrassing, or result in some other ill-defined tragedy<sup id="fnref:37"><a href="#fn:37" class="footnote-ref" role="doc-noteref">37</a></sup>. There is a shared, somewhat histrionic belief across the industry that attackers just need to discover one flaw to win, while defenders must cover all flaws to win. From the assumption that attackers possess an (unfair) information advantage, it can flow that gaining an advantage comes from rebalancing the pervading information asymmetry. That is, defenders can elevate their status relative to their adversaries by accumulating enough data, where the quantification of “enough” is persistently vague.</p>
<p>Through this lens of data accumulation, the end results of FOMOsec-driven behavior look an awful lot like those generated by YOLOsec. To quote Professor Netzer of Columbia University (invoking Andrew Lang), “A lot of people are using data like a drunk man uses a lamppost, for support rather than illumination.”<sup id="fnref:38"><a href="#fn:38" class="footnote-ref" role="doc-noteref">38</a></sup> Doing so is a decidedly YOLO vibe, even if it is fostered by FOMO.</p>
<p>When FOMOsec ignores the basic wisdom of the <a href="https://en.wikipedia.org/wiki/Central_limit_theorem">central limit theorem</a> and the reality of <a href="https://en.wikipedia.org/wiki/Diminishing_returns">diminishing returns</a> on data set size in improving performance and reducing errors<sup id="fnref:39"><a href="#fn:39" class="footnote-ref" role="doc-noteref">39</a></sup>, it wraps around closer to YOLOsec. Data is a tool for improving outcomes when faced with the unknown, but resolving uncertainty presents finite benefits<sup id="fnref:40"><a href="#fn:40" class="footnote-ref" role="doc-noteref">40</a></sup> – and thus data presents finite and diminishing returns.</p>
<p>Like a dragon slowly burying itself in treasure, FOMOsec growls, “We need to hoard all the data…” and YOLOsec roars, “…and who cares if it causes operational distractions and management headaches in the future?” The FOMOsec-distorted cost / benefit model not only overstates the benefits of data accumulation but also misses the costs of handling all that data going forward<sup id="fnref:41"><a href="#fn:41" class="footnote-ref" role="doc-noteref">41</a></sup>in a classically myopic YOLOsec fashion.</p>
<p>FOMOsec tells you that you desperately need to collect all the things (and to buy fancy tech that can help you do so) because otherwise you are not in the know, and YOLOsec tells you to collect all the things just because you can. These impulses are nearly indistinguishable in flavor, and equally as damaging. You should not measure things just because you can<sup id="fnref:42"><a href="#fn:42" class="footnote-ref" role="doc-noteref">42</a></sup> as it will lead to a form of self-sabotage via information overload, which leads to cognitive overload<sup id="fnref:43"><a href="#fn:43" class="footnote-ref" role="doc-noteref">43</a></sup>, which leads to a variety of issues that can be summarized as significant human performance degradation<sup id="fnref:44"><a href="#fn:44" class="footnote-ref" role="doc-noteref">44</a></sup>.</p>
<p>The social element of FOMO manifests in infoxication<sup id="fnref:45"><a href="#fn:45" class="footnote-ref" role="doc-noteref">45</a></sup>, too. The giveaway that data accumulation is not actually about better business outcomes is found in infosec teams refusing to leverage data sources and tools deployed by operations teams, which would streamline budget and promote collaboration. Instead, security teams seemingly refuse to let go. Budget is viewed as a status signal, and security leaders in the vice grip of FOMOsec are disincentivized from taking actions that make them feel <em>less</em> influential, even if it is the right move for their organization and team.</p>
<p>Defenders who #fomosec seek out approval and praise from other defenders as well as their organization – and performing challenging engineering feats helps fulfill that impulse. As one study looking at Amazon’s big data practices unearthed, the accumulation of “big data” is mostly viewed as an engineering challenge rather than providing tangible modeling benefits<sup id="fnref:46"><a href="#fn:46" class="footnote-ref" role="doc-noteref">46</a></sup>. Additionally, most of this “big data” is wasted, with potentially as little as 0.1% of the data treasure hoard being used to power decision-support systems, as in Google’s case<sup id="fnref:47"><a href="#fn:47" class="footnote-ref" role="doc-noteref">47</a></sup>.</p>
<p>The mythical “data feedback loop” does not bear out in practice, but it can certainly help defenders burdened with FOMOsec <em>feel</em> like they are in the know, that they are performing prestigious work, and, besides, everyone else seems to be doing it as part of their security strategy, so mimicry feels right, too. But, just as your mother warned you once upon a time, jumping off a bridge just because everyone else is doing it is a decidedly YOLO course of action.</p>
<h3 id="all-aboard-the-vulnerability-hypetrain">All Aboard the Vulnerability Hypetrain</h3>
<figure>
    <img src="/blog/img/foyo/aleksandr-chernobai-kamaha-draft-32-2.jpg"
         alt="Train by Aleksandr Chernobai"/> <figcaption>
            <p><a href="https://www.artstation.com/artwork/yb1NXJ">Train by Aleksandr Chernobai</a></p>
        </figcaption>
</figure>
<p>The infosec industry is firmly strapped onboard the vulnerability hypetrain: the flurry of media attention and industry panic that explodes upon publication of previously unknown flaws in software, known as zero-day vulnerabilities (or 0day, as the kids say), that often come with their own branding and public relations strategy<sup id="fnref:48"><a href="#fn:48" class="footnote-ref" role="doc-noteref">48</a></sup>. Each new, provocatively-named vulnerability adds a stop on the interminable journey. The engine of the vulnerability hypetrain is #fomosec and its exhaust is #yolosec.</p>
<p>Aboard this train, security leaders roleplay as special agents and muse through their tinted Morphean shades about “threat actors,” presenting idle speculation about how geopolitical events shape their firewall policies. The names of vulnerabilities hold special power, like an eldritch deity lurking in the forests surrounding a village, to whom blood sacrifices must be made each full moon lest it devour any newborns in their cribs. The truth that is lost among these rituals of the status quo is that vulnerabilities, and their monikers, should not be given more thought than the names of hurricanes that threaten power or data availability.</p>
<p>Wherefore this pestilent paradigm, then? Each vulnerability with its own PR campaign is a chance to trigger #fomosec, which leads to money or attention (so money or indirectly money)<sup id="fnref:49"><a href="#fn:49" class="footnote-ref" role="doc-noteref">49</a></sup>. Constantly stimulating the FOMOsec response leads defenders to adopt a vulnerability-centric approach to security that merges into the unkempt path of YOLOsec. YOLOsec curls around you like an anaconda, obscuring your vision until you can only see the industry headlines screaming about the newest cyberweapon or threat group, the peripheral sliding away until the more relevant factors that contribute to security failure, like misconfigurations, are overlooked.</p>
<p>Overly permissive access controls will not receive a fancy name like RootRipper or DefaultDesecration but will make an attacker’s job much easier. Thus, when #fomosec panics about missing the presence of the latest heralded vulnerability in your organization’s environment, #yolosec high fives its partner-in-crime and springs into action to beleaguer your colleagues with the false positives and intractable UIs of vulnerability scanners while the attacker stumbles upon a publicly exposed k8s management dashboard and takes control of prod<sup id="fnref:50"><a href="#fn:50" class="footnote-ref" role="doc-noteref">50</a></sup>.</p>
<p>The stated motivation for the vulnerability hypetrain is to protect users in the surrounding countryside. But, well, COVID-19 was not named LungTempest, and we do not see pharmaceutical companies publishing blog posts by self-proclaimed rockstars about how to improve the scalability or functionality of LungTempest so amateurs can DIY their own virus with a bit of copy pasting and tweaking<sup id="fnref:51"><a href="#fn:51" class="footnote-ref" role="doc-noteref">51</a></sup>.</p>
<p>We would all rightfully be outraged if pharma researchers were publishing posts about leet bioweapons online for fun and profit, about how to bypass a competitor vendor’s vaccine (after an oh-so-generous 90 day window for them to fix the vaccine), or with technical details that dramatically overstated the potential severity of the virus in order to raise funding for a new miracle drug.</p>
<p>Alas, #yolosec relishes the <em>joie de vivre</em> of dropping 0day to thunderous applause and #fomosec drinks deeply of it – the shimmering waters of an oasis in the lonely desert under the blisteringly hot sun of irrelevancy. Defenders thirst for significance and acceptance. And researchers (and the vendors who employ them) are more than happy to provide a means of feeling “in the know” and phantasmic progression towards solving the frustratingly contumacious security problem. I leave it up to the reader to evaluate whether this is symbiosis or parasitism.</p>
<h3 id="fomo-security-fosters-yolo-security">FOMO Security Fosters YOLO Security</h3>
<figure>
    <img src="/blog/img/foyo/minjeong-kim-171223-3.jpg"
         alt="Hacker&amp;rsquo;s temporary hideout by Minjeong Kim"/> <figcaption>
            <p><a href="https://www.artstation.com/artwork/k0Vy2">Hacker&rsquo;s temporary hideout by Minjeong Kim</a></p>
        </figcaption>
</figure>
<p>The desire to acquire the sexy, shiny security toys that seemingly signal membership in the Cool Kids Club is incited by FOMOsec<sup id="fnref:52"><a href="#fn:52" class="footnote-ref" role="doc-noteref">52</a></sup>. <a href="https://twitter.com/swagitda_/status/906113918283730944?s=20">Equifax deployed FireEye to protect against advanced threats</a> and yet: 1) failed to patch a vuln in their database within their own mandated time frame of 48 hours (it was more like four months)<sup id="fnref:53"><a href="#fn:53" class="footnote-ref" role="doc-noteref">53</a></sup>; 2) neglected to update the security certificate in their network traffic monitoring tool for <em>19 months</em>, rendering it useless<sup id="fnref:54"><a href="#fn:54" class="footnote-ref" role="doc-noteref">54</a></sup>.</p>
<p>Equifax simultaneously FOMOsec’d and YOLOsec’d, demonstrating the conceptual compatibility of the horseshoe’s ends. The same security team can both be like, “We need to stop nation states!” and also completely fail to patch their shit.</p>
<p>I argue the general case that #fomosec almost necessarily engenders #yolosec elsewhere, not unlike life outside of security. An obsession with the perceived inadequacy of your own life in light of the perceived excellence of others’ lives (FOMO) is likely to lead you to take extreme action to “prove” how exciting and fun your own life is (YOLO). For instance, college students who experience more FOMO also are more willing to place themselves in riskier social situations and make impulsive, embarrassing, or physically harmful decisions<sup id="fnref:55"><a href="#fn:55" class="footnote-ref" role="doc-noteref">55</a></sup>.</p>
<p>The yearning beget by FOMO to belong to a social group and receive praise from it leads people to pursue novel experiences, with the expectation that these experiences will arouse approval from others<sup id="fnref:56"><a href="#fn:56" class="footnote-ref" role="doc-noteref">56</a></sup>. That is to say, FOMOsec is quite likely to lead defenders to make YOLOsec-flavored decisions, sprinting down a path of myopia filled with seemingly impressive feats – whether buying sexy tech, paying out the nose for “exclusive” threat exposés, being on an advisory board of a hot infosec startup, attending VIP conference parties, and so forth – that are entirely uncoupled with what is required to ensure business operations are pragmatically protected.</p>
<p>This may be a shock to some security readers, whose self-image might shatter at the thought that they could allow – let alone foster – #yolosec. But, when you allow #fomosec, when you want no security stones left unturned, when you demand security approvals on every last bit of new code, or when you lust for security gaining a sacred seat at the Big Kids’ Business Table, you are losing sight of your organization’s priorities and thus inherently routing limited resources in suboptimal directions. You fight your eng org to integrate the vulnerability scanning tool made by the company who let you meet Mr. Robot at RSAC into your organization’s code repo, and now you gain the glorious outcome of developers ignoring the tool’s findings and resenting you – thereby deciding to stay quiet about security issues they do find – while your precious security budget is six figures lighter. You did it!</p>
<p>And before you think that this could not possibly apply to you, consider this: you could be under the influence of FOMO as you read this and be unfeignedly unaware of how it is negatively impacting your work<sup id="fnref:57"><a href="#fn:57" class="footnote-ref" role="doc-noteref">57</a></sup>.</p>
<h2 id="conclusion">Conclusion</h2>
<p>If security must shun both YOLOsec and FOMOsec, how should it look instead? To simultaneously alleviate a longing for belonging, envy, and myopia, infosec defenders must seek out and share the identity of “builder”<sup id="fnref:58"><a href="#fn:58" class="footnote-ref" role="doc-noteref">58</a></sup> with software engineers<sup id="fnref:59"><a href="#fn:59" class="footnote-ref" role="doc-noteref">59</a></sup>. Aligning infosec metrics to software delivery metrics facilitates the alignment of infosec work to software delivery work. Acting upon this alignment – not just paying lip service – engenders the opportunity for security teams to more tangibly connect the work they perform with value and meaning produced.</p>
<p>If you can understand nuance in security problems, you will absolutely be valued by your organization. If you can support the customer experiences required to facilitate business success while ensuring ongoing operational sustainability, it is difficult to imagine your organization viewing you as a nuisance or cost center. FOMOsec poisons missions away from achieving business goals, while YOLOsec erodes the prospect of ongoing sustainability.</p>
<p>Perhaps what is most needed is to shed the label of “security” entirely to encourage a restructuring towards “resilience.” Organizations do not need professionals who self-identify as critics or “breakers”; they need professionals who self-identify as builders but who take pride in building robust systems that can quickly adapt when exposed to any sort of incident – whether an outage caused by an attacker or a performance bug.</p>
<p>That, I think, is the easiest way to kill #fomosec and #yolosec in one fell swoop: the recognition that outcomes are everything and that the differentiation between performance and security concerns in the context of resilience is an unnecessary, outdated construct. #yolosec cannot thrive if engineers are accountable for minimizing instability, regardless of its source. #fomosec cannot thrive if security concerns are treated equally to performance concerns, subject to the same pragmatic prioritization.</p>
<p>The infosec industry would hate it (how many billions of dollars less would vendors make?) and I would lose a multitude of industry insanities to explore… but how much time, money, user pain, and wasted fucks given would we save? I think we should keep an open mind.</p>
<hr>
<p>Thank you shoutouts to Dr. Nicole Forsgren, Camille Fournier, Kyle Kingsbury, Ryan Petrich, Andrew Ruef, and James Turnbull.</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Shortridge, K. (2017). <a href="https://swagitda.com/speaking/us-17-Shortridge-Big-Game-Theory-Hunting.pdf">Big Game Theory Hunting: The Peculiarities of Human Behavior in the InfoSec Game</a>. Presented at Black Hat USA, Las Vegas, N.V. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>To be fair, I leveraged yolosec previously for my educational shitpost <a href="https://swagitda.com/blog/posts/darth-jar-jar-model-infosec-innovation/">“Darth Jar Jar: a Model for Infosec Innovation.”</a> <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>I think this argument can be extended to public sector organizations, but it is not a hill on which I am willing to die. My hot take would be that the mission of defense and intelligence agencies is inherently one of national security, and thus enhanced investment into infosec does not constitute #fomosec, as does not obstruct organizational goals and needs (they are actually quite aligned!). It likely goes without saying that #yolosec is incontrovertibly relevant to the public sector; if you are a crayon freebaser and disagree, you should consider <a href="https://en.wikipedia.org/wiki/Office_of_Personnel_Management_data_breach#Warnings">the case of the OPM data breach back in 2015</a>. <a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>Sure, yeah, this is a hot take, but I know of at least one report coming out with stats to support this, and you can peruse the 10-K filings of Fortune 500 companies and see how far down the Risk Factors section you must go to see something specifically concerning cyberattacks. <a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p>As foreshadowed by Footnote 4, I chose five Fortune 500 companies across technology, agriculture, healthcare, logistics, and retail to compile the above sampling of risk factors enumerated in their 10-K filings – all of which come before any mention of data breaches. If you find my sampling lazy (which it definitely is), then I warmly welcome your forthcoming analysis across a more meaningful subset of the Fortune 500. <a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6" role="doc-endnote">
<p>Listen to my homeboy Dostoevsky, plz: <em>“Above all, don&rsquo;t lie to yourself. The man who lies to himself and listens to his own lie comes to such a pass that he cannot distinguish the truth within him, or around him, and so loses all respect for himself and for others.”</em> (from <em>The Brothers Karamazov</em>). <a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7" role="doc-endnote">
<p>I was initially going to say that infosec is not <a href="https://www.theguardian.com/technology/2017/sep/01/juicero-silicon-valley-shutting-down">the Juicero</a> of enterprise IT, but, upon pondering that analogy, I realized that it actually is quite a bit like Juicero. <a href="https://www.youtube.com/watch?v=_Cp-BGQfpHQ">Juicero required a fancy machine</a> to squeeze juice packets which one could squeeze with one’s own hands, and I am of the belief that software engineers could perform an awful lot of what security teams perform today, with far greater efficiency and without salivating over blinky boxes or viewing vuln research rockstars as senpai, and, further, that the infosec market is incredibly inflated relative to its material importance, which is not dissimilar from Juicero’s own engorged valuation once upon a time. <a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8" role="doc-endnote">
<p>Makridis, C. (2020). <a href="https://ssrn.com/abstract=3596933">Do Data Breaches Damage Reputation? Evidence from 43 Companies Between 2002 and 2018</a>. <a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9" role="doc-endnote">
<p>This is a common, self-serving myth peddled by infosec vendors and security practitioners alike. The reality is that stock prices tend to slightly dip immediately in response to a data breach, but quickly recover. See: Kvochko, E., &amp; Pant, R. (2015). <a href="https://hbr.org/2015/03/why-data-breaches-dont-hurt-stock-prices">Why data breaches don’t hurt stock prices</a>. <em>Harvard Business Review, 31</em>. and Hilary, G., Segal, B., &amp; Zhang, M. H. (2016). <a href="https://www.fordham.edu/download/downloads/id/8180/cyber-risk_disclosure_who_cares.pdf">Cyber-risk disclosure: Who cares?</a>. <em>Georgetown McDonough School of Business Research Paper</em>, (2852519). <a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10" role="doc-endnote">
<p>Sobol-Kwapinska, M., Jankowski, T., &amp; Przepiorka, A. (2016). <a href="https://www.researchgate.net/profile/Tomasz_Jankowski/publication/281437827_What_do_we_gain_by_adding_time_perspective_to_mindfulness_Carpe_Diem_and_mindfulness_in_a_temporal_framework/links/5a1813404585155c26a7c3d1/What-do-we-gain-by-adding-time-perspective-to-mindfulness-Carpe-Diem-and-mindfulness-in-a-temporal-framework.pdf">What do we gain by adding time perspective to mindfulness? Carpe Diem and mindfulness in a temporal framework</a>. <em>Personality and Individual Differences, 93</em>, 112-117. <a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11" role="doc-endnote">
<p>Ignorance of security issues can also be a source, but it is less plausible of an explanation when considering organizations beyond small businesses possessing an IT org of less than ten people. <a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12" role="doc-endnote">
<p>Although I will elaborate on the Equifax breach later in this post in the context of yolo- and fomo-sec, an example of this point is found in the testimony of David Webb, Equifax’s CIO, during the Congressional hearing regarding the breach: <em>“It was not a cost concern. It was–really, if there is a–if there’s a constraint, it’s the domain expertise required to refactor the application, because you need experts who understand what the application does in order to put it in a new environment and do the same thing.”</em> <a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13" role="doc-endnote">
<p>For some proposed solutions to this problem, I will self-servingly recommend reading the forthcoming O’Reilly report on Security Chaos Engineering, of which I am co-author. <a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14" role="doc-endnote">
<p>Wegmann, E., Oberst, U., Stodt, B., &amp; Brand, M. (2017). Online-specific fear of missing out and Internet-use expectancies contribute to symptoms of Internet-communication disorder. <em>Addictive Behaviors Reports, 5</em>, 33-42. <a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15" role="doc-endnote">
<p>Borrowing from one of my favorites, <em>Slaughterhouse-Five</em> by Vonnegut. <a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16" role="doc-endnote">
<p>See the concept of “Reference Dependence,” as first exhibited in the OG paper on Prospect Theory by Kahneman and Tversky. Kahneman, D., &amp; Tversky, A. (1979). <a href="https://www.uzh.ch/cmsssl/suz/dam/jcr:00000000-64a0-5b1c-0000-00003b7ec704/10.05-kahneman-tversky-79.pdf">Prospect theory: An analysis of decision under risk</a>. <em>Econometrica, 47</em>, 263-291. Additionally, see a case study on marathon runners and reference dependence in: Markle, A., Wu, G., White, R., &amp; Sackett, A. (2018). <a href="https://ir.stthomas.edu/cgi/viewcontent.cgi?article=1055&amp;context=ocbmktgpub">Goals as reference points in marathon running: A novel test of reference dependence</a>. <em>Journal of Risk and Uncertainty, 56</em>(1), 19-50. <a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17" role="doc-endnote">
<p>Tversky, A., &amp; Kahneman, D. (1991). <a href="https://pdfs.semanticscholar.org/86af/5b4ce3324624bbb499eb79ee0901d6375df9.pdf">Loss aversion in riskless choice: A reference-dependent model</a>. <em>The quarterly journal of economics, 106</em>(4), 1039-1061. Additionally, see a case study on house sellers and loss aversion in: Genesove, D., &amp; Mayer, C. (2001). <a href="https://www.nber.org/papers/w8143.pdf">Loss aversion and seller behavior: Evidence from the housing market</a>. <em>The quarterly journal of economics, 116</em>(4), 1233-1260. <a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18" role="doc-endnote">
<p>Abel, J. P., Buff, C. L., &amp; Burr, S. A. (2016). <a href="https://www.clutejournals.com/index.php/JBER/article/download/9554/9632">Social media and the fear of missing out: Scale development and assessment</a>. <em>Journal of Business &amp; Economics Research (JBER), 14</em>(1), 33-44. <a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19" role="doc-endnote">
<p>More specifically, these two dimensions manifest as desiring connectedness and approval from others vs. wanting to avoid feeling alienated and ignored. <a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20" role="doc-endnote">
<p>As it is my term, I find it acceptable to broaden the definition beyond strictly FOMO to also include the desire for belonging, anxiety about isolation, underlying envy, and so forth. It is, perhaps, a YOLO move to do so. <a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21" role="doc-endnote">
<p>Baumeister, R. F., &amp; Leary, M. R. (1995). <a href="https://www.researchgate.net/publication/15420847_The_Need_to_Belong_Desire_for_Interpersonal_Attachments_as_a_Fundamental_Human_Motivation">The need to belong: desire for interpersonal attachments as a fundamental human motivation</a>. <em>Psychological bulletin, 117</em>(3), 497. <a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22" role="doc-endnote">
<p>This is true despite protestations by some members of the infosec community that they are more enlightened than the general human population because they do not make “dumb” security mistakes, and despite a non-trivial portion of infosec conference attendees residing in the bottom quintile of hygiene standards. <a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23" role="doc-endnote">
<p>Lai, C., Altavilla, D., Ronconi, A., &amp; Aceto, P. (2016). Fear of missing out (FOMO) is associated with activation of the right middle temporal gyrus during inclusion social cue. <em>Computers in Human Behavior, 61</em>, 516-521. <a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24" role="doc-endnote">
<p>Knowles, M. L., &amp; Gardner, W. L. (2008). <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.830.5393&amp;rep=rep1&amp;type=pdf">Benefits of membership: The activation and amplification of group identities in response to social rejection</a>. <em>Personality and Social Psychology Bulletin, 34</em>(9), 1200-1213. <a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25" role="doc-endnote">
<p>Lakin, J. L., Chartrand, T. L., &amp; Arkin, R. M. (2008). <a href="https://faculty.fuqua.duke.edu/~tlc10/bio/TLC_articles/2008/Lakin_Chartrand_Arkin_2008.pdf">I am too just like you: Nonconscious mimicry as an automatic behavioral response to social exclusion</a>. <em>Psychological science, 19</em>(8), 816-822. <a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26" role="doc-endnote">
<p>Smith, R. H., &amp; Kim, S. H. (2007). Comprehending envy. <em>Psychological bulletin, 133</em>(1), 46. <a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:27" role="doc-endnote">
<p>Menon, T., &amp; Thompson, L. (2010). <a href="https://hbr.org/2010/04/envy-at-work">Envy at work</a>. <em>Harvard business review, 88</em>(4), 74-79. <a href="#fnref:27" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:28" role="doc-endnote">
<p>Shortridge, K., &amp; Forsgren, N. (2019, August). <a href="https://swagitda.com/speaking/us-19-Shortridge-Forsgren-Controlled-Chaos-the-Inevitable-Marriage-of-DevOps-and-Security.pdf">Controlled Chaos: The Inevitable Marriage of DevOps &amp; Security</a>. Presented at Black Hat USA, Las Vegas, N.V. <a href="#fnref:28" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:29" role="doc-endnote">
<p>Yin, L., Wang, P., Nie, J., Guo, J., Feng, J., &amp; Lei, L. (2019). <a href="https://www.researchgate.net/profile/Pengcheng_Wang22/publication/334173863_Social_networking_sites_addiction_and_FoMO_The_mediating_role_of_envy_and_the_moderating_role_of_need_to_belong/links/5d53c07092851c93b62e6914/Social-networking-sites-addiction-and-FoMO-The-mediating-role-of-envy-and-the-moderating-role-of-need-to-belong.pdf">Social networking sites addiction and FoMO: The mediating role of envy and the moderating role of need to belong</a>. <em>Current Psychology, 1-9</em>. <a href="#fnref:29" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:30" role="doc-endnote">
<p>Duman, H., &amp; Ozkara, B. Y. (2019). <a href="http://acikerisim.rumeli.edu.tr:6060/xmlui/bitstream/handle/1/139/The%20impact%20of%20social%20identity%20on%20online%20game%20addiction.pdf?sequence=1&amp;isAllowed=y">The impact of social identity on online game addiction: the mediating role of the fear of missing out (FoMO) and the moderating role of the need to belong</a>. <em>Current Psychology, 1-10</em>. <a href="#fnref:30" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:31" role="doc-endnote">
<p>Kang, I., Cui, H., &amp; Son, J. (2019). <a href="https://www.mdpi.com/2071-1050/11/17/4734/pdf">Conformity consumption behavior and FoMO</a>. <em>Sustainability, 11</em>(17), 4734. <a href="#fnref:31" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:32" role="doc-endnote">
<p>Mead, N. L., Baumeister, R. F., Stillman, T. F., Rawn, C. D., &amp; Vohs, K. D. (2011). <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.459.4993&amp;rep=rep1&amp;type=pdf">Social exclusion causes people to spend and consume strategically in the service of affiliation</a>. <em>Journal of consumer research, 37</em>(5), 902-919. <a href="#fnref:32" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:33" role="doc-endnote">
<p>Practitioners who are more secure in their social standing and group ties may be more immune to this kind of consumption. If only people spent as much for therapy as they do for conference passes. <a href="#fnref:33" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:34" role="doc-endnote">
<p>Aydin, H. (2018). <a href="https://dergipark.org.tr/en/download/article-file/565502">A Systematic Review on the Use of FoMO as a Social Marketing Trend in Marketing Area</a>. <em>İzmir Katip Çelebi Üniversitesi İktisadi ve İdari Bilimler Fakültesi Dergisi, 1</em>(1), 1-9. <a href="#fnref:34" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:35" role="doc-endnote">
<p>I hope someone figures out a way to turn FOYO Security into “FROYO Security.” It would really enhance infosec culture (ba dum tss). <a href="#fnref:35" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:36" role="doc-endnote">
<p>A spoof on: Butthole Surfers (1996). <a href="https://www.youtube.com/watch?v=G8sGmSEehi4">Pepper</a>. On <em>Electriclarryland</em>. Capitol Records. <a href="#fnref:36" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:37" role="doc-endnote">
<p>While I am loathe to paint so broad a brush as to call these fears histrionic, it has always struck me as strange how often security leaders seem worried that the one signal they miss will end their world, and yet are seemingly content remaining in the dark as far as establishing outcome-aligned success measurements, understanding why the humans in their organization are “failing” to adhere to security policies, or learning the persuasive communication skills necessary to better foster consensus in their organization – all of which are far more likely to guarantee their successful tenure. <a href="#fnref:37" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:38" role="doc-endnote">
<p>Netzer, O. (2017, May 26). <a href="https://www8.gsb.columbia.edu/articles/ideas-work/more-data-isn-t-always-answer">More Data Isn’t Always the Answer</a> [Blog post]. <a href="#fnref:38" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:39" role="doc-endnote">
<p>Lerner, A. V. (2014). <a href="http://awa2015.concurrences.com/IMG/pdf/big.pdf">The role of &lsquo;big data&rsquo; in online platform competition</a>. <a href="#fnref:39" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:40" role="doc-endnote">
<p>Veldkamp, L., &amp; Chung, C. (2019, October). <a href="https://www0.gsb.columbia.edu/faculty/lveldkamp/papers/JEL_MacroDataLV_v7.pdf">Data and the aggregate economy</a>. In <em>Annual Meeting Plenary</em> (No. 2019-1). Society for Economic Dynamics. <a href="#fnref:40" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:41" role="doc-endnote">
<p>Davenport, T. H., &amp; Beck, J. C. (2001). The attention economy. <em>Ubiquity, 2001</em>(May), 1-es. <a href="#fnref:41" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:42" role="doc-endnote">
<p>Geri, N., &amp; Geri, Y. (2011). <a href="http://www.inform.nu/Articles/Vol14/ISJv14p047-059Geri587.pdf">The Information Age Measurement Paradox: Collecting Too Much Data</a>. <em>Informing Sci. Int. J. an Emerg. Transdiscipl., 14</em>, 47-59. <a href="#fnref:42" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:43" role="doc-endnote">
<p>Woods, D. D., Patterson, E. S., &amp; Roth, E. M. (2002). <a href="https://apps.dtic.mil/sti/pdfs/ADA371142.pdf">Can we ever escape from data overload? A cognitive systems diagnosis</a>. <em>Cognition, Technology &amp; Work, 4</em>(1), 22-36. <a href="#fnref:43" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:44" role="doc-endnote">
<p>Kirsh, D. (2000). <a href="https://philarchive.org/archive/KIRAFT">A few thoughts on cognitive overload</a>. <a href="#fnref:44" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:45" role="doc-endnote">
<p>A portmanteau of information and intoxication. <a href="#fnref:45" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:46" role="doc-endnote">
<p>Bajari, P., Chernozhukov, V., Hortaçsu, A., &amp; Suzuki, J. (2018). <em><a href="https://www.nber.org/papers/w24334.pdf">The impact of big data on firm performance: An empirical investigation</a></em> (No. w24334). National Bureau of Economic Research. <a href="#fnref:46" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:47" role="doc-endnote">
<p>Varian, H. R. (2014). <a href="https://pubs.aeaweb.org/doi/pdfplus/10.1257/jep.28.2.3?&amp;utm_content=buffera0009&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer">Big data: New tricks for econometrics</a>. <em>Journal of Economic Perspectives, 28</em>(2), 3-28. <a href="#fnref:47" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:48" role="doc-endnote">
<p>Although a few years out of date, this presents a nice recap of some of the major vulnerability branding campaigns: Power, J. <a href="https://medium.com/threat-intel/bug-branding-heartbleed-14ef1a64047f">Celebrity vulnerabilities: A short history of bug branding</a> [Blog post]. <a href="#fnref:48" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:49" role="doc-endnote">
<p>The gross bamboozling of the general public by defenders (which involved bamboozling themselves) of the vulnerability hypetrain was called out two decades ago by <a href="https://en.wikipedia.org/wiki/Antisec_Movement">the Anti-sec Movement</a>. Unfortunately for end users, the movement failed. At this point, I do not think there is any hope of returning the hypetrain back to the station, as there are too many people who profit off from its perpetuation. <a href="#fnref:49" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:50" role="doc-endnote">
<p>Frazelle, J. (2019, July 23). <a href="https://blog.jessfraz.com/post/the-business-executives-guide-to-kubernetes/">The Business Executive&rsquo;s Guide to Kubernetes</a> [Blog Post]. <a href="#fnref:50" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:51" role="doc-endnote">
<p>Again, as noted by the Anti-sec Movement many years ago, it seems somewhat ridiculous that we hand over exploits to skidiots* who barely know what they are doing. As someone who I have completely forgotten suggested, the first major “cybergeddon” attack against critical infrastructure will likely be at the hands of a script kiddy who stumbled upon the system via Shodan and does not even realize its importance before trying some cool shit out with Metasploit. (*credits to @r00tkillah for the term “skidiots”). <a href="#fnref:51" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:52" role="doc-endnote">
<p>To be clear, software engineers are not immune from this phenomenon, which could be called FOMOps or #fomodev, although it is out of scope of this blog post. Consider engineers who see a new shiny library or other trendy software thingamajigger on HackerNews and decide that their current systems are now so tragically unfashionable that a makeover is required ASAP, despite “legacy” options offering a superior fit with the organization’s operational needs. <a href="#fnref:52" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:53" role="doc-endnote">
<p>Federal Trade Commission. (2019, July 22). <em><a href="https://www.ftc.gov/news-events/press-releases/2019/07/equifax-pay-575-million-part-settlement-ftc-cfpb-states-related">Equifax to Pay $575 Million as Part of Settlement with FTC, CFPB, and States Related to 2017 Data Breach</a></em> [Press Release]. <a href="#fnref:53" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:54" role="doc-endnote">
<p>U.S. House of Representatives Committee on Oversight and Government Reform. (2018, December). <em><a href="https://republicans-oversight.house.gov/wp-content/uploads/2018/12/Equifax-Report.pdf">The Equifax Data Breach: Majority Staff Report, 115th Congress</a></em> [Report]. <a href="#fnref:54" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:55" role="doc-endnote">
<p>Riordan, B. C., Flett, J. A., Hunter, J. A., Scarf, D., &amp; Conner, T. S. (2015). <a href="https://www.researchgate.net/profile/Damian_Scarf/publication/283298745_Fear_of_Missing_Out_FoMO_The_relationship_between_FoMO_alcohol_use_and_alcohol-related_consequences_in_college_students/links/5653fb7608aefe619b1979dc/Fear-of-Missing-Out-FoMO-The-relationship-between-FoMO-alcohol-use-and-alcohol-related-consequences-in-college-students.pdf">Fear of missing out (FoMO): The relationship between FoMO, alcohol use, and alcohol-related consequences in college students</a>. <em>Annals of Neuroscience and Psychology, 2</em>(7), 1-7. <a href="#fnref:55" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:56" role="doc-endnote">
<p>Przybylski, A. K., Murayama, K., DeHaan, C. R., &amp; Gladwell, V. (2013). <a href="https://d1wqtxts1xzle7.cloudfront.net/44255710/Motivational_emotional_and_behavioral_co20160331-27397-tg2tl4.pdf?1459425071=&amp;response-content-disposition=inline%3B+filename%3DMotivational_emotional_and_behavioral_co.pdf&amp;Expires=1599944939&amp;Signature=RT2B0JbUIFMyn1HNjMa73qXkeiwX7ZTudu3557AnHsF4Pq8lilkcWW9SfxfONxj3E9L2uP5d9hBzeF~aYyapP0YmEDrzH0Fh4MCITn81x~xdQq9766j1QcN76QBzcGwOSIjNskPSQSG1M63Ug3kKk8xjizwJcPbWDya2aCycEZFMaumyYNtdoLGHBq0DbDtRjo9Ma9VSa6f~stesO35vb~CEysTtVYt1YPbNT02F47tBzgVxOHJf4cqbHKdPC0K7HX-q6FKTRr~nWJ5aulOvc8j2uiYl8O6t9tOYd~d1za87FIvrdmAtQu9TPNn4O934zScXb9hntVvbl6CAArBniw__&amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA">Motivational, emotional, and behavioral correlates of fear of missing out</a>. <em>Computers in Human Behavior, 29</em>(4), 1841-1848. <a href="#fnref:56" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:57" role="doc-endnote">
<p>Budnick, C. J., Rogers, A. P., &amp; Barber, L. K. (2020). The fear of missing out at work: examining costs and benefits to employee health and motivation. <em>Computers in Human Behavior, 104</em>, 106161. <a href="#fnref:57" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:58" role="doc-endnote">
<p>To clarify, the identity of “builder” is explicitly <em>not</em> about taking pride in building your own SIEM, or log ingestion pipeline, or whatever other wheel security people maintain a predilection for reinventing. <a href="#fnref:58" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:59" role="doc-endnote">
<p>The next most obvious alternative is to co-opt the identity of “breaker” with attackers and vulnerability researchers. This is likely seen more frequently than the co-opting of “builder,” perhaps as evidenced by attempts at building red teams at organizations who have yet to master security “basics” as well as the legions of security engineers who lament the defensive parts of their role and yearn for more offense research time. Breaking can be valuable with the appropriate feedback loops in place, but an honest appraisal of infosec professionals’ desire to break things would assuredly surface interest- and ego-based motivations rather than a motivation to improve software quality internally. <a href="#fnref:59" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content>
        </item>
        
        <item>
            <title>Infosec Buzzword Bingo: All Editions</title>
            <link>https://swagitda.com/blog/posts/buzzword-bingo-all-editions/</link>
            <pubDate>Wed, 05 Aug 2020 12:47:37 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/buzzword-bingo-all-editions/</guid>
            <description>Every edition of Infosec Startup Buzzword Bingo thus far (2017 through 2020).</description>
            <content type="html"><![CDATA[<p>Every year, I attempt to distill the infosec zeitgeist into a bingo card filled with all the obnoxious, flamboyant, and inane buzzwords permeating the industry. This blog post includes all editions of the bingo card for your amusement and / or existential crises, and will be updated annually.</p>
<h2 id="2020-infosec-buzzword-bingo-card">2020 Infosec Buzzword Bingo Card</h2>
<p>See <a href="https://www.vice.com/en_us/article/epgp9j/infosec-buzzword-bingo-2020-edition">my article in VICE Motherboard</a> for detailed analysis.</p>
<p><img src="/blog/img/infosec-startup-buzzword-bingo-2020.png" alt="Infosec Startup Buzzword Bingo card for 2020"></p>
<h2 id="2019-infosec-buzzword-bingo-card">2019 Infosec Buzzword Bingo Card</h2>
<p>See <a href="https://swagitda.com/blog/posts/infosec-buzzword-bingo-2019-edition/">my blog post</a> for detailed analysis.</p>
<p><img src="/blog/img/infosec-startup-bingo-2019.png" alt="Infosec Startup Buzzword Bingo card for 2019"></p>
<h2 id="2018-infosec-buzzword-bingo-card">2018 Infosec Buzzword Bingo Card</h2>
<p><img src="/blog/img/infosec-startup-buzzword-bingo-2018.png" alt="Infosec Startup Buzzword Bingo card for 2018"></p>
<h2 id="2017-infosec-buzzword-bingo-card">2017 Infosec Buzzword Bingo Card</h2>
<p>It all started with <a href="https://twitter.com/swagitda_/status/912494974779973632">a Tweet</a>.
<img src="/blog/img/infosec-startup-buzzword-bingo-2017.png" alt="Infosec Startup Buzzword Bingo card for 2017"></p>
]]></content>
        </item>
        
        <item>
            <title>Resilience in Security 101</title>
            <link>https://swagitda.com/blog/posts/resilience-in-security-101/</link>
            <pubDate>Mon, 18 May 2020 20:00:41 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/resilience-in-security-101/</guid>
            <description>A short primer on what resilience means in information security, intended as a resilience 101 resource for people who build, maintain, and secure systems or lead teams who do.</description>
            <content type="html"><![CDATA[<p>This post highlights the key things you need to know about what resilience means in an information security context. It’s intended to serve as a 101 for people involved in building, maintaining, and securing systems.</p>
<p>It&rsquo;s also meant to serve as an antidote for the recent twisting of the term by self-serving vendors and #thotleaders who are blisteringly unaware of the decades of research outside of infosec on the topic.</p>
<blockquote>
<p>tl;dr &ndash; Resilience in security means a flexible system that can absorb an attack and reorganize around the threat.</p>
</blockquote>
<hr>
<h2 id="the-basics-of-resilience-in-infosec">The basics of resilience in infosec</h2>
<p>Resilience in information security (and in other domains) consists of three characteristics: robustness, adaptability, and transformability.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p><strong>Robustness</strong> = withstanding and resisting a negative event. Think of this as your systems’ ability to prevent or block pwnage.</p>
<p><strong>Adaptability</strong> = managing your current systems' response to negative events. Think of this as minimizing event impact in your systems, optimizing for system recovery, and minimizing friction involved in changing your systems.</p>
<p><strong>Transformability</strong> = reorganizing your system in response to updated assumptions. Think of this as moving to a new system configuration or trajectory when existing conditions are indefensible.</p>
<hr>
<h2 id="once-more-but-less-abstractly">Once more, but less abstractly</h2>
<p>Let’s walk through a brief practical example to show how each of these characteristics of resilience work together.</p>
<p>Your organization delivers a PHP application to customers. You use inline PHP code within the HTML of your web apps to perform database queries. An injection vulnerability is found in an instance of this inline PHP code.</p>
<p><strong>Robustness</strong> manifests as implementation of a web application firewall to stop exploitation of the vuln, along with patching that instance of the vuln. These actions return things to “normal” – the prevailing status quo before discovery of the vuln (the negative event).</p>
<p><strong>Adaptability</strong> manifests as removing inline queries from the application, then replacing them with one class that accesses the database and is responsible for all sanitization. This reduces potential incident impact and, by only requiring issues to be fixed in one place, minimizes friction involved in changing the system going forward.</p>
<p><strong>Transformability</strong> manifests as re-architecting the application in a different language, like Java, to solve PHP’s endemic security problems. Evidence from application monitoring or publicly-disclosed vulnerabilities in PHP leads to updated assumptions about PHP’s suitability for the application. These assumptions motivate revision of previous choices that result in reorganization of the system to optimize for the evolving reality.</p>
<p>Piecing it together, these activities result in a more flexibly-designed application that can absorb an attack and be reorganized based on its evolving threat context.</p>
<hr>
<h2 id="what-most-of-the-industry-gets-wrong">What most of the industry gets wrong</h2>
<ol>
<li>
<p><strong>Robustness does not equal resilience.</strong> Robustness is insufficient on its own to foster resilience. Prevention is not resilience. Prevention is insufficient on its own to foster resilience. Being able to block or withstand an attack is not resilience. Being able to block or withstand an attack is insufficient on its own to foster resilience.</p>
<p>I am spelling this out as plainly as I can because I see this misconception all the time now. Resilience is being used as a substitution for robustness, prevention, and “stopping threats” by marketing teams to make their stale pitches feel fresh again. Don’t be bamboozled by these misleading claims.</p>
<p>If you want to understand more why this is such a dangerous conflation, read <a href="https://swagitda.com/blog/posts/red-pill-of-resilience-infosec/#robustness">the Robustness section</a> in my keynote on resilience.</p>
</li>
<li>
<p><strong>Resilience is not a tech stack or set of tools.</strong> Given people still think DevOps is achieved by implementing a certain tech stack, I don’t hold much faith that people will let go of similar notions about resilience. Just like DevOps, resilience is a set of principles and practices. It’s an approach that aims to help you evolve your security as your environment and context evolves.</p>
<p>Certain tools can support your resilience practices &ndash; such as transformability via migrating systems from on-prem to the cloud &ndash; but you will not be able to “do resilience” just by purchasing tech.</p>
</li>
</ol>
<hr>
<h2 id="in-conclusion">In Conclusion</h2>
<p>I’ll repeat my definition again: Resilience in security means a flexible system that can absorb an attack and reorganize around the threat.</p>
<p>I firmly believe resilience is the future of information security. Alas, the term is actively being bastardized by some vendors to serve their pestilent purposes. To the practitioners reading (whether you build systems or secure systems), remember that attackers are continuously evolving their methods based on changing context, and it is imperative for you to evolve your methods, too.</p>
<p>Adopting a resilience approach will help you survive – and hopefully even thrive – in this dynamic digital world of ours.</p>
<hr>
<hr>
<p>Thanks to my engineering and security friends for their feedback on drafts, especially Camille, James, and Vladimir!</p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>I recommend reading the seminal paper <a href="https://www.ecologyandsociety.org/vol9/iss2/art5/">&ldquo;Resilience, adaptability and transformability in social–ecological systems&rdquo;</a> by B Walker, CS Holling, SR Carpenter, A Kinzig (2004).</p>
<p>For a longer discussion about resilience in infosec, check out the <a href="https://swagitda.com/blog/posts/red-pill-of-resilience-infosec/">full text of my keynote</a> on the topic from 2017. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content>
        </item>
        
        <item>
            <title>Kelly&#39;s Hierarchy of Security Product Needs &amp; Vendor Selection v1.0</title>
            <link>https://swagitda.com/blog/posts/kellys-hierarchy-of-security-product-needs/</link>
            <pubDate>Tue, 05 May 2020 07:57:42 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/kellys-hierarchy-of-security-product-needs/</guid>
            <description>A look at the infosec industry&amp;rsquo;s hierarchy of product needs and what drives vendor selection. #antisec</description>
            <content type="html"><![CDATA[<p><img src="/blog/img/hierarchy-infosec-product-needs-2020.png" alt="A triangle, similar to Maslow&rsquo;s hierarchy of needs, but for infosec. Starting at the bottom, the first row includes: single PAIN of glass, AI / Deep Learning / Galactic Magic, less than 100 percent false positive rate, STOPS ALL ZERO DAY, introduces 0day, founded in Silly Valley or Tel Aviv. The second row includes: celeb meet and greet at RSA, Gartner sycophant (crossed out) vassal (crossed out) Magic Quadrant Leader, NBAD / SINBAD. The third row includes: acquired by Cisco or Palo Alto Networks, PERIMETER DEFENSE BUT CLOUD, friend is on the advisory board, sent you a free Apple Watch for a demo. The fourth row includes: published a branded vulnerability, business plan or child&rsquo;s fingerpaint art?, AI less accurate than nested if statements, feature as a product. The fifth row includes: security posture chiropractor, solves the OWASP top 10, less painful than a swarm of literal wasps, the Miss Cleo of Cyber. The sixth row includes: 60 percent of the time, it works every time. The seventh row includes: MITRE ATT&CK namedrop, whatever tf platform means, outlining clouds in crayon as asset management. The eighth row includes: has a zero trust whitepaper, greater than 10 percent not-a-white-dudes on the leadership team. The ninth row includes: next-gen, &ldquo;Shift Left,&rdquo; enterprise-grade. The tenth row includes: threat model being addressed isn&rsquo;t from a DMT trip, subscription model. The eleventh row includes: will be obsolete after re:Invent or Cloud Next. The twelfth row includes: FUD-free marketing, UX that isn&rsquo;t just demoware. The thirteenth row includes: IAM as the new perimeter. The fourteenth row includes: doesn&rsquo;t cause a kernel panic. The fifteenth row includes: helps satisfy SOC2. The sixteenth row includes: resilience. The seventeenth row includes: developers don&rsquo;t hate it. The eighteenth row includes: product works. There is also an eye with a hot pink iris and a hexagram pupil at the top, for flare."></p>
<p>What more is there to say, really?</p>
<hr>
<p>Thanks to Chris Hoff in 2013 for the <a href="https://www.rationalsurvivability.com/blog/2013/11/maslows-hierarchy-of-security-product-needs-vendor-selection/">original inspiration</a>.</p>
]]></content>
        </item>
        
        <item>
            <title>Shall We Play a Coordination Game?</title>
            <link>https://swagitda.com/blog/posts/shall-we-play-a-coordination-game/</link>
            <pubDate>Wed, 08 Apr 2020 20:22:57 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/shall-we-play-a-coordination-game/</guid>
            <description>Examining the relationship between enterprise security and DevOps teams through the lens of game theory, specifically coordinative games.</description>
            <content type="html"><![CDATA[<p><img src="/blog/img/coordination-game.png" alt="An interface in the style of War Games asking if you want to play chess, fighter combat, theaterwide tactical warfare, or cooperative game theory"></p>
<blockquote>
<p>&ldquo;The seasons change; and both of us lose our harvests for want of mutual confidence and security.” – David Hume, A Treatise on Human Nature</p>
</blockquote>
<p><a href="https://swagitda.com/blog/posts/security-as-a-product/">As I expounded before</a>, security should be treated as a product – as “something created through a process that provides benefits” to the organization. Every product has a purpose, something it is trying to help its users accomplish. If security is a product, what is its purpose? What is it trying to help its users – the organization – accomplish? Without this purpose, security can become aimless – falling into the wretched trap of “security for its own sake.”</p>
<p>If we treat security instead as a business enabler, what results? In many tech organizations, the most critical business enabler is software delivery performance. Therefore, security should cooperate with relevant stakeholders who focus on software delivery performance, especially the engineering organization (colloquially known as the DevOps function).</p>
<p>As is well-discussed in the industry, the relationship between security and DevOps is typically described as fraught, icy, or adversarial – a far cry from cooperative, let alone collaborative. There are cultural reasons for this, but I will not be covering them in this post. Instead, I am going to draw on behavioral economics, looking both to cooperation games within game theory and the concept of moral hazard as a lens through which we can better understand the security and DevOps relationship.</p>
<p>So, shall we play a coordination game? Let&rsquo;s dive in.</p>
<hr>
<h1 id="barriers-to-cooperation">Barriers to Cooperation</h1>
<h2 id="cooperation-games">Cooperation Games</h2>
<p>Most relationships in life can be considered through the concept of “games,” behavioral relationships between decision-makers involving certain rules or conditions. It is worth exploring the different potential attributes of games as a backdrop for how to think about the game infosec plays with its DevOps peers.</p>
<p>Games can involve cooperation or non-cooperation. Non-cooperative games involve competition between the game’s players, without any sort of external authority to enforce cooperation between the players – resulting in no chance for alliance. The game between attackers and defenders can be considered a non-cooperative game. Cooperative games, unsurprisingly, involve cooperation rather than competition. Players can form coalitions to coordinate their strategies and share potential payoffs<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup>. One of the more famous cooperation games is the Prisoner’s Dilemma, a non-zero-sum cooperation game in which two prisoners must make the decision to confess or stay silent.</p>
<p>What is a non-zero-sum game? In zero sum games, the total payoffs for all players in the game add up to zero. That is, one player’s gain will equal the other player’s loss exactly. Few real-world scenarios involve zero-sum games, but the game poker is an example of one. Non-zero-sum games are thus games in which the total payoffs for all players do not add up to zero – that the gain by one player does not result in an equivalent loss by the other player. Free-trade is an example of a non-zero-sum game in which all players can benefit in a win-win scenario. The aforementioned Prisoner’s Dilemma is non-zero-sum, as it can result in a win-win or lose-lose scenario.</p>
<p>Information is an essential component of every game, as information is at the heart of strategic interaction – particularly information regarding other player’s decision-making in the game. In perfect information games, all players know all decisions previously made by the other players. As you might suspect, real-life rarely allows such omniscience, outside of games like tic-tac-toe or chess. Imperfect information is common to our existence, wherein players cannot see all prior decision-making by the other players within the game.</p>
<p>Complete and incomplete information is another informational characteristic of games. In a game with complete information, players understand the potential payoffs, risk tolerances, strategies, and player “types” among other players. Again, complete information is largely unrealistic in the real-world. Instead, games with incomplete information are most common in human interaction, wherein players cannot discern other players’ preferences, motivations, and other strategic information.</p>
<p>Although it may scandalize true game theorists, for perspicuity&rsquo;s sake, I will summarize these information-based characteristics into the concept of information asymmetry – that players possess relevant information to which the other players do not have access. Typically, information asymmetry is analyzed through the lens of transactions, though I argue it all comes back to decision-making between relevant players.</p>
<p>I believe one can view DevOps and infosec’s relationship as a coordination game with information asymmetry. I do not believe it is a non-cooperation game, as there is ample room for infosec and DevOps to form a coalition, and there is potential for the organization to serve as an external enforcer of cooperation. There is also information asymmetry, as neither DevOps nor infosec has perfect insight into the other’s decision-making process nor access to all relevant information (much of which might be tacit and considered tribal knowledge).</p>
<p>If we proceed with the assumption that DevOps and infosec’s relationship is a coordination game, then our goal is to understand how to encourage cooperation to maximize the collective payoff. This results in a crucial question: what leads to coordination failures? One impetus is strategic uncertainty among players, that they do not realize their objectives are aligned. Perhaps obviously, misalignment of objectives can also present friction in cooperation games. Thus, mechanisms are needed either to facilitate cooperation – in the event of aligned preferences – or enforce cooperation – in the event of less aligned preferences.</p>
<p>Interestingly, empirical evidence suggests that humans are far more cooperative by nature than traditional game theory predicts. In fact, the wealth of data points showing cooperation within games far exceeding predicted values has led scholars to delve into the nature of cooperation, seeking an answer to why this pattern holds. There is a split among those who seek to prove that cooperation still fits within the confines of rational behavior, and those who argue that cooperation represents more of a strategic irrationality – the philosophical nuance of which I will not cover here.</p>
<p>Despite humans being cooperative by nature, there are potential wrinkles that can come when decision-making power and information possession are unequal – known as moral hazard, which we will explore presently.</p>
<h2 id="moral-hazard">Moral Hazard</h2>
<p>Moral hazard results when someone increases their risk exposure because they are protected from risk impact in some way. It is related to the principal-agent problem, in which someone (the agent) can make decisions on behalf of another person (the principal), leading to the potential for self-interested actions by the agent that are not in the interests of their principal. Information asymmetry exacerbates moral hazard issues, since one party possessing information the other party cannot access creates an incentive for exploitation.</p>
<p>A tangible example of moral hazard is in insurance. If you received an insurance policy with full coverage for all potential losses due to security incidents, theory suggests you will have less of an incentive to invest in a strong security program. The insurance provider may assume you will maintain your current level of protection, but you possess information secret to them – that you have no intention of doing so. Thus, you are willing to accept more risk because you are protected from the risk impact, potentially empowering you to pursue a #yolosec strategy<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<p>Looking to infosec and DevOps, there is the potential for moral hazard given the team structure at most organizations. DevOps can increase their exposure to security-related risk because they are not held accountable for it, making the infosec team bear the risk impact. DevOps can likewise possess hidden motivations or take hidden action from the vantage point of the security team, as not all efforts to secure systems will be observable by infosec. This makes it difficult for infosec to manage the organization’s risk exposure – and thus the ability to manage the risk impact they experience.</p>
<p>I believe moral hazard goes both ways in this relationship, however. Infosec can also increase risk exposure for the rest of the organization – but risk of a different kind. Part of infosec’s infamy is due to creating policies or implementing tools that add risk to their colleagues’ workflows, such as a salesperson wrestling with a clunky VPN when trying to close a deal with a customer. Because infosec is shielded from the risk resulting from friction to their organizational peers’ workflows, they are more willing to add such risk in the name of their own priority: security.</p>
<p>Moral hazard is particularly relevant when considering conflicting goals. Very recent research suggests that decision-makers resolve goal conflicts on behalf of others differently than they would for themselves, potentially resulting in undesirable outcomes for the recipients of the decision. But, first, what defines goal conflict? It is when achieving one goal prohibits or discourages the achievement of another goal. Unless there is the option to satisfy both goals (more on this later), people will only “activate” the higher priority goal.</p>
<p>One study examined moral hazard and goal conflict through the lens of health practitioners choosing between curative care or <a href="https://en.wikipedia.org/wiki/Palliative_care">palliative care</a> for their patients<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>. Health practitioners typically prioritize the goal of curative care over palliative care, believing the two are in conflict. What makes this context interesting is widespread evidence that these two goals are not actually in conflict. Palliative care can extend lifespan; but at the very least, it is not shown to interfere with curative care.</p>
<p>Why do health practitioners believe these goals are in conflict, and why do they opt for curative care rather than improving patient comfort and pain reduction? The problem lies in moral hazard – that people focus on potential gains and perceive fewer risks when making decisions for others rather than themselves<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>, and these choices tend to be more creative and idealistic. People can also justify these choices by telling themselves that there are fewer tradeoffs than there are – pretending that it is an easier decision to make.</p>
<p>Another reason behind this errant goal conflict resolution lies in identity. Healthcare providers take pride in being able to solve medical problems, and curative care reinforces that identity. Palliative care, however, can be threatening to this identity, perceived as a form of “giving up.”<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> Infosec professionals also take pride in their ability to stop threats and to solve security problems, and accepting risk or compromising can be likewise seen as giving up.</p>
<p>The process by which people accomplish multiple goals can also present challenges in an organizational context. Goals can either be pursued sequentially or concurrently. Sequential goal pursuit allocates resources to one goal at a time, only switching attention to an alternative goal once sufficient progress is perceived. Concurrent goal pursuit directs attention to more than one goal at a time, determining a single choice that can satisfy multiple goals (the “killing two birds with one stone” strategy).</p>
<p>There are benefits of each strategy along the spectrum of sequential to concurrent goal pursuit. “Goal shielding” is the primary mechanism of sequential goal pursuit, wherein alternative goals are inhibited to avoid interfering with pursuit of the primary goal – and it has been found to increase successful goal progress<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>. The multifinality principle is the primary mechanism of concurrent goal pursuit, wherein a single means is used to satisfy multiple goals – and it has been found to boost efficiency of goal achievement<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup>.</p>
<p>There are downsides to each end of the spectrum, as well. Sequential goal pursuit means that accomplishing multiple goals can take more time. It can also lead to a false sense of security, as seen in a weight management scenario. In one study, those who believed they had made meaningful progress towards their weight goal were more likely to dig into unhealthy food than those who felt that their progress was wanting<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>. Sequential pursuit also allows the excuse of “I’ll do it later,” when “later” never seems to materialize.</p>
<p>Most with experience in information security have assuredly seen examples of the “I’ll do it later” issue, that certain goals are never achieved and continually pushed off. The false sense of security in the weight management case also manifests in infosec in a few ways, but primarily through the seductive delusion that a series of solid security choices means that security concerns can be ignored for a time, or that enough progress was made on security while ignoring the need for continuous maintenance (let alone improvement).</p>
<p>Concurrent goal pursuit requires a readily-available solution capable of satisfying multiple goals at the same time, which is not always possible. What’s more, these magical solutions end up being discounted due to their versatility. For instance, when people were asked to think of three goals a computer serves in a study, they perceived that the computer was less important to accomplishing those goals as when they were asked to think of only one goal a computer serves<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup>. While a computer is seen as essential for the sole task of checking email, it is perceived as less critical for checking email when considered alongside the goals of using a search engine or browsing an online publication. Thus, concurrent goal pursuit can save time, but can potentially lead to the feeling of less being accomplished.</p>
<p>This curious effect, known as the “dilution of instrumentality,” is considered decidedly irrational, entirely based on people’s mental models rather than objective evidence of how a course of action can serve multiple goals. I believe this is commonly seen in infosec when evaluating solutions that can help both infosec and DevOps – that any course of action or means to an end that can solve use cases on both sides must not be a very good or powerful one.</p>
<p>Of course, in the context of enterprise security, there is not just one individual pursuing goals. Let us now dive into the concept of team reasoning to better understand the nature of collaborative goal pursuit.</p>
<h2 id="team-reasoning">Team Reasoning</h2>
<p>Team reasoning is an emerging theory<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> that allows for a group of players within a game to represent a single player, postulating that team members aim to achieve common interests, rather than fulfilling their individual self-interest. As Sugden, one of the parents of the theory, would say, team reasoning represents “intentional cooperation for mutual benefit.” It is commonly referred to as “we thinking” or “joint intentionality” in the literature, and is considered a conceptual kin to “collective intentionality” from the realm of philosophy.<sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup></p>
<p>There is ample experimental evidence suggesting that team reasoning serves as a more accurate theoretical framework than traditional game theory. For example, one study conducted five game types and found that across all games, a majority of players eschewed the individually rational strategy and opted instead for the collectively rational strategy – the one that maximized the group’s payoff<sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>. An earlier study demonstrated that players specifically identified “focal points” – targets that naturally stand out – that facilitated coordination<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup>.</p>
<p>An intuitive reason for cooperation is that we derive value from helping those with whom we identify. On the flip side, if we view the players in a cooperative game as “the others,” we are less likely to cooperate. An imperative ingredient to foster collaboration is encouraging the shift from an individual mindset to a group mindset – to consider what the group’s goals are and what part the individual should play in achieving those goals<sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup>. Naturally, the path to this shift to a collective perspective is not so simple as telling the individual to start thinking in that way.</p>
<p>One method to improve this so-called group identification is by making it <a href="https://en.wikipedia.org/wiki/Salience_%28neuroscience%29">salient</a> – the behavioral economics term for making a piece of data more readily accessible and more prominent. For instance, I could encourage group identification among blonde people by telling an all-blonde group that I am conducting an experiment to compare brunettes versus blondes.</p>
<p>Regrettably, from what I have witnessed regarding infosec and DevOps’ relationship (or lack thereof), there is almost a point of pride among each group for being distinct. I certainly do not believe that increasing salience of group identification between the two will fix tension among infosec and DevOps – but it does seem like an important step worth attempting. In any projects or important decision-making meetings, increasing salience by emphasizing that you, collectively, are the core of the organization’s technology group – party members on the imperative quest of ensuring safe software delivery performance – can perhaps remind everyone more of the collective similarities rather than differences. Even more compellingly, this effect can be magnified if you emphasize the true “other.”</p>
<p>Emphasizing potential negative outcomes due to a group of “others” dissimilar from your group (as a compliment to espousing the potential positive outcomes due to group collaboration) offers potent results, backed by experimental evidence.<sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup> This is known as “perceived interdependence,” achieved by framing the situation as one in which the group needs each other in the face of dissimilar “others” who might seek to harm them.</p>
<p>Luckily, it is not a stretch to present organizational defense in this light. Relative to attackers, infosec should lie squarely in the “in-group” for DevOps – despite their perceived antagonistic qualities otherwise. With that said, there may be perception that security is a more harrowing threat to DevOps than attackers, particularly if DevOps was relatively shielded from incidents in the past, because security stymies their work far more acutely. Hence, I believe attempting group salience alone to fix coordination issues is likely to product mixed results in the vexed realm of infosec and DevOps relations.</p>
<p>Leveraging salience in other ways may prove more fruitful, however. Experimental evidence indicates that making the joint goal salient makes team reasoning more likely to occur<sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup>. Unfortunately, in many games, payoffs are asymmetric, meaning one player or group receives a greater reward for success than their co-player or co-group. Such asymmetry can result in miscoordination, because players find the payoff factor more salient and begin to act more competitively. For instance, in one experiment, games with symmetric payoffs resulted in a 93% cooperation rate, while games with even small asymmetric payoffs dropped to a 49% coordination rate<sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>.</p>
<p>At most organizations, payoffs for infosec and DevOps will be largely unknown, as most compensation information is private. However, perceived payoffs for success might result in greater miscoordination – and it will most likely take the form of infosec feeling less rewarded than DevOps, if I were to hazard a guess. These rewards are not necessarily monetary, either. The disparity in payoffs between DevOps and infosec is perhaps highest in social rewards, namely social recognition.</p>
<p>One all too common scenario is that infosec may insist on a fix of a critical vulnerability shortly before an anticipated release, requiring last minute scrambling by DevOps to unblock the release. DevOps may be rewarded for these efforts, which might have been avoided by fixing the vulnerability when it was first discovered by the infosec team, rather than ignoring or denying it. Infosec, however, is more likely to be chided than noted for their contributions.</p>
<p>A potential counter is to publicly state equal rewards for certain joint goals, such as mean time to remediation or, more contentiously, fewer vulnerabilities introduced into production, so that this data point regarding payoffs becomes most salient. Again, these rewards do not have to be monetary, but should involve joint recognition at an organizational level. With that said, emphasizing “label salience” – accentuating group salience, as discussed before – may also serve as a deterrence from payoff salience, so experimentation is recommended.</p>
<p>When emphasizing joint payoffs, the payoff matrix for a game changes, as shown below. The new, “we-thinking” payoff matrix illustrates why the theory of team reasoning can still easily support the notion of rationality, as it makes perfect sense for a player to choose a payoff-maximizing strategy:</p>
<p><img src="/blog/img/payoff-matrix.png" alt="A payoff matrix showing how combining individual payoffs via team reasoning promotes cooperation. The original individual payoffs were (3,3) for cooperating, (0,5) for one player defecting, and (1,1) for both defecting. In the team reasoning payoff matrix, the payoff for cooperation is (6), one defection (5), and joint defection (2)."></p>
<p>By visualizing team reasoning through this payoff matrix, its value in promoting coordination becomes palpable. This serves as the perfect starting point for contemplating how we can win the coordination game.</p>
<hr>
<h1 id="facilitating-cooperation">Facilitating Cooperation</h1>
<p>In the course of my research, I did not encounter a single organization where DevOps and infosec codified guidelines for how they should interact – or even documented their collective objectives. As I will discuss in this section, choosing the right goals and publicizing them in the right way is essential to facilitate cooperation.</p>
<h2 id="team-reasoning-1">Team Reasoning</h2>
<p>One notable and highly relevant experiment involves the centipede game, from Lambsdorff, et al.<sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup> The centipede game is a multi-stage trust game in which players alternate offers. For instance, in the first round, I could receive $10 while you receive $2, or I could pass the choice over to you to double each amount – giving you the choice of receiving $20 and me receiving $4, or passing it back to me to double the amounts again. This game structure is useful for exploring the reciprocal nature of cooperation, as the subgame perfect Nash equilibrium (i.e. what the rational player “should” play) is for the players to never pass.</p>
<p>The empirical evidence starkly differs from the theoretically rational strategy, with a majority of players passing in the first stage, and some even ending the game without anyone taking vs. passing. The results are even more elucidating when compared across the treatments the experimenters created. In one treatment, the game’s payoffs were presented in probabilistic terms, showing the probability of achieving a joint goal rather than individual payoffs. In the other treatment, the game was presented through a soccer analogy, where passing offers was seen through the lens of passing the ball to score a goal.</p>
<p>In games where the number of passes could lie between 0 or 2 for each player, the average number of passes in the probabilistic treatment was approximately 1.5, and for the soccer treatment approximately 1.9 passes. Both averages are substantially higher than the average for the vanilla version of the centipede game – approximately 1.2 passes – and, strikingly, much higher than the perfect Nash equilibrium of 0 passes. Why did these alternative game treatments succeed? The probabilistic treatment was successful in promoting cooperation due to emphasis on the shared goal, removing the salience of the payoff asymmetry (as discussed in the prior section).</p>
<p>What led the soccer treatment to be most effective? The researchers believe it is because the soccer analogy made the joint goal obvious, thereby making the team identity salient. This not only is supportive of the theory of team reasoning, but also perhaps supports the practice common among the stereotypical former-jock sales leaders of using sportsball analogies to foster team spirit and motivation. While I remain somewhat skeptical of the efficacy of sports analogies on engineers, I believe similar levels of salience for group identity can be accomplished and provide similar results in improving cooperation.</p>
<p>What else can these results suggest for the relationship between DevOps and infosec? One is that controls targeting individuals for infractions – for instance, punishing individual developers for security bugs – may be less effective than sharing security-enhancing goals at a group level. Further, emphasizing differences between groups is less effective in improving conflict resolution than emphasizing joint goals. This perhaps is where infosec culture fails the most – presenting a draconian notion of infosec vs. normies and declaring that infosec is a misunderstood, maligned clique that is the gatekeeper of secure practices.</p>
<h2 id="outcome--process-goals">Outcome &amp; Process Goals</h2>
<p>Another set of tools for our conceptual arsenal is found in outcome and process goals. Outcome accountability prioritizes people getting things right. Process accountability prioritizes people thinking in the right way. I am a huge proponent for focusing on outcomes rather than outputs, particularly when it comes to measuring success – because lots of aimless creation is not useful, but <em>impactful</em> creation is. Nevertheless, there are caveats to outcome accountability, regarding what it incentivizes, that are necessary to explore before people jump on the outcome bandwagon and fully abandon process accountability.</p>
<p>Outcome accountability is beneficial in incentivizing realization of expected outcomes when making decisions. There is experimental evidence showing that outcome accountability boosts performance relative to process accountability alone.<sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup> However, this can ignore analysis of whether the decision itself was appropriate or not. The potential hazards of outcome accountability include the worsening of overall decision quality, increasing commitment to sunk costs, diminishing of complex thinking, impairment of attentiveness, and reduction of situational awareness<sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup>.</p>
<p>In short-term decision-making problems, outcome accountability can lead to analysis paralysis due to uncertainty, or succumbing to cognitive bias, thereby worsening decision quality. Process accountability, in contrast, can help temper the temptation of cognitive bias, helping decision-makers navigate choppy cognitive waters short-term. Further, in the aforementioned experiment, process accountability was shown to promote more effective knowledge sharing, boosting performance of those observing the decision-makers’ actions.</p>
<p>Process accountability, although already not as popular in Silicon Valley, has its deficiencies worth mentioning, too. Process accountability can incentivize adherence to policies and best practices, even when they are not the best options in dynamic environments long-term. It is inherently less flexible than outcome accountability, making it difficult to improvise and incorporate feedback loops to inform better strategy in changing environments. For example, process accountability was shown to be far weaker than outcome accountability in augmenting pilots’ skill in navigating changing environments<sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>.</p>
<p>Thus, a hybrid of outcome accountability and process accountability is optimal, balancing out weaknesses while not decreasing the respective benefits of each method. A hybrid of outcome goals and process goals should give teams the ability to remain flexible while ensuring knowledge transfer and inhibiting potential abuses of power. Importantly, this hybrid accountability can ensure that standard practices are met, but also encourage experimentation with novel strategies. This ensures collective knowledge is not discarded and adaptive prowess are not discouraged – both of which are essential components for designing secure systems and responding to incidents.</p>
<p>Creating stretch outcome goals can encourage innovation, allowing teams to stretch their metaphorical wings and attempt ambitious plans – tempered with the need to still be able to justify process. Stretch goals tend to also be more fun, satiating people’s curiosity and desire to learning new things. For example, a security-related stretch goal might be to create a tool to automate asset inventory management, whereas the basic goal may be to perform manual asset inventory management.</p>
<p>Importantly, process goals should apply equally to infosec and to DevOps. Infosec should justify why they made a less business-friendly decision – helping curb the FUD-driven decision-making to which infosec is prone. DevOps should justify why they made a less secure decision – helping curb the tendency to treat security as an afterthought. By forcing each team to articulate their justifications, it allows the opportunity to, as the kids say, call out bullshit.</p>
<h2 id="goal-framing">Goal Framing</h2>
<p>Finally, <em>how</em> these goals are communicated is consequential to winning the coordinative game. Drawing from the aforementioned study involving goal conflict between curative or palliative care, there are a few lessons to glean towards how to set goals. First, the study found that participants who received messaging emphasizing the conflicting nature of the goals reported increased perception of goal conflict and decreased importance of palliative care, as expected<sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup>.</p>
<p>Second, the researchers anticipated that self-affirmation and self-reflection on values – with the goal of ameliorating cognitive dissonance associated with maintaining conflicting beliefs – would improve providers’ abilities to empathize with patients, thereby increasing the importance of palliative care. Instead, the opposite was shown to be true. Unfortunately, self-affirmation can also deactivate less valued or more difficult goals, becoming a reinforcement mechanism for moral hazard-driven beliefs.</p>
<p>These results certainly seem discouraging! So, what can be done? The key takeaway is that goals must be presented as complementary rather than conflicting, particularly when there is evidence to support it (as is true with the complementary nature of palliative and curative care). When considering infosec and DevOps goals, I have long argued that their respective goals bear far more similarities than differences<sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>. Empirical analysis from the most recent “2019 Accelerate: State of DevOps” report also shows that elite DevOps teams fix security issues earlier and faster than their less performant peers<sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>.</p>
<p>We must also include the ordering of goals in our calculus here. Sequential goal pursuit is inevitable given the relative scarcity of solutions that can accomplish multiple goals, and in light of the tendency for people to prioritize one goal over another. However, concurrent goal pursuit can still be encouraged. DevOps and infosec teams can make a list of their respective goals and perform an exercise to brainstorm where goals from each side might be achieved through the same means. As an example, tools designed to collect data for performance use cases are collecting data valuable for security use cases as well.</p>
<p>To avoid the “dilution of instrumentality” – the perception that the stone is less important in killing the two birds, because it can kill both concurrently – highlight objective information about a choice, tying its importance to each goal directly. For instance, a database monitoring tool can help accomplish both performance and security goals, thus running the risk of invoking the dilution of instrumentality. To re-anchor perception to reality, you can express how the tool relates to each goal specifically: collecting data on resource utilization for performance, and detecting abnormal query behavior for security.</p>
<hr>
<h1 id="conclusion">Conclusion</h1>
<p>The relationship between DevOps and information security must be healthy for the business to thrive. This relationship, like all relationships, requires work, and understanding it as a cooperative game involving information asymmetry can inform how we can work smarter to nurture it. By leveraging team reasoning, hybrid goals (outcome and process), and framing goals as complementary and concurrent, we become a strong contender for winning this coordinative game.</p>
<p><img src="/blog/img/winning-cooperative-games.png" alt="An interface in the style of War Games declaring that &ldquo;you&rdquo; won by adopting the strategies of team reasoning, hybrid goals, and goal framing."></p>
<hr>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Lui, J. (2008). <em>CSC6480: Introduction to Game Theory: Cooperative Games</em> [PowerPoint slides]. Retrieved from <a href="http://www.cse.cuhk.edu.hk/~cslui/CSC6480/cooperative_game.pdf">http://www.cse.cuhk.edu.hk/~cslui/CSC6480/cooperative_game.pdf</a> <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>The invention of the term #yolosec is, perhaps, one of my crowning achievments within the infosec industry. <a href="https://swagitda.com/speaking/us-17-Shortridge-Big-Game-Theory-Hunting.pdf">See my 2017 Black Hat talk</a> for the use of it in context of attack trees (slide 77). <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p>Ferrer, R. A., Orehek, E., &amp; Padgett, L. S. (2018). Goal conflict when making decisions for others. <em>Journal of Experimental Social Psychology, 78</em>, 93-103. <a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p>Polman, E. (2012). Self–other decision making and loss aversion. <em>Organizational Behavior and Human Decision Processes, 119</em>(2), 141-150. <a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p>CAPC (2011). 2011 public opinion research on palliative care: A report based on research by public opinion strategies. Retrieved from <a href="https://media.capc.org/filer_public/18/ab/18ab708c-f835-4380-921d-fbf729702e36/2011-public-opinion-research-on-palliative-care.pdf">https://media.capc.org/filer_public/18/ab/18ab708c-f835-4380-921d-fbf729702e36/2011-public-opinion-research-on-palliative-care.pdf</a> <a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6" role="doc-endnote">
<p>Shah, J. Y., Friedman, R., &amp; Kruglanski, A. W. (2002). Forgetting all else: on the antecedents and consequences of goal shielding. <em>Journal of personality and social psychology, 83</em>(6), 1261. <a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7" role="doc-endnote">
<p>Orehek, E., &amp; Vazeou-Nieuwenhuis, A. (2013). Sequential and concurrent strategies of multiple goal pursuit. <em>Review of General Psychology, 17</em>(3), 339-349. <a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8" role="doc-endnote">
<p>Fishbach, A., &amp; Dhar, R. (2005). Goals as excuses or guides: The liberating effect of perceived goal progress on choice. <em>Journal of Consumer Research, 32</em>(3), 370-377. <a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9" role="doc-endnote">
<p>Zhang, Y., Fishbach, A., &amp; Kruglanski, A. W. (2007). The dilution model: How additional goals undermine the perceived instrumentality of a shared path. <em>Journal of personality and social psychology, 92</em>(3), 389. <a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10" role="doc-endnote">
<p>Team reasoning’s roots are with Sugden and Bacharach, both who first released papers in the 1990s on the topic – so it is quite a recent theory on a relative basis. <a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11" role="doc-endnote">
<p>Schweikard, D. P., &amp; Schmid, H. B. (2013). Collective intentionality. <a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12" role="doc-endnote">
<p>Colman, A. M., Pulford, B. D., &amp; Rose, J. (2008). Collective rationality in interactive decisions: Evidence for team reasoning. <em>Acta psychologica, 128</em>(2), 387-397. <a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13" role="doc-endnote">
<p>Mehta, J., Starmer, C., &amp; Sugden, R. (1994). The nature of salience: An experimental investigation of pure coordination games. <em>The American Economic Review, 84</em>(3), 658-673. <a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14" role="doc-endnote">
<p>Colman, A. M., &amp; Gold, N. (2018). Team reasoning: Solving the puzzle of coordination. <em>Psychonomic bulletin &amp; review, 25</em>(5), 1770-1783. <a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15" role="doc-endnote">
<p>Flippen, A. R., Hornstein, H. A., Siegal, W. E., &amp; Weitzman, E. A. (1996). A comparison of similarity and interdependence as triggers for in-group formation. <em>Personality and Social Psychology Bulletin, 22</em>(9), 882-893. <a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16" role="doc-endnote">
<p>One such example is in the study by Lambsdorff, et al. involving the centipede game, mentioned later in this piece. <a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17" role="doc-endnote">
<p>van Elten, J., &amp; Penczynski, S. P. (2018). Coordination games with asymmetric payoffs: An experimental study with intra-group communication. <em>Unpublished manuscript available at <a href="http://www.penczynski.de/attach/APC.pdf">http://www.penczynski.de/attach/APC.pdf</a></em>. <a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18" role="doc-endnote">
<p>Lambsdorff, J. G., Giamattei, M., Werner, K., &amp; Schubert, M. (2018). Team reasoning—Experimental evidence on cooperation from centipede games. <em>PloS one, 13</em>(11), e0206666. <a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19" role="doc-endnote">
<p>Chang, W., Atanasov, P., Patil, S., Mellers, B. A., &amp; Tetlock, P. E. (2017). Accountability and adaptive performance under uncertainty: A long-term view. <em>Judgment &amp; Decision Making, 12</em>(6). <a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20" role="doc-endnote">
<p>Scholars would call it reduction of “epistemic motivation.” <a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21" role="doc-endnote">
<p>Skitka, L. J., Mosier, K. L., &amp; Burdick, M. (1999). Does automation bias decision-making?. <em>International Journal of Human-Computer Studies, 51</em>(5), 991-1006. <a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22" role="doc-endnote">
<p>Ferrer, R. A., Orehek, E., &amp; Padgett, L. S. (2018). Goal conflict when making decisions for others. <em>Journal of Experimental Social Psychology, 78</em>, 93-103. <a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23" role="doc-endnote">
<p>Shortridge, K. (2018). Paint by Numbers: Measuring Resilience in Security. Retrieved from <a href="https://swagitda.com/speaking/Paint-by-Numbers-Resilience-in-Infosec-Kelly-Shortridge-AusCERT-2018.pdf">https://swagitda.com/speaking/Paint-by-Numbers-Resilience-in-Infosec-Kelly-Shortridge-AusCERT-2018.pdf</a> <a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24" role="doc-endnote">
<p>Forsgren, N., et al. (2019). 2019 Accelerate State of DevOps Report. Retrieved from <a href="https://cloud.google.com/blog/products/devops-sre/the-2019-accelerate-state-of-devops-elite-performance-productivity-and-scaling">https://cloud.google.com/blog/products/devops-sre/the-2019-accelerate-state-of-devops-elite-performance-productivity-and-scaling</a> <a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content>
        </item>
        
        <item>
            <title>Analyzing the 2020 RSA Innovation Sandbox Finalists</title>
            <link>https://swagitda.com/blog/posts/analyzing-2020-rsa-innovation-sandbox/</link>
            <pubDate>Thu, 06 Feb 2020 21:33:26 -0500</pubDate>
            
            <guid>https://swagitda.com/blog/posts/analyzing-2020-rsa-innovation-sandbox/</guid>
            <description>How do the nominees for the 2020 RSA Conference’s Innovation Sandbox look compared to prior years? I decided to explore the funding profile of the 10 selected startups for the competition, but with the benefit of comparison this year.</description>
            <content type="html"><![CDATA[<p>How do the nominees for the <a href="https://www.rsaconference.com/usa/the-experience/innovation-programs/innovation-sandbox">2020 RSA Conference’s Innovation Sandbox</a> look compared to prior years? <a href="https://swagitda.com/blog/posts/analyzing-2019-rsa-innovation-sandbox-finalists/">Like last year</a>, I decided to explore the funding profile of the ten selected startups – but with the benefit of comparison this year.</p>
<p><img src="/blog/img/rsa-2020-sandbox-01.png" alt="Chart of funding raised by RSA Innovation Sandbox finalists"><em>Total Funding Raised &amp; the Latest Stage for each 2019 RSA Innovation Sandbox Finalist ($USD millions)</em></p>
<p>The median funding raised by all ten startups this year is $14.3 million (mean of $21.3 million), which still reflects a reasonably early stage – but it reflects a 36% jump from 2019’s median of $10.5 million. Last year’s winner, Axonius, was tied for the second smallest startup funding-wise; they had only raised a $4 million seed round until a week before the competition.</p>
<figure>
    <img src="/blog/img/rsa-2020-sandbox-02.png"
         alt="Chart of the Distribution of 2020 RSA Innovation Sandbox Finalists, by Funding Stage"/> <figcaption>
            <p>Distribution of 2020 RSA Innovation Sandbox Finalists, by Funding Stage</p>
        </figcaption>
</figure>
<p>There are no startups with that sort of profile in 2020, as they are all past the seed phase and into at least Series A. The distribution of startups at the Series A phase is even more concentrated this year (80% of all finalists vs. 60% in 2019). We have an additional nominee at the Series B phase this year, too.</p>
<p>However, if startup maturity is measured through temporal age<a name="back-1"></a><a href="#cite-1">[1]</a>, we see a dramatic increase in variability. The median number of months is roughly the same (29.5 months this year vs. 27.5 last year), but the range is quite different: 10 to 138 months (yes, over 11 years old) in 2020 compared to 20 to 46 months in 2019.</p>
<p>Category-wise, there is a decent level of variability of the problems the nominees are tackling. By far the greatest concentration is in AppSec tools, although they consist of different approaches (including RASP, WAF, AST, and risk assessment). There are two finalists tackling the security of third-party SaaS applications. The rest include PII discovery, vulnerability remediation, anti-phishing, and security awareness training.</p>
<p>For those of you familiar with <a href="https://swagitda.com/speaking/index.html">my work</a>, you’re aware of the fact that I dissect and analyze buzzwords in infosec with some regularity. This year’s word-cloud certainly doesn’t disappoint on the buzzword front:</p>
<p><img src="/blog/img/wordcloud-2020-rsa-innovation-sandbox.png" alt="Wordcloud of buzzwords from RSA Innovation Sandbox finalists in 2020"></p>
<p>There were 24 investors across the most recent funding rounds for the ten nominees, with more overlap than last year. ClearSky is a lead investor in both AppOmni and INKY Technology. Costanoa Ventures is a participating investor in AppOmni and Elevate Security. Greylock Partners is a participating investor in Obsidian Security and a lead investor in Sqreen. This debunks my theory from last year that investors put forth a chosen startup from their portfolios, like movie studios do with the Oscars.</p>
<p>The full list of lead investors in these ten startups is:</p>
<ul>
<li>Blossom Capital</li>
<li>ClearSky x2</li>
<li>Costanoa Ventures x2</li>
<li>DARPA</li>
<li>Defy.vc</li>
<li>FireBolt Ventures</li>
<li>General Catalyst</li>
<li>Greylock Partners x2</li>
<li>Gula Tech Adventures</li>
<li>GV</li>
<li>Inner Loop Capital</li>
<li>Jackson Square Ventures</li>
<li>Mayfield Fund</li>
<li>NEA</li>
<li>Point Nine Capital</li>
<li>Point72 Ventures</li>
<li>SignalFire</li>
<li>Silicon Valley Data Capital</li>
<li>StoneMill Ventures</li>
<li>TechOperators</li>
<li>TenEleven Ventures</li>
<li>Unusual Ventures</li>
<li>Wing Venture Capital</li>
<li>Y Combinator</li>
<li>YL Ventures</li>
</ul>
<p>How do these investors overlap with the judges? Well, judge Asheem Chandna is a Partner at Greylock and a board member of Obsidian (his colleague, Sarah Guo, is on Sqreen’s board). Judge Patrick Heim is an Operating Partner at ClearSky, a board member of AppOmni, and on Elevate’s advisory board (ClearSky colleagues Peter Kuper and John Cordo are on Inky’s board). Greylock has coinvested with Clearsky (Demisto) and GV (Censys, Obsidian). ClearSky has coinvested with Costanoa Ventures (AppOmni), Greylock (Demisto), GV (CyberGRX), and TenEleven Ventures (CyberGRX).</p>
<p>As President of Dell Technologies Capital, Scott Darling has coinvested with some of the notable VCs on the list above, including ClearSky (CloudKnox), General Catalyst (RiskRecon), Greylock Partners (Agari), and TenEleven Ventures (JASK). Neither judges Dr. Dorit Dor nor Paul Kocher have immediately obvious ties to any of the VCs backing the 2020 nominees.</p>
<p>All but one 2020 Innovation Sandbox finalist is based in the U.S. (the outlier is based in Israel). 70% are based in California, a huge jump from 40% in 2019. Maryland and Pennsylvania possess one nominee each.</p>
<p>As a final statistic, only one company’s founding team includes any female founders, a 0% increase from 2019.</p>
<hr>
<p><a name="cite-1"></a><a href="#back-1">[1]</a> Not every startup gives the precise day they were founded, so I used a combination of Crunchbase and LinkedIn data (e.g., the start date the founder lists) to get as close as possible.</p>
]]></content>
        </item>
        
        <item>
            <title>My 2019 Reading List</title>
            <link>https://swagitda.com/blog/posts/2019-reading-list/</link>
            <pubDate>Tue, 17 Dec 2019 20:00:00 -0500</pubDate>
            
            <guid>https://swagitda.com/blog/posts/2019-reading-list/</guid>
            <description>Every year, I publish my reading list for those seeking inspo. This is my reading list for 2019, featuring a wide variety of fantasy, sci-fi, and non-fiction books.</description>
            <content type="html"><![CDATA[<p>This year, it&rsquo;s blatantly obvious that I clung to escapism, as evidenced by a fiction list that dwarfs the non-fiction list. What&rsquo;s more, I averaged around 2.7 books per month in 2019 &ndash; roughly double what I achieved the previous three years.</p>
<p>In contrast to prior years, I would say this year&rsquo;s fiction list is weighted towards fantasy more than sci-fi. And, because I began a new vocational journey in a leadership position, my non-fiction books included business-y picks (unlike years prior). As always, I don&rsquo;t provide ratings or reviews of each book here &ndash; I leave it to you to investigate them on your own.</p>
<p>If you’re looking for more science fiction, speculative fiction, or non-fiction recommendations, check out <a href="/blog/posts/2018-reading-list">my 2018</a>, <a href="/blog/posts/2017-reading-list">my 2017</a>, and <a href="/blog/posts/2016-reading-list">my 2016</a> reading lists.</p>
<h2 id="fiction">Fiction</h2>
<p><a href="https://www.amazon.com/2666-Novel-Roberto-Bola%C3%B1o/dp/0312429215/">2666</a> by Roberto Bolaño</p>
<p><a href="https://www.amazon.com/Unkindness-Ghosts-Rivers-Solomon/dp/1617755885/">An Unkindness of Ghosts</a> by Rivers Solomon</p>
<p><a href="https://www.amazon.com/Brothers-Karamazov-Fyodor-Dostoevsky/dp/0374528373/">The Brothers Karamazov</a> by Fyodor Dostoevsky (re-read)<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></p>
<p><a href="https://www.amazon.com/Bird-King-G-Willow-Wilson/dp/080212903X/">The Bird King</a> by G. Willow Wilson</p>
<p><a href="https://www.amazon.com/Certain-Dark-Things-Silvia-Moreno-Garcia/dp/1250099080/">Certain Dark Things</a> by Silvia Moreno-Garcia</p>
<p><a href="https://www.amazon.com/CIRCE-New-York-Times-bestseller/dp/0316556343/">Circe</a> by Madeline Miller</p>
<p><a href="https://www.amazon.com/City-Brass-Novel-Daevabad-Trilogy/dp/0062678108/">The City of Brass</a> by S.A. Chakraborty</p>
<p><a href="https://www.amazon.com/Devil-America-Tor-Com-Original-ebook/dp/B00IW3DCRK/">The Devil in America</a> by Kai Ashante Wilson</p>
<p><a href="https://www.amazon.com/Devourers-Novel-Indra-Das/dp/1101967536/">The Devourers</a> by Indra Das</p>
<p><a href="https://www.amazon.com/Empire-Sand-Books-Ambha-Tasha/dp/0316449717/">Empire of Sand</a> by Tasha Suri</p>
<p><a href="https://www.amazon.com/Everfair-Novel-Nisi-Shawl/dp/076533805X/">Everfair</a> by Nisi Shawl</p>
<p><a href="https://www.amazon.com/Ficciones-Jorge-Luis-Borges/dp/0802130305/">Ficciones</a> by Jorge Luis Borges (re-read)<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup></p>
<p><a href="https://www.amazon.com/Gideon-Ninth-Tamsyn-Muir/dp/1250313198/">Gideon the Ninth</a> by Tamsyn Muir</p>
<p><a href="https://www.amazon.com/Monsters-Lucky-Peach-Kelly-Robson/dp/1250163854/">Gods, Monsters, and the Lucky Peach</a> by Kelly Robson</p>
<p><a href="https://www.amazon.com/Gods-Jade-Shadow-Silvia-Moreno-Garcia/dp/0525620753/">Gods of Jade and Shadow</a> by Silvia Moreno-Garcia</p>
<p><a href="https://www.amazon.com/Kingdom-Copper-Novel-Daevabad-Trilogy/dp/0062678132/">Kingdom of Copper</a> by S.A. Chakraborty</p>
<p><a href="https://www.amazon.com/Haunting-Tram-Car-DJ%C3%88L%C3%8D-CLARK/dp/1250294800/">The Haunting of Tram Car 015</a> by P. Djèlí Clark</p>
<p><a href="https://www.amazon.com/Mistborn-Trilogy-Boxed-Hero-Ascension/dp/076536543X/">Mistborn trilogy</a> by Brandon Sanderson</p>
<p><a href="https://www.amazon.com/Nexus-Ramez-Naam/dp/0857662929/">Nexus</a> by Ramez Naam</p>
<p><a href="https://www.amazon.com/No-Longer-Human-Osamu-Dazai/dp/0811204812/">No Longer Human</a> by Osamu Dazai</p>
<p><a href="https://www.amazon.com/Rosewater-Wormwood-Trilogy-Tade-Thompson/dp/0316449059/">Rosewater</a> by Tade Thompson</p>
<p><a href="https://www.amazon.com/Spinning-Silver-Novel-Naomi-Novik/dp/0399180990/">Spinning Silver</a> by Naomi Novik</p>
<p><a href="https://www.amazon.com/Storm-Locusts-Sixth-Rebecca-Roanhorse/dp/1534413529/">Storm of Locusts</a> by Rebecca Roanhorse</p>
<p><a href="https://www.amazon.com/Lighthouse-Virginia-Woolf/dp/0156907399/">To the Lighthouse</a> by Virginia Woolf</p>
<p><a href="https://www.amazon.com/Trail-Lightning-Sixth-Rebecca-Roanhorse/dp/1534413499/">Trial of Lightning</a> by Rebecca Roanhorse</p>
<p><a href="https://www.amazon.com/Uprooted-Novel-Naomi-Novik/dp/0804179050/">Uprooted</a> by Naomi Novik</p>
<p><a href="https://www.amazon.com/Waste-Tide-Chen-Qiufan/dp/0765389312/">Waste Tide</a> by Chen Qiufan</p>
<hr>
<h2 id="non-fiction">Non-Fiction</h2>
<p><a href="https://www.amazon.com/Cheating-Deception-J-Bowyer-Bell/dp/088738868X/">Cheating and Deception</a> by J. Bowyer Bell and Barton Whaley</p>
<p><a href="https://www.amazon.com/Good-Strategy-Bad-Difference-Matters/dp/0307886239/">Good Strategy/Bad Strategy: The Difference and Why It Matters</a> by Richard Rumelt</p>
<p><a href="https://www.amazon.com/Her-Majestys-Spymaster-Elizabeth-Walsingham/dp/0452287472/">Her Majesty&rsquo;s Spymaster: Elizabeth I, Sir Francis Walsingham, and the Birth of Modern Espionage</a> by Stephen Budiansky</p>
<p><a href="https://www.amazon.com/Inconvenient-Indian-Curious-Account-America/dp/0816689768">The Inconvenient Indian: A Curious Account of Native People in North America</a> by Thomas King</p>
<p><a href="https://www.amazon.com/Lost-Enlightenment-Central-Conquest-Tamerlane/dp/0691165858/">Lost Enlightenment: Central Asia&rsquo;s Golden Age from the Arab Conquest to Tamerlane</a> by S. Frederick Starr</p>
<p><a href="https://www.amazon.com/Managers-Path-Leaders-Navigating-Growth/dp/1491973897/">The Manager&rsquo;s Path: A Guide for Tech Leaders Navigating Growth and Change</a> by Camille Fournier</p>
<hr>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>One of my favorite lines from &ldquo;Slaughterhouse Five&rdquo; is: <em>&ldquo;He said that everything there was to know about life is in &lsquo;The Brothers Karamazov,&rsquo; by Fyodor Dostoevsky. &lsquo;But that isn&rsquo;t enough anymore,&rsquo; said Rosewater.&quot;</em> Given current times, this line kept rattling around in my head and compelled me to re-read it. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p><em>&ldquo;No hay ejercicio intelectual que no sea finalmente inútil.&quot;</em> <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content>
        </item>
        
        <item>
            <title>Ransomware: Towards an Economic Equilibrium</title>
            <link>https://swagitda.com/blog/posts/ransomware-towards-an-economic-equilibrium/</link>
            <pubDate>Sun, 15 Dec 2019 20:58:46 -0500</pubDate>
            
            <guid>https://swagitda.com/blog/posts/ransomware-towards-an-economic-equilibrium/</guid>
            <description>This post will explore my thoughts on how the economics of physical ransom translate to digital ransom, and how we as an industry might want to reconceive our current approaches to considering and dealing with ransomware – and the criminals who run ransomware campaigns.</description>
            <content type="html"><![CDATA[<p><img src="/blog/img/ransomware.JPG" alt="Image of someone giving money in exchange for a key"></p>
<p>On my vacation to Namibia earlier this year, I caught up on podcasts during the long stretches of driving (albeit in breathtaking scenery). One episode in particular jolted my mental juices – the <a href="http://www.econtalk.org/anja-shortland-on-kidnap/">EconTalk episode featuring Dr. Anja Shortland</a> discussing her book <em><a href="https://www.amazon.com/Kidnap-Inside-Business-Anja-Shortland/dp/0198815476">Kidnap</a></em>. The fascinating chat between Dr. Shortland and host Russ Roberts delved into the incentive mechanisms between kidnappers who demand ransom and insurers, and the economic paradigm that results.</p>
<p>Naturally, there are implications for ransomware, the digital counterpart to physical ransom. In particular, I believe the role cyber insurance should play deserves closer examination, but there are other spicy takes that fomented as I listened to and digested the podcast episode. This post will explore my thoughts on how the economics of physical ransom translate to digital ransom, and how we as an industry might want to reconceive our current approaches to considering and dealing with ransomware – and the criminals who run ransomware campaigns.</p>
<hr>
<h1 id="the-shadow-of-the-future">The Shadow of the Future</h1>
<p>First, let us set the stage with a discussion of the “shadow of the future” and how it applies to the ransom market. The “shadow of the future” is a game theoretic concept that explains how people will behave differently if they believe they will need to interact with their current counterparty again (“repeated games” in game theory lingo). This belief encourages cooperation between counterparties, as they will play much nicer in the hope of receiving better treatment in future interactions.<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> Thus, the future lingers like a “shadow” over current interactions.</p>
<p>In the kidnapping for ransom world, criminals cast a shadow of the future. If they desire to kidnap again, they want to “behave” in the immediate interaction to help them in their future business. If kidnappers demonstrate they will honor their demands upon receipt of a ransom, then future victims will be more likely to pay ransoms, believing that promises are more likely to be kept. This, Dr. Shortland surmises, is why 97.5% of kidnapping cases “go right” – which is better than the success rate of many <em>legitimate</em> transactions.</p>
<p>An example Dr. Shortland gives is that Somali pirates, upon receiving ransom for multimillion-dollar sea vessels, are repeatedly seen to leave the vessels and not re-hijack them again. The exchange of hijacked sea vessels for cash consistently goes right for all parties involved – even in a situation that is rife with mistrust and conflict. The Somali pirates are now trustable in a twisted way, as owners of sea vessels know that they will indeed have their ships returned reliably if they pay the ransom. As Dr. Shortland points out, this shadow of the future applies to kidnapping gangs within cities as well, through the power of local gossip.</p>
<p>How does the shadow of the future apply to ransomware? It certainly <em>should</em> apply, as few attackers run ransomware campaigns against only one target, thus creating the opportunity for future interactions with victims. Victims, at least in theory, would be more likely to pay ransoms to criminal groups who were known to reliably decrypt data, especially those who do so without any data loss.</p>
<p>Unfortunately, the data on ransomware and success rates (on both sides) is limited, particularly when getting as granular as specific ransomware types. At first blush, the statistic from the first quarter of 2019 that 96%<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> of ransomware payments were successful seems to match the high success rate of kidnapping cases. However, that just represents the number of victims who received a decryption tool. The recovery rate in the same survey ranges from 80% to 100%, depending on the ransomware type. Other surveys suggest the data recovery rate is as low as 66%<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> to 75%<sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>.</p>
<p>These statistics suggest a far more inefficient market for ransomware than exists for physical ransom. Additional supporting evidence of this inefficiency arises from the mismatch of ransomware campaigns with the most reliable data recovery and campaigns with the highest ransom demanded. Ryuk requests $286,557 on average<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup>, despite their approximately 80% data recovery rate, due to targeting larger enterprises. Grand Crab, in contrast, demands just under $8,000 but offers an approximately 100% data recovery rate. This seems like a far cry from a “nice equilibrium” as exists in the physical sphere.</p>
<hr>
<h1 id="encouraging-better-attackers">Encouraging Better Attackers</h1>
<p>This kind of illegal activity is an inevitability – neither physical nor digital ransom can be fully prevented. Therefore, we must optimize given the constraints of this reality. Just like you want to encourage kidnappers that do not kill their victims, we want to encourage attackers that do not lose ransomed data.</p>
<p>With this grounding aspiration in mind, let me offer you my ghost pepper-level take. There is some level of attacker activity that represents a healthy equilibrium, and defining that equilibrium (perhaps “only teams that can discover and weaponize 0day”) is healthier than trying to stop attacker activity. That is, if we can eliminate the <a href="https://en.wikipedia.org/wiki/Script_kiddie">script kiddies</a> and #basicbitch<sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup> attackers who lack the operational resources to ensure data fidelity when conducting digital ransom, organizations will be better off – even if they are still hit by sophisticated attackers who will receive payments but reliably facilitate data recovery.</p>
<p>As Dr. Shortland cited, the presence of armed guards in the Niger delta creates a “nice equilibrium,” because it, in essence, raises the cost of attack. Disorganized, resource-constrained street gangs cannot pursue physical ransom as one of their normal activities when they must contend with armed guards. Only more sophisticated criminal organizations will possess the means to pursue physical ransom – and they are vastly more likely to adhere to the aforementioned shadow of the future, leading them to behave professionally and responsibly.</p>
<hr>
<h1 id="the-role-of-cyber-insurance">The Role of Cyber Insurance</h1>
<p>How can we encourage this kind of equilibrium? If we look to the physical ransom domain, insurance companies play a critical role. Kidnap insurance creates stability in the market, reducing the friction between “buyers” (the victim’s representatives) and “sellers” (the kidnappers). Of course, it would be remiss of me not to acknowledge the dark side of insurance – the creation of macro-level moral hazard. Kidnap insurance’s very existence allows kidnapping to be an especially profitable ongoing activity. However, the safer ends – based on current evidence – seem to suitably justify the means.</p>
<p>The insurers’ goal, in the kidnapping market, is to eliminate stupid or irrational kidnappers from the market – those who make errors in process or judgment, such as cutting off fingers to hasten payment of ransom. Likewise, cyber insurance’s goal should be the same, to eliminate the skidiots<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> who could accidentally brick systems or delete data and to encourage more sophisticated attackers who are true to their promises and conduct their operations reliably and professionally.</p>
<p>One can envision a world in which a cyber insurance company negotiates a flat rate to receive the decryptor, then sending a bonus if all data is recovered. Such a scheme would incentivize attackers to maximize victim data recovery upon receipt of payment. This, of course, relies on the “shadow of the future” – but it is in the best interests of the victims, cyber insurance firms, and attackers to develop the trust that full payments will be received and data will be fully recovered.</p>
<p>You may be thinking to yourself, “This feels really icky – aren’t the attackers winning here?” Attackers will continue to be a reality, as, likely, will ransomware. By accepting reality, we can depart from the unrealistic goal of “eliminate all ransomware attacks” to “maximize reliability of data recovery in ransomware attacks.” Part of maximizing reliability is encouraging better attackers, which is done by raising the cost of attack.</p>
<p>Naturally, there are caveats. Both physical and digital ransom are examples of markets in which imperfect information is actually advantageous to the “good” side, as insurance companies benefit from information being withheld from criminals. Accordingly, insurance companies should withhold the extent to which individuals are insured to prevent victims from divulging how much money the attackers could receive. The attackers will logically ask for the maximum ransom payment based on their expectations – so it is better to minimize their expectations as much as possible.</p>
<p>As Dr. Shortland advises, the goal is to “manage the size of the towel the [attackers] think they’re squeezing.” We – ideally, through insurance companies – must convince the attacker that they have reaped everything they could from their attack. Therein lies the beautiful pragmatism of this strategy: we focus on the elements we can control (perceptions) rather than the elements we cannot (motivations, resources, etc.). Yes, implementing proper backup and recovery solutions is within defenders’ control, too, but as we can see from the seemingly weekly headlines about ransomware incidents, we need a sane Plan B.</p>
<hr>
<h1 id="conclusion">Conclusion</h1>
<p>In general, there is much information security can learn from domains which have a rich history of experimenting with solutions to similar problems. Physical ransom, in which a rather efficient market between attackers, victims, and insurance companies exists, is a pertinent exemplar for how infosec can more efficiently deal with ransomware.</p>
<p>While it may feel uncomfortable to accept a healthy level of malicious activity, at a certain point, we must become pragmatic rather than wallowing in sententious idealism. We can never fully prevent attacks, and that goes for ransomware as well. But we do have a chance to encourage more intelligent attackers – who operate professionally, incentivized by ongoing business interests – so that the ultimate impact of ransomware is less deleterious than what transpires under the claws of disorganized, incompetent attackers.</p>
<p>This may not be the safer world we imagined, but, as Machiavelli advised centuries ago, “Prudence consists in knowing how to distinguish the character of troubles, and for choice to take the lesser evil.”<sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup> We owe it to those who depend on our expertise to think more boldly in how we can build a sustainable equilibrium in a world – digital and otherwise – that will always be troubled by aggressors.</p>
<hr>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>This, as with many things in economics and game theory, does not always hold true, depending on the context. In the realm of international relations, where the shadow of the future is commonly studied, <a href="https://www.sciencedirect.com/science/article/pii/0167268195000771">some researchers</a> <a href="https://www.sciencedirect.com/science/article/pii/0167268195000771">suggest</a> the shadow can actually harm cooperation. <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Statistic sourced <a href="https://www.coveware.com/blog/2019/4/15/ransom-amounts-rise-90-in-q1-as-ryuk-ransomware-increases">via Coveware</a> <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p><a href="https://blog.trendmicro.com/paying-for-ransomware-could-cost-you-more-than-just-the-ransom/">Trend Micro, 2016</a> <a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4" role="doc-endnote">
<p><a href="https://www.fortinet.com/content/dam/fortinet/assets/white-papers/WP-Mapping-The-Ransomware-Landscape.pdf">Fortinet, 2016</a> <a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5" role="doc-endnote">
<p>Both Ryuk and Grand Crab&rsquo;s monetary amounts are taken from the Coveware report in footnote 2. <a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6" role="doc-endnote">
<p>I still have yet to find a word or term that so immediately evokes the blend of insipidness, mediocrity, and formulaicity that “basic bitch” conveys. <a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7" role="doc-endnote">
<p>Credit to <a href="https://twitter.com/r00tkillah">@r00tkillah</a> for this delightful term for script kiddies. <a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8" role="doc-endnote">
<p>This quote is, of course, from <a href="https://www.gutenberg.org/files/1232/1232-h/1232-h.htm">&ldquo;The Prince.&quot;</a> <a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
]]></content>
        </item>
        
        <item>
            <title>When Prospect Theory Meets Chaos Engineering</title>
            <link>https://swagitda.com/blog/posts/when-prospect-theory-meets-chaos-engineering/</link>
            <pubDate>Mon, 12 Aug 2019 08:00:00 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/when-prospect-theory-meets-chaos-engineering/</guid>
            <description>There is a connection between my research into behavioral models of information security and my Black Hat USA talk with Dr. Forsgren from last week regarding DevOps and the future of information security that might not be immediately obvious. However, it is a connection I believe is worth illuminating.
Adopting the “chaotic infosec” philosophy (the application of chaos engineering to information security) can influence those who build and secure systems to operate more like attackers – that is, to be more risk averse and to more quickly update their mental models given new inputs.</description>
            <content type="html"><![CDATA[<p>There is a connection between my research into <a href="https://swagitda.com/blog/tags/behavioral-infosec/">behavioral models of information security</a> and <a href="https://swagitda.com/speaking/us-19-Shortridge-Forsgren-Controlled-Chaos-the-Inevitable-Marriage-of-DevOps-and-Security.pdf">my Black Hat USA talk</a> with Dr. Forsgren from last week regarding DevOps and the future of information security that might not be immediately obvious. However, it is a connection I believe is worth illuminating.</p>
<p>Adopting the “chaotic infosec” philosophy (the application of chaos engineering to information security) can influence those who build and secure systems to operate more like attackers – that is, to be more risk averse and to more quickly update their mental models given new inputs. This post will explore what exactly this means, and why it represents a valuable mindshift for organizational security.</p>
<h2 id="how-does-prospect-theory-apply-to-security">How does Prospect Theory apply to security?</h2>
<p>While I encourage you to read my prior post on applying <a href="https://swagitda.com/blog/posts/behavioral-models-infosec-prospect-theory">Prospect Theory to information security</a>, I recognize it is a bit long. I will thus summarize its relevant points here.</p>
<p>Humans make decisions by setting a reference point (their view of the status quo) against which they measure the decisions’ potential outcomes. Empirical evidence shows that people generally prefer options that provide a small but certain gain rather than options that provide a larger but uncertain gain. They also generally prefer options that provide a miniscule chance of losing nothing (with a larger chance of losing a lot) rather than options that provide a certain chance of losing less.</p>
<p>These results, which are modelled by <a href="https://en.wikipedia.org/wiki/Prospect_theory">Prospect Theory</a>, suggest that people are risk averse when making decisions with positive potential outcomes (when they are in the “Gain Domain”), and risk seeking when making decisions with negative potential outcomes (when they are in the “Loss Domain”). The further people get away from their reference point (again, their perceived status quo), these trends exaggerate. People who experience heavy losses become even more risk seeking in an attempt to jump out of the figurative hole, and people who experience substantial gains become even more risk averse to preserve their winnings.</p>
<p><a href="https://swagitda.com/blog/posts/behavioral-models-infosec-prospect-theory/#infosec-ref-points">My hypothesis was</a> that defenders set their reference point based on a status quo where their organization is perceived to be secure and uncompromised (to simplify a bit). The nature of enterprise defense means that defenders will operate in the Loss Domain as a result – compromises are inevitable, as are failures to maintain a level of security posture that defenders find acceptable. Attackers, in contrast, operate in the Gain Domain – because their reference point is their current level of compromise, and, generally, they are likely to positively further their position of pwnage.</p>
<p><a href="https://swagitda.com/blog/posts/behavioral-models-infosec-prospect-theory/#infosec-examples">As a result</a>, defenders are more risk seeking, leading them to adopt more speculative solutions to attempt to reach their reference point of perfect prevention instead of adopting more basic solutions with larger probabilities of success but a perception of being less likely to stop a big, sexy attack. Attackers, on the other hand, are more risk averse, moving more cautiously to achieve their goals, opting first for inexpensive methods before moving to expensive methods.</p>
<h2 id="how-does-chaos-transform-reference-points">How does chaos transform reference points?</h2>
<p>Applying the principles of chaos engineering to information security, as outlined in <a href="https://swagitda.com/speaking/us-19-Shortridge-Forsgren-Controlled-Chaos-the-Inevitable-Marriage-of-DevOps-and-Security.pdf">my Black Hat USA 2019 talk</a>, changes the reference point for defenders. If you extend the chaos engineering philosophy of “things will fail” to “things will be pwned,” then the status quo for security teams becomes the assumption of compromise.</p>
<p>For traditional enterprise security programs, mapping Prospect Theory to security shows a state of being that is fragile to reality. This state anchors those involved in enterprise defense to the Loss Domain, as shown in the graph below, encouraging risk seeking and reactive behaviors.</p>
<img style="display:block; margin-right:auto; margin-left:auto; max-width:75%;" src="/blog/img/prospect-theory-infosec-today.png" alt="A Prospect Theory graph representing how infosec lives in the Loss Domain today">
<p>In contrast, applying chaos engineering to security transforms security&rsquo;s Prospect Theory graph into being resilient to reality, encouraging risk averse and strategic behaviors. A dearth of significant compromises at your organization now feels like a gain, as shown in the graph below, incentivizing the preservation of that gain – which can be achieved in part through some of the <a href="https://swagitda.com/speaking/us-19-Shortridge-Forsgren-Controlled-Chaos-the-Inevitable-Marriage-of-DevOps-and-Security.pdf">strategies and testing</a> I enumerated in the Black Hat talk (see the “A Phoenix Rises” section).</p>
<img style="display:block; margin-right:auto; margin-left:auto; max-width:75%;" src="/blog/img/prospect-theory-infosec-chaos.png" alt="A Prospect Theory graph for infosec when influenced by the chaos philosophy of things will be pwned">
<p>As demonstrated in these graphs, by assuming “things will be pwned,” there is really only upside – so those who architect and secure their organizations’ systems can begin feeling less defeated and instead feel proud of their efforts. Implementing security “basics” can feel unrewarding, but successfully increasing the cost of attack deserves a sense of accomplishment. While I use the term “stopping” on the Gain Domain side of the graphs for brevity, I do not literally mean preventing attacks by skiddies or APTs from happening. Rather, I mean stopping these attacks from negatively impacting your organization, which is ultimately what matters.</p>
<p>Just as failure-based metrics, such as Time Between Failure, inhibit innovation and make systems more brittle, allowing an organization&rsquo;s security contributors to languish in the Loss Domain similarly hinders resilience and, ultimately, organizational performance. Instead, a success-oriented metric like Time to Recovery promotes innovation and resilience – and operating in the Gain Domain incentivizes similar behaviors. Therefore, switching your reference point from “maintaining secure systems” to “things will be pwned” – despite seeming like trivial semantics – has the potential to subtly transform how your teams design systems.</p>
<h2 id="conclusion">Conclusion</h2>
<p>The most effective way to engender cultural change is by changing what people do, not what they think. By altering the security mental model through this path of chaos, you change behavioral vectors – harnessing people’s embedded wetware – to promote the type of strategic, innovative, and perceptive decision-making that we so desperately need to build and maintain secure systems. Adopting the mantle of chaos through the philosophy of “things will be pwned” can reorient team perception to operate in a more strategic, less frenetic fashion by re-architecting their relationship between risk and reward.</p>
]]></content>
        </item>
        
        <item>
            <title>Analyzing the Black Hat USA 2019 Business Hall</title>
            <link>https://swagitda.com/blog/posts/analyzing-blackhatusa-business-hall-2019/</link>
            <pubDate>Fri, 02 Aug 2019 08:35:54 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/analyzing-blackhatusa-business-hall-2019/</guid>
            <description>Prerequisite plug that you should come see my talk with Dr. Nicole Forsgren at Black Hat next week (16:00 in South Pacific)!
What type of vendors are showing themselves off in the Business Hall? Are they mostly startups? Exactly like last year, 46% of the vendors in the Business Hall are startups backed by venture capital (VC) firms. Private companies represent only 13% of total vendors this year (vs. 17% last year), and there are far more acquired companies (&#34;</description>
            <content type="html"><![CDATA[<p><em>Prerequisite plug that you should come see <a href="https://www.blackhat.com/us-19/briefings/schedule/index.html#controlled-chaos-the-inevitable-marriage-of-devops--security-15273">my talk with Dr. Nicole Forsgren</a> at Black Hat next week (16:00 in South Pacific)!</em></p>
<h2 id="what-type-of-vendors-are-showing-themselves-off-in-the-business-hall-are-they-mostly-startups">What type of vendors are showing themselves off in the Business Hall? Are they mostly startups?</h2>
<img style="display:block; margin-right:auto; margin-left:auto; max-width:80%;" src="/blog/img/bhusa2019/vendors-type.png" alt="Chart of number of vendors by funding type for the Black Hat USA 2019 Vendor Hall">
Exactly like last year, 46% of the vendors in the Business Hall are startups backed by venture capital (VC) firms. Private companies represent only 13% of total vendors this year (vs. 17% last year), and there are far more acquired companies ("M&A" within the chart) this year (8% vs. 5% in 2018). Some of them were acquired within the past year, which means they already booked the booth in their name. However, others are companies acquired awhile ago that still retain their brand name as distinct from their new owners. 
<img style="float:right; max-width:50%; padding-left: 10px" src="/blog/img/bhusa2019/vc-by-age.png" alt="Chart of number of VC-backed companies by age of last raise">
Over half of VC-backed vendors received fresh funding within the past year, up quite a bit from 44% last year. We saw a 80% were funded within the past two years, and 92% were funded within the last three. Only nine companies have not been funded in the last three years, and those companies are very likely itching for exit (i.e. M&A) opportunities now.
<hr>
<h2 id="how-many-vendors-from-2018-are-exhibiting-again-in-2019">How many vendors from 2018 are exhibiting again in 2019?</h2>
<p>67% of vendors who exhibited in 2018 are exhibiting in 2019, while 33% are not. Of the 31% of VC-backed security vendors who exhibited in 2018 but are not in 2019, some are vendors who were acquired (e.g. Twistlock, ProtectWise), while many of the others are well-known to be &ldquo;long in the tooth&rdquo; (e.g. Bromium, CounterTack). Others were still funded recently (e.g. Digital Guardian), so it&rsquo;s possible they calculated a lack of ROI from the event.</p>
<p>An interesting statistic is that the VC-backed vendors who are exhibiting again received their latest VC infusion more recently than those who are not still exhibiting. For VC-backed vendors exhibiting again in 2019, the delta between their last funding round and Black Hat USA 2018 (which was August 2018) was 482 days (a mean of April 2017). For VC-backed vendors not exhibiting again in 2019, the average was 622 days (a mean of November 2016). This might support the notion that vendors who have not received VC funding for awhile are less financially healthy, and therefore unable to pony up the cash for another booth at Black Hat.</p>
<p>Outside of VC-backed vendors, around half of the publicly-traded non-security vendors from last year decided not to exhibit this year. 8 companies that were acquired decided not to exhibit this year (for instance, Phantom presumably now will be present at the Splunk booth). Around half of the privately-owned vendors from last year decided not to exhibit. All of the publicly-traded security vendors are exhibiting again this year, save for Gemalto (who knew they were being acquired by Thales). Perhaps not surprisingly, DarkMatter decided not to show their face at BlackHat this year. <a href="https://www.reuters.com/article/us-usa-cyber-alphabet-google/google-blocks-websites-certified-by-darkmatter-after-reuters-reports-idUSKCN1UR5JD">Can&rsquo;t imagine why</a>.</p>
<hr>
<h2 id="how-many-vcs-are-dedicated-to-investing-in-infosec">How many VCs are dedicated to investing in infosec?</h2>
<img style="float:right; max-width:50%; padding-left: 10px" src="/blog/img/bhusa2019/fund-numbers.png" alt="Chart of the number of VC funds by companies invested">
Out of the 168 investors who led a funding round in a security vendor exhibiting at the Black Hat USA 2019 Business Hall, 69% only led one round. This suggests that the amount of investors "dabbling" in infosec is not decreasing, which is a shame. Ideally, investors educated on the space would make most of the funding decisions as, at least in theory, they can better sift through the FUD and buzzwords to determine which vendors actually fill a need in the market. 
<p>There were 16 investors who led 4 deals or more, which is down from 21 last year. 25 venture capital firms led 3 deals or more, which is a convenient number to remember as a proxy for the amount of VCs at least somewhat dedicated to infosec investing. Below is the Top Ten list, which includes all VC firms who led at least 5 funding rounds in this year&rsquo;s exhibitors:</p>
<script src="https://gist.github.com/swagitda/e640aa3f4d1c740094292b956b61f68a.js"></script>
<hr>
<h2 id="what-venture-stage-are-vendors--how-much-capital-are-they-raising">What venture stage are vendors &amp; how much capital are they raising?</h2>
<img style="float:right; max-width:50%; padding-left: 10px" src="/blog/img/bhusa2019/vc-by-round.png" alt="Chart of the number of VC-backed vendors, by latest round">
The distribution of exhibitors by funding stage looks a little different than last year. While the number of late-stage companies (Series C or later) stayed roughly constant, there was a notable spike in early-stage companies (Seed through Series B) -- from 53% last year to representing 61% of all VC-backed startups in 2019. This may reflect the increasing dollar-size of early-stage rounds over the past year, as younger companies can now more easily afford to purchase booths. 
<p>Supporting evidence for my theory is that the median dollar amount raised in Series A deals increased 45% for exhibitors who raised after August 1, 2018 vs. those who raised before then. A counterpoint is that Seed and Series B median deal sizes were down from 2018 (-15% and -4%, respectively). Late-stage deals boomed in median dollar amount raised, increasing 32% for Series C, 40% for Series D, and 119% for Series E rounds.</p>
<p>The median amount raised across all stages increased 38%, from a median of $17.0 million in 2018 to $23.5 million in 2019. I use the median here since the mean is skewed by some absolute unit late stage deals since August 2018. Nevertheless, the mean amount raised across all stages increased 89%, from $21.6 million to $40.8 million.</p>
<img style="display:block; margin-right:auto; margin-left:auto; max-width:80%" src="/blog/img/bhusa2019/vc-dollars-by-round.png" alt="Chart of the average size of funding rounds, by stage">
<hr>
<h2 id="how-many-private-equity-firms-are-backing-companies-on-the-floor">How many Private Equity firms are backing companies on the floor?</h2>
<p>There are 29 companies backed by 20 total Private Equity firms in the Business Hall this year. Last year, there was roughly the same number of companies (30), but significantly more Private Equity firms (27). It is still true that the vast majority (85%, up from 81%) of Private Equity investors are one-off investors, and only 3 Private Equity firms invested in / acquired 2 or more security companies. Dominating that figure is Thoma Bravo, who has 5 portfolio companies exhibiting in 2019.</p>
<script src="https://gist.github.com/swagitda/1c894e489c750649f025cc6eda277b33.js"></script>
<hr>
<h2 id="how-fresh-is-the-innovation-city">How fresh is the Innovation City?</h2>
<img style="float:right; max-width:50%; padding-left: 10px" src="/blog/img/bhusa2019/innovation-city.png" alt="Chart of Innovation City 'residents,' by type">
Innovation City now has 44 "residents" (up from 41 in 2018), and has a significantly higher concentration of VC-backed companies than the total population (73% vs. 46%). Last year, Innovation City was only 59% VC-backed, and part of the increase this year was at the expense of the proportion of privately-held but unfunded vendors.
<p>True to its promise as a bastion of &ldquo;startups and emerging companies,&rdquo; 91% of the VC-backed residents of Innovation City are Seed through Series B stage &ndash; way more than the 61% present in the total population. The median amount of the latest round of funding was $10.0 million among Innovation City residents, in contrast to the total population&rsquo;s median of $23.5 million.</p>
<p>Fascinatingly, 12 of the 44 Innovation City residents were also residents last year &ndash; over a quarter of the population. I personally assumed they rotated vendors to keep things fresh for attendees attempting to scout the most cutting-edge vendors of the flock, but I was clearly pretty wrong.</p>
<hr>
<h2 id="how-us-centric-are-the-vendors-at-black-hat">How U.S.-centric are the vendors at Black Hat?</h2>
<img style="float:right; max-width:60%; padding-left: 10px" src="/blog/img/bhusa2019/geo-all.png" alt="Chart of all companies, by geography">
The Business Hall is marginally less U.S.-centric in 2019 than in 2018, decreasing to 79% from 83% last year. Even the proportion of VC-backed companies that are U.S.-based decreased, from 86% in 2018 to 82% in 2019. The EU grew its portion of VC-backed companies, which now represent over half of all EU-based vendors. Perhaps this is the GDPR effect in action?
<img style="float:right; max-width:40%; padding-left: 10px" src="/blog/img/bhusa2019/geo-vc.png" alt="Chart of VC-backed companies, by geography">
It surprises me somewhat that the number of Israeli startups is still quite low proportionally, despite the substantial number of them funded each year. I suspect the reason is that many Israeli startups end up switching their headquarters to the U.S. (particularly California) once they've reached the Series A stage or later. Thus, many of the startups founded in Israel may not be reflected in these numbers. 
<p>Within the U.S., California makes up 43% of all U.S.-based vendors presenting, and over half (53%) of VC-backed startups in the Business Hall. After California, Massachusettes, New York, and the D.C.-region dominate, though Texas is ascendant.</p>
<img style="display:block; margin-right:auto; margin-left:auto; max-width:80%" src="/blog/img/bhusa2019/state-all.png" alt="Chart of all U.S. companies, by state">
<p>Final note: I have no idea what is happening with Brexit (does anyone?), but given the UK has more representative companies than the definitely-EU-countries combined, I kept the UK separate.</p>
<hr>
<h2 id="a-few-notes-on-the-data">A few notes on the data</h2>
<p>Vendors were retrieved from the Black Hat 2019 Business Hall Floorplan, and exclude any federal agencies, educational organizations, or nonprofits. I also excluded any companies in the Career Zone, as they are aiming to recruit security talent rather than sell products or services.</p>
<p>Location and funding information was collected through Crunchbase. There may be errors if a company&rsquo;s Crunchbase page is not up to date.</p>
]]></content>
        </item>
        
        <item>
            <title>Darth Jar Jar: a Model for Infosec Innovation</title>
            <link>https://swagitda.com/blog/posts/darth-jar-jar-model-infosec-innovation/</link>
            <pubDate>Sun, 05 May 2019 08:30:09 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/darth-jar-jar-model-infosec-innovation/</guid>
            <description>Despite its seeming absurdity and superficiality, the theory of Darth Jar Jar can serve as a poignant parable for security innovation. For those unfamiliar, the notion of a Darth Jar Jar springs from a meticulously researched fan theory from the Star Wars subreddit. While I do not wish to spoil the breathtaking beauty of the fleshed-out theory, the underlying legend is one of an ostensibly bumbling fool who, in reality, is an insidious puppet master full of cunning and strength.</description>
            <content type="html"><![CDATA[<p><img src="/blog/img/darth-jar-jar.jpg" alt="Image of Darth Jar Jar"></p>
<p>Despite its seeming absurdity and superficiality, the theory of Darth Jar Jar can serve as a poignant parable for security innovation. For those unfamiliar, the notion of a Darth Jar Jar springs from a <a href="https://www.reddit.com/r/StarWars/comments/3qvj6w/theory_jar_jar_binks_was_a_trained_force_user/">meticulously researched fan theory</a> from the Star Wars subreddit. While I do not wish to spoil the breathtaking beauty of the fleshed-out theory, the underlying legend is one of an ostensibly bumbling fool who, in reality, is an insidious puppet master full of cunning and strength.</p>
<p>What lessons from Darth Jar Jar can we glean and apply to information security? I argue there are a few innovative strategies one can postulate on both the offense and defense sides, which I will explore within this post.</p>
<hr>
<h2 id="darth-jar-jar-for-offense">Darth Jar Jar for Offense</h2>
<p>For an attacker to fully become one with Darth Jar Jar, they must be content playing a fool. Just as Darth Jar Jar appeared to be clumsy to lead to his underestimation, attackers should likewise appear to be sloppy to lead to their underestimation by defenders. By conducting purposefully noisy and messy operations in one part of a system, attackers can direct defenders’ attention away from the attack that is truly transpiring right under their cocksure noses.</p>
<p>There already exist public examples of attackers embracing the spirit of Darth Jar Jar. One of my favorites is the misdirection employed by <a href="https://krebsonsecurity.com/2013/02/ddos-attack-on-bank-hid-900000-cyberheist/">attackers back in 2013</a>, in which they conducted a DDoS to cover their tracks when exfiltrating funds out of corporate accounts. A further three banks were hit by <a href="https://www.cnet.com/news/cybercrooks-use-ddos-attacks-to-mask-theft-of-banks-millions/">the same approach later that year</a> – a low-powered DDoS attack that captured defenders’ attention, while fraudulent money transfers happened concurrently.</p>
<p>Additionally, the Nigerian prince scam is arguably a long-term ploy very much in the vein of Darth Jar Jar. Scammers specifically use poor spelling and grammatical errors to weed out victims who would be less trusting. Those who are not deterred by lacking language are more likely to believe in the tale the scammer is spinning – and thus more willingly depart with their money. The clumsiness is intentional to lure precisely the right victims into the attacker’s maw.</p>
<p>I collected and brainstormed a few additional offense strategies for attackers who seek to replicate the brilliance of Darth Jar Jar:</p>
<h3 id="meesa-so-noisy">Meesa so noisy!</h3>
<p>One option is to flood EDR systems with noise so that alert fatigue sets in on the part of the defender, letting subtler attacks slip through. The goal is to create noise for events that will receive a higher priority flag within the tool, such as purposefully clumsy kernel exploits – no team with a hundred critical-priority alerts (often called &ldquo;P0s,&rdquo; for priority-zero) would clear them in time to catch your sneakier attack.</p>
<p>Even cleverer would be to throw sloppy attacks over a period of time, while inserting the exact same quieter traffic that you plan to leverage in your real attack, so that the machine learning systems begin baselining it in. After all, Darth Jar Jar maintained his foolish façade for more than just one day!</p>
<h3 id="eicar-car-binks">EICAR-CAR Binks</h3>
<p>A common strategy in security detection is the notion of “alert on the first bad thing, then stop processing” so that there is not a flood of alerts. Thusly, an attacker could send EICAR in the same data stream or file as a real attack so that defenders see the EICAR alert and dismiss it. Then, the darker, sneakier underlying attack will go unnoticed – just as Darth Jar Jar used rambling babbling during the entirety of <em>The Phantom Menace</em> to obscure his devious speech that directly led to the dissolution of democracy.</p>
<h3 id="ex-squeeze-the-data-outta-the-network">Ex-squeeze the data outta the network</h3>
<p>During the rescue of Queen Amidala, Darth Jar Jar proved to be a master of diverting the attention of his enemies to take them by surprise. In the realm of critical infrastructure, an attacker could send a large volume of fake location update requests from SIMs, which would certainly attract the attention of defenders at any telecom provider.</p>
<p>While defenders remain distracted and scrambling, the attacker could then infiltrate the internal telecom network by plugging into <a href="https://en.wikipedia.org/wiki/ENodeB">an eNodeB</a> and moving horizontally to compromise elements such as <a href="https://en.wikipedia.org/wiki/System_Architecture_Evolution#MME_(Mobility_Management_Entity)">the MME</a> or even <a href="https://medium.com/@AlepoTech/home-subscriber-server-hss-82470d3f332">the HSS</a> (think: the master user database). Darth Jar Jar would absolutely approve of deflecting defender attention to outside of their own network to conceal the true threat from within.</p>
<hr>
<h2 id="darth-jar-jar-for-defense">Darth Jar Jar for Defense</h2>
<p>Just as attackers must play the fool to follow the wisdom of Darth Jar Jar, so must defenders. Luckily, many defenders are accidentally foolish, making purposeful foolishness all the more likely to lead attackers to underestimate defenders. While I usually strongly advise against #yolosec strategies, pretending to deploy a #yolosec strategy can perfectly replicate the sinister subterfuge of Darth Jar Jar.</p>
<p>There are fewer public examples in the realm of defense that highlight the gloriousness of a Darth Jar Jar approach. The closest might be the use of honeypots or canarytokens, such as a webserver that appears to be configured in a thoroughly #yolosec manner, creating irresistible temptation for attackers to explore them – and thus alert defenders to the fact that someone is very intrigued by their data.</p>
<p>In ths vein, there are a few Darth Jar Jar-esque defense strategies I collected and brainstormed:</p>
<h3 id="oh-no-yousa-connection-is-slow">Oh, no! Yousa connection is slow</h3>
<p>Once you detect attackers within your network, begin throttling their connections to satellite-link speeds at random. The goal is to make it seem like an unstable system to test how the attacker reacts and alters their strategy – just as Darth Jar Jar “clumsily” handled a booma during the Battle of Grassy Plains to take down an armored assault tank.</p>
<h3 id="where-wesa-executing">Where wesa executing?</h3>
<p>Darth Jar Jar never revealed to his Jedi companions that they were succumbing to his duplicity. Likewise, defenders can avoid revealing that they have not only caught attackers, but are bamboozling them.</p>
<p>For instance, when defenders catch an attacker attempting to pwn a production instance, they can migrate that instance out of production, setting up all the same network connectivity so no change is perceived by the attacker. Then, defenders can begin logging and monitoring everything for later learning (and to inform broader investigation) while spinning up a replacement instance in production to avoid downtime.</p>
<h3 id="mmm-dissen-loverly-data">Mmm, dissen loverly data</h3>
<p>Just as Darth Jar Jar tricked the Jedi into travelling through the core of a planet to make himself indispensable, defenders can trick attackers into going down a heavily monitored path to make it inevitable that they will be caught. For example, defenders can sprinkle cleartext AWS credentials in places that lead to alert traps. Or, defenders can “accidentally” reveal credentials attackers would need to access a seemingly sensitive system – when in reality, there is no valuable data residing in the system, just deep monitoring present.</p>
<hr>
<p>Ultimately, no matter which side of the infosec game on which you fight, I hope that you will adopt the following mantra to let the dark side flow through you, elevating your #basic strategy to one of subtle manipulation and insidious deception – “What would Darth Jar Jar do?”</p>
<p><img src="/blog/img/darth-jar-jar.gif" alt="Gif of Darth Jar Jar peeking through Vader&rsquo;s helmet"></p>
]]></content>
        </item>
        
        <item>
            <title>My Reflections on the 2019 RSA Conference</title>
            <link>https://swagitda.com/blog/posts/my-reflections-on-rsac-2019/</link>
            <pubDate>Wed, 13 Mar 2019 21:28:01 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/my-reflections-on-rsac-2019/</guid>
            <description>Artist’s rendition of how I felt by Thursday morning of the con
Reflecting on my existential crisis during RSAC, I tried to distill what exactly was so troublesome about the conference. The expo floor was less two separate halls, as per years prior, and more like Mordor, with a befouled sprawl connecting Minas Morgul and the Black Gate — but instead of orcs and Uruk-hai, vendors crammed the hallways that used to serve as open breathing space.</description>
            <content type="html"><![CDATA[<p><img src="/blog/img/bad-cyberart-12.jpeg" alt="Very cyber-y skull"><em>Artist’s rendition of how I felt by Thursday morning of the con</em></p>
<p>Reflecting on my existential crisis during RSAC, I tried to distill what exactly was so troublesome about the conference. The expo floor was less two separate halls, as per years prior, and more like Mordor, with a befouled sprawl connecting Minas Morgul and the Black Gate — but instead of orcs and Uruk-hai, vendors crammed the hallways that used to serve as open breathing space.</p>
<figure style="float:right; max-width:40%; padding-left: 10px">
	<img src="/blog/img/infosec-buzzword-bingo.jpg" alt="Kelly Shortridge holding their infosec buzzword bingo card">
	<figcaption>The RSAC Innovation Sandbox’s “natural” lighting (featuring me and <a href="/blog/posts/infosec-startup-buzzword-bingo-2019-edition">my buzzword bingo card</a>)<figcaption>
</figure>
The color of RSAC itself is royal purple — fitting as hosts of this ostentatious banquet — with a splash of cyber-turquoise. The vendors left an abstract expressionist mark bursting with oceanic blues, imperial reds, dramatic gunmetal, and the occasional accent of atomic tangerine. Artfully abstract globes, honeycombs, and glowing orbs were juxtaposed with elegant waves and gently curved lines, mixing familiar shapes with the futuristic mouthfeel of “cyber.”
<p>There was a dizzying sense of perpetual motion, like a spinning top just barely staying upright. Quiet was seemingly anathema — the pestilential cacophony of canned speeches and whizbangs and desperate pleas for attention was unavoidable.</p>
<p>In this vainglorious feast by the information security industry in dedication to itself, experiencing an existential crisis is perhaps an inevitability. The ultimate purpose of information security — ensuring an organization can thrive despite digital risks — was obscured beneath the thick layers of cheap pens dimly glinting, XL men’s t-shirts boldly proclaiming trivialities, and the hollow promises of soothing your fears one badge scan at a time.</p>
<p>But this alone can be rationalized away and not lead to a crisis of faith in the importance of our collective work. These criticisms are true for most trade shows; they are inherently loud and sales-y. What makes the RSA Conference burrow into the brain like a parasite greedily devouring all hope is that the diabolical song and dance is not helping beneficial solutions fall into the right hands.</p>
<p>RSAC is largely successful due to network effects — because everyone seemingly attends, everyone else attends — making it a good place to catch up with a lot of people at once. This reality makes its issues even more problematic; the four that personally drove my distress are:</p>
<ol>
<li><a href="#fud">Hyperbolization of FUD</a></li>
<li><a href="#disconnect">Disconnect between products &amp; personas</a></li>
<li><a href="#personas">Misunderstanding of personas</a></li>
<li><a href="#blocker">Promotion of security as a blocker vs. a compromiser</a></li>
</ol>
<hr>
<h2 id="a-namefudahyperbolization-of-fud"><a name="fud"></a>Hyperbolization of FUD</h2>
<p>In a banquet of distasteful and inane catch phrases and bullet points, one gave me acid reflux like no other—it exemplifies what I am calling the hyperbolization of fear, uncertainty, and doubt (“FUD”). A large EDR vendor’s advertisements around town roughly stated, <em>“It takes a lifetime to build your career, and 5 seconds to lose it.”</em></p>
<p>There was no shortage of FUD around threats, but this tagline directly stokes the fear that someone’s professional life will be over if they let an attacker slip by. It’s tasteless and mostly incorrect, and I find it appalling to imply that someone’s life will be ruined if they don’t buy your product. I also find it lazy; if you can’t sell your product without scaring people to such a degree, perhaps you should make your product inherently matter more to them.</p>
<p>Part of the issue might be that the industry is generally poor at realistic threat modelling, making these doom and gloom buzzphrases compelling. While it’s too much to hope that all vendors could help their customers threat model responsibly, I believe it’s a reasonable expectation to not aim directly at personal fears and not make up scenarios that lack precedence in history or logic. If a vendor must create dystopian sci-fi to justify use of their product, they are doing it all wrong.</p>
<h2 id="a-namedisconnectadisconnect-between-products--personas"><a name="disconnect"></a>Disconnect between products &amp; personas</h2>
<p>My first supposition with regards to the persona problem was a disconnect <a href="https://blog.hubspot.com/marketing/buyer-persona-definition-under-100-sr">between buyer</a> and <a href="https://blog.hubspot.com/marketing/buyer-persona-definition-under-100-sr">user personas</a>. Specifically, that narratives around usability seemed to be keeping the buyer (CISO) in mind, rather than the people who would actually use it (individual contributors (“ICs”). Upon reflection, I think it’s worse than this — that there is a disconnect between the buyer personas and the vendors’ target audience.</p>
<p>By this I mean that the marketing tactics, highlighted characteristics, even the words used all feel targeted towards other sales and marketing professionals, or perhaps venture capitalists (“VCs”). During the conference, I spoke with a large swath of practitioners ranging from CISOs to managers to senior ICs to more junior ICs, and none of them found the booths enlightening or particularly worthy of their attention.</p>
<p>This begets the question — for whom is all this marketing? My prior assumption was that vendors would target the buyer persona (generally the CISO or director/manager-level) at the very least, since they are the people spending the budget. Ideally vendors would also target ICs, who are the ones actually using the product, and whose thumbs up is generally required by the buyer.</p>
<p>But given <em>none</em> of those personas felt addressed by vendors at the RSAC expo hall, who did? To be perfectly frank, I’m not entirely convinced of the answer, but my hunch is that:</p>
<ol>
<li>VCs are dictating marketing/value propositions too much, particularly given they are generally disconnected from customer viewpoints</li>
<li>Marketing people are generally too disconnected from customers &amp; don’t really understand the relevant personas</li>
<li>Infosec is generally horrendously bad at understanding the spectrum of relevant user personas</li>
</ol>
<h2 id="a-namepersonasamisunderstanding-of-personas"><a name="personas"></a>Misunderstanding of personas</h2>
<p>Point #3 above leads to this observation, which is that vendors overall seem to egregiously misunderstand the personas for which they are allegedly building their products.</p>
<p>As I discussed in <a href="https://techcrunch.com/2019/02/13/the-infosec-reckoning-has-arrived/">my TechCrunch article</a>, vendors are building tools and determining the specific problem being solved after the fact — often leading to the need to convince customers that the vendor-invented problem is relevant to their organization. This trend of focusing on tech rather than customer problems extends, I think, to vendor-invented personas, as well.</p>
<p>If you were judging solely based on the RSAC vendor floor this year, you might think the most important user persona in infosec is “SecOps.” There’s little differentiation visible in this “persona” between a SOC analyst straight out of school analyzing low-priority events vs. a SecOps engineer who writes automation scripts for things like <a href="https://slack.engineering/distributed-security-alerting-c89414c992d6">distributed alerting</a> — not to mention a SecOps manager vs a SOC manager and the chromatic variation around all of these titles. And, is their purview <a href="https://medium.com/@sroberts/introduction-to-dfir-d35d5de4c180">just DFIR</a> or other responsibilities, too?</p>
<p>This isn’t to say generalized personas aren’t useful — but I’m wondering if vendors are now treating SecOps as the “person who deals with security events.” If so, then most people in infosec are kind of SecOps depending on how you define “event,” which would thus render SecOps a meaningless term given how different everyone’s workflows are across the range of roles.</p>
<p>Additionally, there were impressively lazy attempts at catering to the DevOps and so-called SecDevOps personas. Security vendors seem to think that making their product available via API means they “integrate with DevOps workflows,” which is either amazingly apathetic or oblivious.</p>
<p>There was also lip service paid to working with existing CI/CD pipelines, but then security vendors still expect DevOps people to go through 20 additional hoops, not realizing that they simply won’t. For instance, please don’t claim you are DevOps-friendly while asking them to install a kernel module on every machine they actively use.</p>
<p>This leads to my assumption (and into my next point) that security doesn’t realize how immaterial they are relative to a team (DevOps) that can justifiably argue that they support revenue-generating activities. And, what’s worse, vendors provide little support for their customers to fight for security’s inclusion in the conversation.</p>
<p>It as if vendors expect that by saying “we secure the development lifecycle!”, security practitioners can convince the organization to install their product. This notion of a security team having the keys to an organizational steam roller is, of course, pure fantasy.</p>
<h2 id="a-nameblockerapromotion-of-security-as-a-blocker-vs-a-compromiser"><a name="blocker"></a>Promotion of security as a blocker vs. a compromiser</h2>
<p>Finally, I think infosec is largely ignoring an important emerging shift, which I believe is inevitable — the transition from security as the “no people” to enablers of the business. Enterprise security only matters to the extent that it is helping preserve the company’s ongoing operations. Anything beyond that feels largely like intellectual vanity to me (this is precisely why I’ve been evangelizing the notion for <a href="/blog/posts/security-as-a-product/">a few years now</a>).</p>
<p>How does this play into RSAC? I argue that the most successful security vendors of late are about removing barriers, in contrast to many security people believing barriers are worthwhile aids in their infosec crusade (and I also suspect that creating organizational barriers provides significant vocational fulfillment among a chunk of security professionals).</p>
<p>To wit, zScaler consolidated old products and made it easier for the organization to access resources without the tedious VPN dance. Okta likewise streamlined access and made a lot of enterprise workflows simpler. Both are now trading at delectably rich multiples (both above 20x <a href="https://www.investopedia.com/terms/e/ev-revenue-multiple.asp">EV/Revenue</a>) — a victory even beyond the fact that they are some of the few information security startups to IPO in recent years.</p>
<p>Ultimately, anyone can say “no” to something —but just saying “no” isn’t actually solving a problem. Figuring out a compromise, like preserving or even improving UX while still ensuring an organization’s security, is a hard problem — the type of problem which should be most intellectually fulfilling.</p>
<p>Security will keep being dismissed by other parts of the organization until it lets go of finding fulfillment through security righteousness and instead finds fulfillment by finding an elegant way to enable the business while still reducing its risk.</p>
<p>One of my favorite examples to cite is John “Four” Flynn and <a href="https://www.youtube.com/watch?v=pY4FBGI7bHM">the tale of implementing 2FA on SSH at Facebook</a>. The security team conducted product-like user research interviews across engineering teams to figure out how SSH was being used — essentially mapping user workflows. The security team’s goal was to add 2FA to SSH, but instead of ramming it through like petulant ayatollahs, they sought to understand the user perspective and determine a solution that would not add friction for engineers.</p>
<p>It was a hard problem, but with a huge payoff; now the engineering teams can trust that security isn’t just trying to make their lives more difficult for sport or quasi-religious fervor. This means the relationship can be more like a <em>partnership</em>, rather than a political battle — the sort of battle security practitioners allegedly detest (likely because they tend to lose it).</p>
<hr>
<h2 id="conclusion">Conclusion</h2>
<p>These issues are not engendered by one constituent of the industry — they just all happen to notably bubble up like a tar pit burping methane in the harsh fluorescent spotlight of RSAC. It is the failure of culture among practitioners, vendors failing to understand their customers’ needs, founders going for cash grabs, and VCs encouraging the noxious sleaze and bamboozlery.</p>
<p>All of this comes, perhaps, from a reticence towards doing the harder, right thing and instead taking the easier path — the one that harvests confusion and fear to seize success that mediocrity could not earn otherwise.</p>
<p><a href="https://swagitda.com/speaking/index.html">I speak a lot</a> about incentives, and, in fairness, there is an abundance of incentives rewarding this mediocrity, but far fewer promoting the more difficult path. CISOs don’t want to speak out against vendors and, in fact, benefit when they are seen as essential in navigating not just the threat landscape, but the vendor landscape as well. Vendors can still find decent M&amp;A exits that make founders and investors happy enough, even if they sell solely within their professional networks and don’t ever find true product/market fit.</p>
<p>And if VCs make enough money from this buffoonery, why should they bother to understand the customer personas better to inform their investment choices? Many VCs have CISO friends, but I know from private conversations that these CISO friends often view the VCs as useful fools who can help them gain advisory or board positions.</p>
<p>If it sounds hopeless, well… I’m not sure it isn’t. But I refuse to <a href="/blog/posts/red-pill-of-resilience-infosec/">give into nihlism</a>. There are absolutely those of us who are fighting to change things, but there is a lot of entrenched power which benefits from keeping these dynamics the way they are in information security.</p>
<p>It will take those willing to risk their power to speak out in the truest form of thought leadership there is. Speaking into a warm and fuzzy echo chamber isn’t thought leadership; bravely challenging the status quo, armed with evidence, is.</p>
<p>We can keep the corporate-friendly cerulean and navy aesthetic, the blustering loudness, and yes, even the free pens, but we need to dedicate these efforts not to the thrill of our industry finally being considered “cool,” but to solving hard problems and protecting organizations in the way they need.</p>
]]></content>
        </item>
        
        <item>
            <title>InfoSec Startup Buzzword Bingo: 2019 Edition</title>
            <link>https://swagitda.com/blog/posts/infosec-buzzword-bingo-2019-edition/</link>
            <pubDate>Wed, 27 Feb 2019 16:57:23 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/infosec-buzzword-bingo-2019-edition/</guid>
            <description>This is the third edition of my Infosec Buzzword Bingo, just in time for 2019’s RSA Conference (RSAC). Rather than relying on my keenly tuned snake oil spidey senses to generate the words populating the bingo card, I took a more data-driven approach this year.
I surveyed 100 companies’ websites[1], the vast majority of which are exhibiting at RSAC and possess VC funding. I did not include any of the large security vendors[2], who probably could populate their own bingo cards across their mastodonian websites.</description>
            <content type="html"><![CDATA[<p>This is the <a href="https://twitter.com/swagitda_/status/912494974779973632">third</a> <a href="https://twitter.com/swagitda_/status/967566556262694912">edition</a> of my Infosec Buzzword Bingo, just in time for 2019’s RSA Conference (RSAC). Rather than relying on my keenly tuned snake oil spidey senses to generate the words populating the bingo card, I took a more data-driven approach this year.</p>
<p>I surveyed 100 companies’ websites<a name="back-1"></a><a href="#cite-1">[1]</a>, the vast majority of which are exhibiting at RSAC and possess VC funding. I did not include any of the large security vendors<a name="back-2"></a><a href="#cite-2">[2]</a>, who probably could populate their own bingo cards across their mastodonian websites.</p>
<p>The idea is to take this with you to RSAC or any other vendor halls at information security conferences this year to see how many times you can win bingo at a single vendor booth! For more fun, <a href="https://github.com/swagitda/infosec-buzzword-bingo/blob/master/cyber-taglines.py">try out my Cyber Tagline Generator script</a> to create your own maniacally terrible buzzword salad (<a href="https://twitter.com/swagitda_/">then @ it to me on Twitter</a>).</p>
<p>Without further introduction, here’s the bingo card in all its glory — read on if you want more analysis on the stats:
<img src="/blog/img/infosec-startup-bingo-2019.png" alt="Infosec Startup Buzzword Bingo card for 2019"></p>
<p>The top word by far this year was <em><strong>automated</strong></em> and its variants — nearly three quarters of all companies used it on their sites in one way or another (e.g. <em><strong>automatically</strong></em>, <em><strong>automation</strong></em>, <em><strong>automates</strong></em>, etc.). There were a few repeats from prior bingo cards, perhaps proving my natural acuity for sensing the buzziest buzzwords. The <a href="https://github.com/swagitda/infosec-buzzword-bingo/blob/master/buzzword-bingo.md">following table</a> of the top 25 buzzwords (the ones on the bingo card) includes the number of companies who cited the buzzword, along with whether the buzzword was on prior bingo cards:</p>
<script src="https://gist.github.com/swagitda/7a55615c8b7889b92a3edaae7e8462e2.js"></script>
<h2 id="which-buzzwords-are-on-the-rise">Which buzzwords are on the rise?</h2>
<p>Let’s start with the words on the bingo card itself. You can’t just enable security people anymore, you must <em><strong>empower</strong></em> them. Seemingly a reaction to CISOs through SecOps analysts complaining about the complexity of security tools, <em><strong>simple</strong></em>, <em><strong>simplifies</strong></em>, and <em><strong>simplified</strong></em> are being used to (proactively ;) assuage concerns.</p>
<p>Allegedly, security professionals now want to <em><strong>discover</strong></em> things, and I suppose with most data lakes being more akin to data swamps, the predilection for adventure that <em><strong>discovery</strong></em> implies is required. And, taking a page from the DevOps world, <em><strong>orchestration</strong></em> is peppered around enough now to create a veritable symphony of infosec startups <em><strong>orchestrating</strong></em> away.</p>
<p>Not quite making it to the bingo card, but still heating up, is <em><strong>collaborate</strong></em> and <em><strong>collaboration</strong></em>. Who knew that infosec teams wanted to work together? And if your security product isn’t <em><strong>optimized</strong></em>, what are you even doing? Note that you do not have to say for what your product is <em><strong>optimizing</strong></em>, just that it is, in fact, <em><strong>optimized</strong></em>.</p>
<p>Finally, solutions for <em><strong>runtime</strong></em> security are growing, which basically is just saying it doesn’t break the computer as it is computing. The fact that this assurance must be stated at all says more about the infosec vendor situation than perhaps <a href="https://techcrunch.com/2019/02/13/the-infosec-reckoning-has-arrived/">even a long thought piece</a> can.</p>
<h2 id="which-buzzwords-are-starting-to-fall">Which buzzwords are starting to fall?</h2>
<p><em><strong>Hunting</strong></em> / <em><strong>hunt</strong></em>, most frequently used with “threat” before it, just barely missed making the Infosec Buzzword Bingo card again this year. I anticipate that it’ll fall even further by next year as the category morphs into SIEM 2.0. While <em><strong>behavioral</strong></em> is still holding strong, <em><strong>anomalies</strong></em> is beginning to wane — it’s much sexier to say you have <em><strong>behavior-based machine learning</strong></em> or <em><strong>AI</strong></em> instead.</p>
<p>As far as threats, they are notably less <em><strong>sophisticated</strong></em>, and less found on the <em><strong>dark</strong></em> web or in <em><strong>IoT</strong></em> devices. You def don’t want to talk about your product as a <em><strong>single-pane-of-glass</strong></em> anymore (try <em><strong>intuitive</strong></em> instead, which is on the rise). And, <em><strong>cloud-based</strong></em> is becoming less relevant as most security solutions move to a SaaSy model. If anything, companies should now specify when they <em>aren’t</em> cloud-based.</p>
<h2 id="which-buzzwords-are-the-weirdest">Which buzzwords are the weirdest?</h2>
<p>Most of the weirdo-words are only used in a handful of companies’ marketing spiels, thankfully. But, a full seven companies used <em><strong>real-world</strong></em>, which, I mean — as far as I know, we aren’t trying to secure hypothetical worlds? I’m being purposefully obtuse (in the Dostoevskyan-fool spirit), since I do understand that too many solutions catch bad stuff only in theory without rigorously testing against what attackers will actually do (or without even really considering this during the product’s conception). But, its usage still makes me sad.</p>
<p>Another odd buzzword was <em><strong>holistic</strong></em>, also cited by seven companies, which is perhaps the most credible buzzword due to its close association with essential “healing” oils. However, the one I hate the most by far is <em><strong>quantum-resistant</strong></em>. For my sanity’s sake, I am grateful only one company chose to use that term.</p>
<hr>
<p><a name="cite-1"></a><a href="#back-1">[1]</a> I scoped it to the websites’ landing and product/platform pages (e.g. no blog content).</p>
<p><a name="cite-2"></a><a href="#back-2">[2]</a> When I say “large” security vendors, think those who are publicly traded, are more than ten years old, or who have entire product “suites.”</p>
]]></content>
        </item>
        
        <item>
            <title>Analyzing the 2019 RSA Innovation Sandbox Finalists</title>
            <link>https://swagitda.com/blog/posts/analyzing-2019-rsa-innovation-sandbox-finalists/</link>
            <pubDate>Tue, 05 Feb 2019 19:02:53 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/analyzing-2019-rsa-innovation-sandbox-finalists/</guid>
            <description>This year’s nominees for the 2019 edition of the RSA Conference’s Innovation Sandbox were announced this morning. As I’m wont to do, I wanted to explore the funding side of these ten startups.
Total Funding Raised &amp;amp; the Latest Stage for each 2019 RSA Innovation Sandbox Finalist ($USD millions)
The median funding raised by all ten startups is $10.5 million (mean of $10.3 million), which makes sense for an early stage-flavored competition.</description>
            <content type="html"><![CDATA[<p>This year’s nominees for the 2019 edition of the RSA Conference’s Innovation Sandbox were <a href="https://www.rsaconference.com/press/98/rsa-conference-announces-finalists-for-innovation">announced this morning</a>. As I’m wont to do, I wanted to explore the funding side of these ten startups.</p>
<p><img src="/blog/img/rsa-sandbox-02.png" alt="Chart of funding raised by RSA Innovation Sandbox finalists"><em>Total Funding Raised &amp; the Latest Stage for each 2019 RSA Innovation Sandbox Finalist ($USD millions)</em></p>
<p>The median funding raised by all ten startups is $10.5 million (mean of $10.3 million), which makes sense for an early stage-flavored competition. Additional analysis is required to compare funding levels of finalists from prior years to see if there is a correlation with those who win the competition.</p>
<figure>
    <img src="/blog/img/rsa-sandbox-01.png"
         alt="Chart of the Distribution of 2019 Innovation Sandbox Finalists, by Funding Stage"/> <figcaption>
            <p>Chart of the Distribution of 2019 Innovation Sandbox Finalists, by Funding Stage</p>
        </figcaption>
</figure>
<p>The distribution of startups by stage is also consistent, with the highest concentration at the Series A stage. Of course, another way to determine startup maturity is through actual temporal age. The median number of months<a name="back-1"></a><a href="#cite-1">[1]</a> since the finalists’ founded dates is 27.5, equating to roughly 2.3 years. The eldest is just shy of four years old.</p>
<p>Category-wise, there is a healthy distribution across sub-sectors. The highest concentration is in DevSecOps-related tools, which range from detecting attacks in modern infrastructure to “API security.” There are also two finalists tackling data protection/privacy. The rest include one startup each tackling anti-fraud, appsec, asset management, firmware/hardware security, and IAM. If <a href="https://twitter.com/swagitda_">you follow me</a>, you know I find <a href="/blog/posts/2019-cybersecurity-predictions/">masochistic pleasure</a> in examining the nature of infosec buzzwords, and the Innovation Sandbox word cloud does not disappoint on this front:</p>
<p><img src="/blog/img/rsa-sandbox-wordcloud.png" alt="Wordcloud of buzzwords from RSA Innovation Sandbox finalists in 2019"><em>“a security platform to automatically protect human fraud from exhaustive enforcement”</em></p>
<p>What is perhaps most peculiar about this group of finalists to those who follow VC funding trends in infosec (hopefully I am not alone in this nerddom), is that there is scant overlap between investors in these startups. Perhaps, like with movie studios and the Oscars, each VC selects the startup in their portfolio they believe is in the strongest position to win. The sole overlapping investor was ClearSky, who led Capsule8’s Series B last August, and also led CloudKnox’s “Venture Round” (which feels very Series A) last October. The full list of lead investors in these ten startups is:</p>
<ul>
<li>Bain Capital Ventures</li>
<li>Bessemer</li>
<li>ClearSky x 2</li>
<li>Foundation Capital</li>
<li>Madrona Venture Group</li>
<li>Mayfield Fund</li>
<li>New Enterprise Associates</li>
<li>PayPal</li>
<li>PSP Growth</li>
<li>Rally Ventures</li>
<li>S Capital</li>
<li>Team8</li>
<li>USVP</li>
<li>Y Combinator</li>
<li>YL Ventures</li>
</ul>
<p>All finalists are based inside of the U.S. Of those, 40% are based in California — New York has two, and Kansas, New Jersey, Oregon, and Virginia have one startup each.</p>
<p>As a final statistic, only one company’s founding team includes any female founders.</p>
<hr>
<p><a name="cite-1"></a><a href="#back-1">[1]</a> Note: Not every startup gives the precise day they were founded, so I used a combination of Crunchbase and LinkedIn data (e.g., the start date the founder lists) to get as close as possible.</p>
]]></content>
        </item>
        
        <item>
            <title>The Cyber Tub: Communicating the Dynamics of Information Security Risk Management</title>
            <link>https://swagitda.com/blog/posts/the-cyber-tub/</link>
            <pubDate>Thu, 20 Dec 2018 22:02:49 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/the-cyber-tub/</guid>
            <description>This is probably how a Cyber Tub looks, right?
People struggle to understand how risk accumulates in complex systems, thereby also not understanding the extent to which risk must be reduced. This misapprehension can lead to “wait and see” decisions that cause a problem to snowball, or mitigations that don’t meaningfully reduce risk, creating the feeling of just barely treading water in your security program.
It is challenging for people to understand risk dynamics conceptually for two primary reasons.</description>
            <content type="html"><![CDATA[<p><img src="/blog/img/cyber-tub.png" alt="A tub covered in Matrix code"><em>This is probably how a Cyber Tub looks, right?</em></p>
<p>People struggle to understand how risk accumulates in complex systems, thereby also not understanding the extent to which risk must be reduced. This misapprehension can lead to “wait and see” decisions that cause a problem to snowball, or mitigations that don’t meaningfully reduce risk, creating the feeling of just barely treading water in your security program.</p>
<p>It is challenging for people to understand risk dynamics conceptually for two primary reasons. First, we are bad at tying inflows and outflows to the current level of risk in a system, as we tend to believe outputs are positively correlated with inputs. For example, from the climate change realm, 63% of MIT graduate students erroneously believed that if you stabilize emissions above the rate they’re being removed, atmospheric CO2 would stabilize.<a name="back-1"></a><a href="#cite-1">[1]</a> If emissions are still higher than reductions, there still will be net pollution — it will just be added at a more stable rate.</p>
<p>Second, we tend to ignore the accumulation of effects from inflows.<a name="back-2"></a><a href="#cite-2">[2]</a> For example, you may reduce the amount you overspend in a given year, but that doesn’t mean your personal debt is being reduced — you must earn a surplus over a period of time to pay down the debt you already accumulated. Ignoring accumulation leads us to underestimate the magnitude of mitigations required to stabilize risk — let alone make a dent in decreasing the risk level towards our goal.</p>
<p>What can we do about this lack of intuitive comprehension? A useful analogy to help people conceptually is a bathtub, with its straightforward inflows and outflows. When discussing information security risk, this analogy can help policy makers grasp the true implications of the decisions they’re making. Too often, mitigations are believed to “solve” the problem, while in reality, the inflows contributing to the problem are still outpacing the benefits from mitigations — but no further action is taken, resulting in continued accumulation of risk.</p>
<p>Thus, I’ve conceived the “Cyber Tub” as a way to better communicate information security risk and ensuring its dynamics — from accumulation to reduction — are well understood. Let’s delve into the analogy.</p>
<hr>
<h3 id="the-spout">The Spout</h3>
<p>Let’s say you have a bathtub already full of water. The bathtub is actually a “Cyber Tub,” and the water already in it represents your risk level — it could include things like your legacy systems or even the risk of credential theft in modern systems. The spout is actively running, adding a steady, hot stream of complexity into the tub. You don’t want the tub to overflow, because in real life, that leads to a state where you want to tear your hair out from all the complexity you must manage, and probably something will go wrong. So what do you do?</p>
<h3 id="the-drain">The Drain</h3>
<p>First, you need to install a drain — the patch management drain, in fact — if you don’t have one already, which is going to be challenging given all the water already in the tub. If you do have a drain, it’s likely clogged with lots of gross hair from people using the tub, so you’re going to have to clean it out manually so it can drain — and you’ll have to do that each time manually when it gets clogged again.</p>
<p>But, of course, you’re very clever, so you decide to install a self-cleaning drain — an automated patch management solution. However, you already know it will take a lot of effort to implement, and it probably won’t work perfectly the first time (and probably not every time in the future, either). So, you perform some calculations to see which helps keep the tub from overflowing more effectively given how many manual uncloggers you have vs. how many auto-drain maintainers you have on your team.</p>
<h3 id="the-bucket">The Bucket</h3>
<p>Regrettably, your drain solution only keeps the tub from filling up more rather than helping the water level go down. Clearly you need a bucket to remove a bunch of water all at once. But where do you get the bucket? Which type of bucket is right? How do you dunk in the bucket without splashing a bunch of water out? Where do you put the water in the bucket after? Do you need multiple buckets? There are lots of things to think about when transitioning to the bucket life.</p>
<p>Think of this like transitioning to a cloud or containerized world — the transition costs will be non-trivial and involve a lot of thinking over how to carefully lift the water without losing any.<a name="back-3"></a><a href="#cite-3">[3]</a> You can also only transition a certain amount of code at a time, so there needs to be a rollout plan as well. After all, even if you can buy a bunch of buckets at one time, it’s unlikely you can dump them all in at once to clear out the tub without something going wrong.</p>
<p>As you can see, there’s a lot of calculation here, including whether the bucket-based transition to cloud / containers can clear out the tub, since we already know the patch management drain will cancel out the complexity faucet, but nothing more. You also can’t forget that managing a bunch of little buckets is different from managing one tub, so you’ll need to consider the potential risks from that, too.</p>
<h3 id="additional-examples">Additional Examples</h3>
<p>To solidify exactly what I mean through this analogy, let’s consider other examples from information security and how they can be viewed through the Cyber Tub lens:</p>
<ol>
<li>A design review by the security team helps steady the water level as you release a new feature or product. By addressing security issues at the design phase, you tackle problems before they go into production and come out of the spout (you can use a threat model to prioritize). You could also require sign-off by the security team before release. Therefore, when a new feature or product is released, it won’t add as much water to the Cyber Tub.</li>
<li>Pentesting only tells you a very rough measure of your water level is — do limited findings mean your app is secure, or instead that your testing team is inadequate? Even if you remedy issues from the results of the pentest, it may only be counteracting the spout slightly more — you can think of a pentest like a leaky bucket that may or may not help. Adopting a continuous testing model instead can act as a healthy drain and hedge against ongoing risk that point-in-time assessments cannot catch.</li>
<li>If you are concerned about credential theft risk, think of it as the water in the bathtub. The drain could represent requirements for complex passwords —perhaps enough to counteract the additional risk of each new credential added. The bucket could be enforcing the use of SSO and a password manager, which will actually lower the level of the risk engendered by the existing pool of credentials.<a name="back-4"></a><a href="#cite-4">[4]</a></li>
</ol>
<hr>
<h2 id="conclusion">Conclusion</h2>
<p>For any problem in the information security risk space, try to think of it in terms of this “Cyber Tub.” Consider these four key questions:</p>
<ol>
<li>What are the inflows that add to the problem?</li>
<li>What can you do to reduce water coming in from the spout?</li>
<li>How can you keep the drain open and draining quickly?</li>
<li>What mitigations will actually make a dent in the problem? What are the best buckets available?<a name="back-5"></a><a href="#cite-5">[5]</a></li>
</ol>
<p>While the Cyber Tub may seem like an overly simplistic analogy, that is part of its beauty — nearly anyone can understand it, as long as they’re familiar with the basics of how a bathtub works. We can’t expect to present facts and figures to non-experts and have them perfectly grasp the dynamic processes around information security risk. Let’s give everyone a helping hand and start presenting information security risk in a way people can actually understand it — a way that leads to smarter decision making.</p>
<hr>
<h2 id="references">References</h2>
<p><a name="cite-1"></a><a href="#back-1">[1]</a> Sterman, J. D., &amp; Sweeney, L. B. (2007). <a href="http://web.mit.edu/jsterman/www/StermanSweeneyClimaticChangeFinal.pdf">Understanding public complacency about climate change: Adults’ mental models of climate change violate conservation of matter.</a> <em>Climatic Change, 80</em>(3–4), 213–238. doi:10.1007/s10584–006–9107–5</p>
<p><a name="cite-2"></a><a href="#back-2">[2]</a> Sterman, J. D. (2012). <a href="http://jsterman.scripts.mit.edu/docs/Sterman%20Sustaining%20Sustainability%2010-2.pdf">Sustaining Sustainability: Creating a Systems Science in a Fragmented Academy and Polarized World.</a> <em>Sustainability Science</em>, 21–58. doi:10.1007/978–1–4614–3188–6_2</p>
<p><a name="cite-3"></a><a href="#back-3">[3]</a> It’s surprisingly difficult to find a succinct explanation for how modern infrastructure can help with information security, outside of vendor drivel. For now, please check out <a href="/blog/posts/red-pill-of-resilience-infosec/">the fulltext of my keynote on resilience in infosec</a>, specifically the “adaptability” and “transformability” sections. You can also view <a href="https://www.leviathansecurity.com/cloudsecurity">these resources by Leviathan</a>, although they are a bit out of date (2015).</p>
<p><a name="cite-4"></a><a href="#back-4">[4]</a> Thank you to <a href="https://medium.com/@HockeyInJune/product-security-14127b5838ba">Julian Cohen</a> for this example.</p>
<p><a name="cite-5"></a><a href="#back-5">[5]</a> You also have to consider the difficulty implementing these mitigations in the context of the stagnant bathwater — the problem — potentially obscuring your path to implementation (a topic for another time).</p>
<p>I also suggest reading: Åström, K.J. and Murray, R.M. <a href="http://www.cds.caltech.edu/~murray/books/AM08/pdf/am07-complete_17Jul07.pdf">Feedback Systems: An Introduction for Scientists and Engineers</a>.</p>
<p><em>Thank you to Julian Cohen, Camille Fournier, and Alex Rasmussen.</em></p>
]]></content>
        </item>
        
        <item>
            <title>My 2018 Reading List</title>
            <link>https://swagitda.com/blog/posts/2018-reading-list/</link>
            <pubDate>Mon, 17 Dec 2018 18:35:02 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/2018-reading-list/</guid>
            <description>My perennial New Year’s resolution is to read one fiction and one non-fiction book per month. I tend to fail, and this year I only averaged 1.33 books per month (which, interestingly, is the same as last year; 2016 was 1.5 per month).
As you can tell from this list, I became a bit obsessed with afrofuturism and am still in awe of the immersive worldbuilding within the genre’s novels I read.</description>
            <content type="html"><![CDATA[<p>My perennial New Year’s resolution is to read one fiction and one non-fiction book per month. I tend to fail, and this year I only averaged 1.33 books per month (which, interestingly, is the same as last year; 2016 was 1.5 per month).</p>
<p>As you can tell from this list, I became a bit obsessed with <a href="https://en.wikipedia.org/wiki/Afrofuturism">afrofuturism</a> and am still in awe of the immersive worldbuilding within the genre’s novels I read. I gravitated more towards fiction this year in general, which meant I snuck in fewer non-fiction books than usual (I did read more academic papers this year, but they’re far more arid).</p>
<p>If you’re looking for more science fiction, speculative fiction, or non-fiction recommendations, check out <a href="/blog/posts/2017-reading-list">my 2017</a> and <a href="/blog/posts/2016-reading-list">my 2016</a> reading lists.</p>
<hr>
<h2 id="fiction">Fiction</h2>
<p><a href="https://www.amazon.com/1Q84-Vintage-International-Haruki-Murakami-ebook/dp/B004LROUW2/">1Q84</a> by Haruki Murakami</p>
<p><a href="https://www.amazon.com/After-Flare-Olukotun-Deji-Bryce-ebook/dp/B0759VMZ66/">After the Flare: A Novel</a> by Olukotun Deji Bryce</p>
<p><a href="https://www.amazon.com/All-Systems-Red-Kindle-Single-ebook/dp/B01MYZ8X5C">All Systems Red: the Murderbot Diaries</a> by Martha Wells</p>
<p><a href="https://www.amazon.com/Black-Gods-Drums-Dj%C3%A8l%C3%AD-Clark-ebook/dp/B0791JV58Z/">The Black God’s Drums</a> by P. Djèlí Clark</p>
<p><a href="https://www.amazon.com/Black-Gods-Drums-Dj%C3%A8l%C3%AD-Clark-ebook/dp/B0791JV58Z/">Children of Blood and Bone (Legacy of Orisha Book 1)</a> by Tomi Adeyemi</p>
<p><a href="https://www.amazon.com/Black-Gods-Drums-Dj%C3%A8l%C3%AD-Clark-ebook/dp/B0791JV58Z/">The Last Wish: Introducing the Witcher</a> by Andrzej Sapkowski</p>
<p><a href="https://www.amazon.com/Obelisk-Gate-Broken-Earth-Book-ebook/dp/B01922I1GG/">The Obelisk Gate (The Broken Earth Book 2)</a> by N. K. Jemisin</p>
<p><a href="https://www.amazon.com/Pale-Vintage-International-Vladimir-Nabokov-ebook/dp/B004KABDSY/">Pale Fire</a> by Vladimir Nabokov</p>
<p><a href="https://www.amazon.com/Stone-Sky-Broken-Earth-Book-ebook/dp/B01N7EQOFA/">The Stone Sky (The Broken Earth Book 3)</a> by N. K. Jemisin</p>
<p><a href="https://www.amazon.com/Tigers-Daughter-Ascendant-Book-ebook/dp/B01MT7C6T7/">The Tiger’s Daughter</a> by K Arsenault Rivera</p>
<p><a href="https://www.amazon.com/Tigers-Daughter-Ascendant-Book-ebook/dp/B01MT7C6T7/">Who Fears Death</a> by Nnedi Okorafor</p>
<p><a href="https://www.amazon.com/Wizard-Earthsea-Cycle-Book-ebook/dp/B008T9L6AM/">A Wizard of Earthsea (The Earthsea Cycle Series Book 1)</a> by Ursula K. Le Guin</p>
<hr>
<h2 id="non-fiction">Non-Fiction</h2>
<p><a href="https://www.amazon.com/Anticipating-Surprise-Analysis-Strategic-Warning-ebook/dp/B008H9Q5IW/">Anticipating Surprise: Analysis for Strategic Warning</a> by Cynthia M. Grabo</p>
<p><a href="https://www.amazon.com/Behind-Human-Error-David-Woods-ebook/dp/B075QFGTNP/">Behind Human Error</a> by David D. Woods, Sidney Dekker, Richard Cook, Leila Johannesen, Nadine Sarter</p>
<p><a href="https://www.amazon.com/Book-Why-Science-Cause-Effect-ebook/dp/B075CR9QBJ/">The Book of Why: The New Science of Cause and Effect</a> by Judea Pearl and Dana Mackenzie</p>
<p><a href="https://www.amazon.com/Complexity-Guided-Tour-Melanie-Mitchell-ebook/dp/B002SAUBWC/">Complexity: A Guided Tour</a> by Melanie Mitchell</p>
]]></content>
        </item>
        
        <item>
            <title>2019 Cyber Security Predictions</title>
            <link>https://swagitda.com/blog/posts/2019-cyber-security-predictions/</link>
            <pubDate>Wed, 05 Dec 2018 20:07:01 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/2019-cyber-security-predictions/</guid>
            <description>Fed up with ridiculous infosec predictions for the upcoming year, I decided to aggregate them all and use the power of Markov Chains to generate my own list. What follows is the result, very lightly edited solely for readability. You can see last year’s edition here.
In 2019, we predict 2019. Cyber espionage, cybercriminals — in 2019, they materialize. What if this is a dangerous reality? For example, consider how the world feels sometimes.</description>
            <content type="html"><![CDATA[<p><em>Fed up with ridiculous infosec predictions for the upcoming year, I decided to aggregate them all and use the power of Markov Chains to generate my own list. What follows is the result, very lightly edited solely for readability. You can <a href="/blog/posts/2018-cybersecurity-predictions/">see last year’s edition here</a>.</em></p>
<p><img src="/blog/img/bad-cyberart-14.jpg" alt="An image of a digital chain"></p>
<p>In 2019, we predict 2019. Cyber espionage, cybercriminals — in 2019, they materialize. What if this is a dangerous reality? For example, consider how the world feels sometimes. According to Ponemon, security leaders around the world feel sometimes.</p>
<p>During 2019 we expect to see an increase in cyber space. The prospects are understatement. If a sophisticated attack involves not one but five top-notch threats synergistically working together, the defense panorama could become very blurry. Security experts have a recipe for disaster.</p>
<p>We predict that criminals will further focus their efforts injudiciously, ignoring the lower severity vulnerabilities with known exploits in favor of largely academic high severity vulnerabilities. In 2019, we will see a version of this fictional attacker.</p>
<p>The purchase of cybersecurity has led to expanding attacks that will become more sophisticated in 2019 and beyond. We will continue to influence societal expectations on security, which will trickle down to companies through hundreds of thousands of vulnerable and easy targets for attackers to profit. Driven by many falling victim to feature misconceptions, more will become key targets. Cyber products that provide consolidated feature sets have a hard time understanding each customer’s specific pain points and the bad guys know this.</p>
<p>In 2019, even more high-profile breaches will push the security and privacy, finally. Security is argued about until we die. That’s a particularly terrifying threat.</p>
<hr>
<h2 id="prediction-1-ai-techniques-attacks-will-result-hackers">Prediction #1: AI TECHNIQUES: ATTACKS WILL RESULT, HACKERS</h2>
<img style="float:right; max-width:40%; padding-left: 10px" src="/blog/img/bad-cyberart-15.gif" alt="Gif of robot saying 'I will destroy humans'">
<p>In this day and age of big data, artificial intelligence is the next weapon. The gold standard in hacking efficiency, weaponized AI offers attackers unparalleled insight into what, when, and where to strike. Attempts to weaponize AI offers attackers actual attacks. Systems could launch coordinated cyber criminals to increasingly AI. Is it a matter of anomalies.</p>
<p>AI could be exploited and could also leverage machine-learning and artificial intelligence and machine-learning technologies. The consistent threat is very real. In 2017, a Vietnamese security group claims to have created a mask that can learn incrementally from data scientists providing frequent feedback.</p>
<p>We predict AI-powered attacks become the keys for email scams. For example, imagine a fake AI-created phishing using AI to aid assaults. Unlike humans, machines can do it in seconds and continue even after business hours. They have gotten smarter about phishing and other human activities such as opening doors. Closer to home, AI will expose the mistakes they’ve made regarding human activities.</p>
<p>Automated systems powered by AI could also be used to evade detection by infrequently trained machine learning engines. This game of cat and machine-learning technology will be an investment in the new year. There will likely be future attacks focused on building robust centers for security breach infringement, but the AI bubble has many experts worried.</p>
<p>In 2019, we will see brute force attacks powered by AI. The attack requires automating out all the less interesting stuff so attackers can focus their resources on such attractive, data-rich environments, with no downtime to these utilities. More corporate attacks based on math will propel this trend forward.</p>
<hr>
<h2 id="prediction-2-the-ai-security-software-has-malicious-intent">Prediction #2: THE AI SECURITY SOFTWARE HAS MALICIOUS INTENT</h2>
<p>Skynet is becoming broader and more expansive. To combat this, organizations have turned to the promise of big data, artificial intelligence (AI), and machine learning. Automated systems powered by AI could help people better understand the tradeoffs involved when they give up personal information in their malicious software.</p>
<p>The fragility of some AI technologies will become the picklock that opens a much larger door. Certain algorithms may be too late. 2019 will demonstrate a lot of the “AI Winter” of 1969, in which Congress cut funding as results lagged behind lofty expectations. AI will bolster security in 2019 to a total of $206.2 billion, up from $175.8 billion in 2016, down to $14 billion by 2025.</p>
<p>The buzz for cybersecurity AI is expected to grow in popularity. As the report notes, the pure-play AI security story also has a dark side — they will start scamming you. In addition, certain algorithms may be too complex to understand what is driving a specific set of security firm activities that are popping up in Cyber Town, USA.</p>
<p>AI start-ups are going to exploit the growth of attacks. Analytics solutions will extort companies with 1,000 or more slippery endpoints. Based on developments we are seeing, this change will come as all teams recognize that cybersecurity AI in the purest sense is nonexistent, and we will continue raging.</p>
<hr>
<h2 id="prediction-3-cloud-will-slip-out-into-the-wild">Prediction #3: CLOUD WILL SLIP OUT INTO THE WILD</h2>
<img style="float:right; max-width:40%; padding-left: 10px" src="/blog/img/the-internet-was-a-mistake.gif" alt="Gif saying 'The internet was a mistake'">
Cloud adoption will begin to expand the world (though many dispute this story). By default, cloud is sensitive data. Also, the internet. In 2019, attackers will hold the internet hostage on a computer disc with Internet written on tape in sharpie.
<p>Cloud adoption is game-changing in the threat equation. Many of the tried and true attacks of five years ago don’t work very well in the cloud. Organizations are rapidly shifting content to the cloud, therefore we predict a shortfall of 3.5 million cyber threats that demonstrates a real demand for these easy pickings.</p>
<p>Organizations will struggle to manipulate public cloud and will experience a massive security priority for 2019. Emerging technologies used to protect the cloud not only help capture the big picture but also are less effective at mitigating. Cloud and DevOps teams’ security experts are worried.</p>
<hr>
<h2 id="prediction-4-criminals-grow-more-confident-in-demanding-that-risks-involve-the-cloud">Prediction #4: CRIMINALS GROW MORE CONFIDENT IN DEMANDING THAT RISKS INVOLVE THE CLOUD</h2>
<p>Cyber criminals will use big-scale platforms to create instead of just one, five top-notch threats in today’s landscape. Such threats would be very difficult for hackers. Attacks are usually centered on the use of one threat. Bad actors concentrate their efforts on iterating and evolving one threat at a time for effectiveness and evasion.</p>
<p>With an attack surface of automated prevention methods, like embedded human microchips, for example, attackers will generate new threats such as AWS and Azure. Large-scale data breaches will be attributed to misconfigured Amazon S3 buckets. This is clearly not the fault of AWS. IDG, for example, calls 2019 “a seminal year” on the criminal to-do list, since criminals can silently steal thousands of open buckets and credentials.</p>
<p>Still, I make a brilliant, contrarian, and very accurate prediction: You might lose the data. There will be surprises, too, says Captain Obvious.</p>
<hr>
<h2 id="prediction-5-iot-powered-distributed-denial-of-cat">Prediction #5: IOT-POWERED DISTRIBUTED DENIAL OF CAT</h2>
<img style="float:right; max-width:40%; padding-left: 10px" src="/blog/img/drone-battle.gif" alt="A gif of a drone preparing for battle">
The security breaches will be IoT. There is an ever-increasing probability that these devices make their vulnerabilities. The Future often uses an IoT botnet, which runs the entire network. In one example, an attacker could compromise or alter a chip or add source code to avoid or delay botnet takedowns.
<p>Another challenge is the newest form of an attack that combines card enumeration with smart gadgets, from plugs to TVs, coffee makers. In transportation, data has been accused of sneaking into a site connected to traffic lights. With IoT growth posing huge unknown risks to enterprises with the internet, which runs entirely in memory without effective mitigation, this tactic works. Refrigerators and washing malware will be undetected.</p>
<blockquote>
<p>“I think the big innovation is in best practice standards for IoT” — Damon Ponemon, Vice President of Technology to Detect Evil.</p>
</blockquote>
<hr>
<h2 id="prediction-6-evolving-definitions-of-privacy">Prediction #6: EVOLVING DEFINITIONS OF PRIVACY</h2>
<p>This year we highlighted privacy, finally, due to the European Union’s mid-2018 implementation of the internet. Nearly every nation has not been able to settle on a standard of constant privacy, which will continue to exacerbate in 2019. Singapore and India are consulting to adopt breach notification regimes, while Australia has already enforced GDPR-like legislation due to lack of attribution and accountability.</p>
<p>The Data Protection legislative and regulatory environment will become the de facto method for spreading malicious scripts directly on targeted subjects and organizations. The U.S. government will give birth to more advanced technology and employee training in order to distribute it quickly and surreptitiously to malware. Congress is already working on an RDP option.</p>
<blockquote>
<p>“Managing privacy will become a huge priority for the C-suite and board” — Prasad Woodridge, More Compliance Officer</p>
</blockquote>
<p>In 2019, black hat hackers will penetrate critical aspects of GDPR to become broadly deployed threats. The internet itself is ripe for the taking by someone with PCI or SOX. Well-crafted emails designed to avoid detection are likely to be life-threatening; however, we’re unlikely to see upticks in legislative and regulatory activity. With this in mind, even an organization that erased event logs and backups to avoid investigation will have to decide whether something that happened was supposed to happen.</p>
<hr>
<h2 id="prediction-7-malware-bots-tend-to-spread-chaos">Prediction #7: MALWARE BOTS TEND TO SPREAD CHAOS</h2>
<img style="float:right; max-width:40%; padding-left: 10px" src="/blog/img/bad-cyberart-16.gif" alt="Gif of someone typing in hacker-y things">
In 2019, we predict malware. Attackers will undoubtedly continue to evolve their tactics to steal credit cards and credentials. Malware authors will turn to either more targeted attacks using embedded chips on printers or use ransom techniques, including the manipulation of memory space and adding arbitrary code. Because the attack landscape continues to evade AI-based solutions, attackers will be able to use this naivete to their advantage and pull off a major attack with ransomware.
<p>There is a race to get the most troubling widespread ransomware-as-a-service. These attacks often have costs far beyond the ransom itself. There is evidence that the author of GandCrab is already working on their marketing campaign to extort companies by threatening the data lakes. What can we do? What is permissible? What if we are missing the reasons synergic threats are becoming more than just real people? We will continue to falter.</p>
<p>In 2019, we’ll see the emergence of new threats such as cryptocurrency and the overwhelming demand for the large amounts of computing. Inevitably, there will be a battle as to which is more convenient than ransomware. An example is WaterMiner, which simply stops its mining process when the consumer is just about die.</p>
<hr>
<h2 id="prediction-8-identity-supply-chain-meets-blockchain">Prediction #8: IDENTITY SUPPLY CHAIN MEETS BLOCKCHAIN</h2>
<p>In 2019, cyber activities collide with physical worlds. New techniques will use attacks on critical infrastructure of blockchain, with a touch of “Huh?”</p>
<p>In 2019, the next vector in attacks will continue — privileged accounts, because bots. Identity is a fundamental shift in risk. Identity providers are exposed to an increase in the Open Authorization standard. Access management solutions are actually the intended malware — one was launched by Fancy Bear, the Russian cyber espionage.</p>
<p>“Edge device” breaches will push the security industry to finally solve the username/password problem. The ineffective username/password conundrum has plagued consumers and businesses for years. AI could be used in the hope that 2019 will see a more concerted effort to replace passwords altogether.</p>
<p>A ‘zero trust’ approach requires an organization and AI-enabled malware. This ‘zero trust’ approach can open up several attack vectors. First, it transfers risk and no one can rest easy. Second, organizations end up creating their own criminal activities. The embrace of Google’s BeyondCorp is a strategic guess by taking intelligence, which will become more clear across the field.</p>
<hr>
<h2 id="prediction-9-nation-state-attacks-will-cause-the-un-to-come-to-some-consensus">Prediction #9: NATION-STATE ATTACKS WILL CAUSE THE U.N. TO COME TO SOME CONSENSUS</h2>
<img style="float:right; max-width:40%; padding-left: 10px" src="/blog/img/computer-fire.gif" alt="Gif of someone setting computers on fire">
2019 might just be the toughest in the United States to date. While a direct cyberwar is not on the horizon, a nation-state will launch a “Fire Sale” attack: electronics on fire. You may remember the fictional concept of a “fire sale” attack from the 4th Die Hard movie, in which a terrorist demonstrated this.
<p>Governments will be fed a false sense of security intelligence from tapped infected machines. Nation-states have launched huge distributed denial of services, Bitcoin mixers, and counter-antimalware services. These attacks mean governments are deeply suspicious of each threat actors’ criminal groups.</p>
<p>Brazil recently passed new process-injections and erased event logs to aid trade wars. North Korea, meanwhile, has allegedly attacked public and privacy needs. We are looking forward to seeing a steady increase in Iranian attackers that will continue to fall further and further behind in competency and integrity.</p>
<hr>
<h2 id="prediction-10-the-public-cloud-will-experience-a-massive-security-attack">Prediction #10: THE PUBLIC CLOUD WILL EXPERIENCE A MASSIVE SECURITY ATTACK</h2>
<p>The worldwide public cloud will experience a massive security attack<br>
The worldwide public cloud will experience a massive security attack<br>
The worldwide public cloud will experience a massive security attack<br>
The worldwide public cloud will experience a massive security attack<br>
The worldwide public cloud will experience a massive security attack<br>
The worldwide public cloud will experience a massive security attack<br>
The worldwide public cloud will experience a massive security attack<br>
The worldwide public cloud will experience a massive security attack<br>
The worldwide public cloud will experience a massive security attack<br>
The worldwide public cloud will experience a massive security attack<br>
The worldwide public cloud will experience a massive security attack<br>
The worldwide public cloud services market is still taking shape, with many brands still looking to develop weapons in the creation of malicious executables.</p>
]]></content>
        </item>
        
        <item>
            <title>Analyzing the Black Hat USA 2018 Business Hall</title>
            <link>https://swagitda.com/blog/posts/analyzing-blackhatusa-business-hall-2018/</link>
            <pubDate>Mon, 06 Aug 2018 18:40:42 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/analyzing-blackhatusa-business-hall-2018/</guid>
            <description>What type of vendors are showing themselves off in the Business Hall? Are they mostly startups? Not quite “mostly,” but 46% of vendors in the hall are indeed VC-backed companies at varying stages of maturity. Privately held companies are a non-trivial segment at 17%, and there are 30 Private Equity-owned companies making up 12% of the hall. There are also 12 companies who are acquisitions, primarily those who were acquired within the past year; booths require being booked far in advance, leaving insufficient time to be assimilated into their acquiror’s booth (if so desired).</description>
            <content type="html"><![CDATA[<h2 id="what-type-of-vendors-are-showing-themselves-off-in-the-business-hall-are-they-mostly-startups">What type of vendors are showing themselves off in the Business Hall? Are they mostly startups?</h2>
<img style="display:block; margin-right:auto; margin-left:auto; max-width:80%;" src="/blog/img/bhusa2018/vendors-type.png" alt="Chart of number of vendors by funding type for the Black Hat USA 2018 Vendor Hall">
<p>Not quite “mostly,” but 46% of vendors in the hall are indeed VC-backed companies at varying stages of maturity. Privately held companies are a non-trivial segment at 17%, and there are 30 Private Equity-owned companies making up 12% of the hall. There are also 12 companies who are acquisitions, primarily those who were acquired within the past year; booths require being booked far in advance, leaving insufficient time to be assimilated into their acquiror’s booth (if so desired).
<img style="float:right; max-width:50%; padding-left: 10px" src="/blog/img/bhusa2018/vc-by-age.png" alt="Chart of number of VC-backed companies by age of last raise"></p>
<p>Nearly half (44%) of VC-backed companies were funded within the past year, shooting up to 82% within the past two years and 92% in the past three. Only 10 companies have not been funded in the past three years, and one could hypothesize that they are considered long in the tooth by their VCs.</p>
<hr>
<h2 id="how-many-vcs-are-dedicated-to-investing-in-infosec">How many VCs are dedicated to investing in infosec?</h2>
<img style="float:right; max-width:50%; padding-left: 10px" src="/blog/img/bhusa2018/fund-numbers.png" alt="Chart of the number of VC funds by companies invested">
The overwhelming majority (69%) of Venture Capital firms are investors in only one company exhibiting in the BH USA 2018 Business Hall. Out of 350 total investors in 118 VC-backed companies, 46% [led](https://avc.com/2013/09/leading-vs-following/) at least one deal — and of those 46%, 71% only led one deal.
<p>I’ve long held a hypothesis that the list of “dedicated” investors in infosec is actually quite small, and that the incredible amount of deal volume we presently see is driven by one-off investors who want to dip their toe in the infosec waters, having seen blazing, FUD-ridden headlines declaring its relevance. The data seem to support this hypothesis.</p>
<p>There are 21 VC firms who participated in four deals or more (i.e. invested in four or more companies exhibiting). Thus, I consider them the most “dedicated.” Data Collective, while following in four deals, did not lead any deals, meaning they just miss the cut to be part of the “Top 20 VCs”:</p>
<script src="https://gist.github.com/swagitda/c27200dedbac7090090d7a0a2fe98ba1.js"></script>
<p>You can explore all of the Venture Capital firms, ordered by number of companies in the Business Hall in which they’ve invested by <a href="https://github.com/swagitda/bhusa2018-bizhall/blob/master/vc-analysis/vc-fund-count-with-names.png">visiting the GitHub repo</a>, or scrolling to the very bottom of this post.</p>
<hr>
<h2 id="what-venture-stage-are-vendors--how-much-capital-are-they-raising">What venture stage are vendors &amp; how much capital are they raising?</h2>
<img style="float:right; max-width:50%; padding-left: 10px" src="/blog/img/bhusa2018/vc-by-round.png" alt="Chart of the number of VC-backed vendors, by latest round">
As you might suspect given the steep price for Black Hat booths, there are few seed-stage companies present. The VC-backed vendors are highly concentrated between Series A and Series C (68% of all VC-backed vendors), which reflects general infosec funding trends, as few companies get funded to the late stage, either being acquired or quietly starved for capital.
<p>Note, “Venture Round” is a nebulous term and can mean basically anything — from earlier stage to later stage — so it should not be interpreted in the same timeline as the Series rounds.</p>
<p>The size of the funding round naturally grows the later stage the company reaches. Note that there are few data points for Series E and Series F rounds, so don’t read too much into the decline in size at Series F (a hypothesis might be that reaching such an exceedingly late stage means investors’ patience has worn thin).</p>
<img style="display:block; margin-right:auto; margin-left:auto; max-width:80%" src="/blog/img/bhusa2018/vc-dollars-by-round.png" alt="Chart of the average size of funding rounds, by stage">
<hr>
<h2 id="how-many-private-equity-firms-are-backing-companies-on-the-floor">How many Private Equity firms are backing companies on the floor?</h2>
<p>There are 30 companies backed by 27 total Private Equity firms in the Business Hall this year. While the majority (81%) are mostly one-off investors (though some are also participants in late-stage VC rounds), there are five PE firms that back two or more companies presenting on the floor:</p>
<script src="https://gist.github.com/swagitda/5115bd90d76dfe7b67029dc3f665c90d.js"></script>
<hr>
<h2 id="how-fresh-is-the-innovation-city">How fresh is the Innovation City?</h2>
<img style="float:right; max-width:50%; padding-left: 10px" src="/blog/img/bhusa2018/innovation-city.png" alt="Chart of Innovation City 'residents,' by type">
Innovation City, with 41 “residents,” has a higher concentration of VC-backed companies than the total population (59% vs. 46%), as well as of privately-held companies (34% vs. 17%). What might be surprising is that there are still two acquired companies and one PE-backed company presenting in Innovation City.
<p>True to its marketing pitch of being a designated area for early-stage companies, the average amount of the latest raise by Innovation City residents who are VC-backed is $11.4mm, in contrast to the overall average of $27.2mm. 58% of residents most recently raised a Series A or Series B, while only 4% most recently raised a Series C or later (vs. 34% in the general VC-backed Business Hall population). Nearly double (25% vs. 14% in the general VC-backed population) raised a “Venture Round,” which again, being a nebulous term, is troublesome to place in the VC funding timeline.</p>
<hr>
<h2 id="how-us-centric-are-the-vendors-at-black-hat-anyway">How U.S.-centric are the vendors at Black Hat, anyway?</h2>
<img style="float:right; max-width:60%; padding-left: 10px" src="/blog/img/bhusa2018/geo-all.png" alt="Chart of all companies, by geography">
The answer is pretty U.S.-centric, at 83% of all vendors in the Business Hall (and 86% of all VC-backed vendors). While I know Brexit hasn’t happened yet, I do consider the UK infosec market somewhat distinct from the EU, as there’s a decently active infosec startup scene there and an emergent VC ecosystem, too. There are 13 (5%) EU-based vendors, but less than half of those (6) are VC-backed. The UK is slightly more VC-weighted, with 6 VC-backed companies out of 10 companies total (4% of all companies).
<img style="float:right; max-width:40%; padding-left: 10px" src="/blog/img/bhusa2018/geo-vc.png" alt="Chart of VC-backed companies, by geography">
Although funding activity is exceptionally strong for Israel-based security startups, there are only 7 Israeli vendors (3%) in the hall this year, 3 of which are VC-backed startups. Given the stark contrast with the funding volume into Silicon Wadi I’ve personally witnessed this year, I suspect it’s either that the companies are too young to have reserved a booth in time for 2018, or that quite a few are playing the classic game of listing HQ in the U.S. so as not to deter customers or investors.
<p>Within the U.S., California makes up nearly half (47%) of all U.S.-based vendors presenting, and over half (52%) of VC-backed startups in the Business Hall. After California, the usual suspects of Massachusetts, New York, and the D.C. area (Virginia/Maryland) round out the bulk of companies, along with growing areas of VC interest like Colorado and Texas.</p>
<img style="display:block; margin-right:auto; margin-left:auto; max-width:80%" src="/blog/img/bhusa2018/state-all.png" alt="Chart of all U.S. companies, by state">
<hr>
<h2 id="how-many-companies-have-some-form-of-name-collision">How many companies have some form of name collision?</h2>
<p>We’re all familiar with the infosec startup tropes, so I decided to see whether the data support it. Unsurprisingly, many companies (13%!) have some form of “Security” or “Secure” in their name. Net (which can include Networks), and Cy (which can include Cyber) present a solid showing as well. More recent tropes, such as “Dark” or “Deep” are less prevalent than I assumed — in fact, Deep only lurks in two vendors’ names.</p>
<img style="display:block; margin-right:auto; margin-left:auto; max-width:80%" src="/blog/img/bhusa2018/name-trope.png" alt="Chart of the number of companies, by trope in name">
<hr>
<h2 id="a-few-notes-on-the-data">A few notes on the data</h2>
<p>Vendors were retrieved from the <a href="http://www.expocad.com/host/fx/ubm/18blckh/exfx.html#exhibitors">Black Hat 2018 Business Hall Floorplan</a>, and exclude any federal agencies, educational organizations, or nonprofits. I also excluded any companies in the Career Zone, as they are aiming to recruit security talent rather than sell products or services — for example, I presume Major League Baseball is not selling the latest Threat Intelligence Automation on the Blockchain.</p>
<hr>
<p>Care to explore the data yourself? <a href="https://github.com/swagitda/bhusa2018-bizhall/blob/master/data-table/bhusa18-bizhall-list.md">The raw table is available on GitHub</a>, as is the <a href="https://github.com/swagitda/bhusa2018-bizhall">general project repo</a> (potentially more to come later!).</p>
<hr>
<h2 id="appendix">Appendix</h2>
<h3 id="exactly-which-vcs-funded-exactly-how-many-companies-exhibiting-in-the-black-hat-usa-business-hall-this-year">Exactly which VCs funded exactly how many companies exhibiting in the Black Hat USA Business Hall this year?</h3>
<img style="display:block; margin-right:auto; margin-left:auto" src="/blog/img/bhusa2018/fund-names-tall.png" alt="List of VCs, sorted by number of business hall vendors funded">
]]></content>
        </item>
        
        <item>
            <title>The Red Pill of Resilience in InfoSec</title>
            <link>https://swagitda.com/blog/posts/red-pill-of-resilience-infosec/</link>
            <pubDate>Wed, 01 Aug 2018 17:26:47 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/red-pill-of-resilience-infosec/</guid>
            <description>What follows is the full text of my keynote, also available as a video and as slides.
 There has been insufficient exploration of the first principles of resilience in the context of information security, despite the term being superficially peppered in our common discourse. Too often, resilience is conflated with robustness — to the detriment of us all.
To state more poetically, through the pen of the notable fantasy author Robert Jordan referencing one of Aesop’s fables, “The oak fought the wind and was broken, the willow bent when it must and survived.</description>
            <content type="html"><![CDATA[<p><img src="/blog/img/resilience-01.jpg" alt="Image of two hands clasping each other"></p>
<p><em>What follows is the full text of my keynote, also available as <a href="https://www.youtube.com/watch?v=ux--pHFpeac">a video</a> and <a href="https://swagitda.com/speaking/Red-Pill-of-Resilience-Shortridge-Countermeasure-2017.pdf">as slides</a>.</em></p>
<hr>
<p>There has been insufficient exploration of the first principles of resilience in the context of information security, despite the term being superficially peppered in our common discourse. Too often, resilience is conflated with robustness — to the detriment of us all.</p>
<p>To state more poetically, through the pen of the notable fantasy author Robert Jordan referencing one of Aesop’s fables, <em>“The oak fought the wind and was broken, the willow bent when it must and survived.”</em> To speak of protection without resilience is to believe you can always beat the wind. To speak of deterrence without resilience is to believe you can deter the wind from blowing at all.</p>
<p>There are times when attacks may be deterred or halted before damage is wrought, but one cannot always predict which way the wind will blow. We cannot predict the adversary we will face and the amount of resources they are willing to expend to compromise our systems.</p>
<p>Protection or deterrence can serve as a valuable tactic to grant some level of peace, but resilience — the ability to absorb change and survive — is the foundation on which survival rests. Again, far more poetically than I could ever say, Generalissimo <a href="https://en.wikipedia.org/wiki/Chiang_Kai-shek">Chiang Kai-shek</a> of the Republic of China advised, <em>“The more you sweat in peace, the less you bleed in war.”</em> Attempt the peace, but assure you can still survive the war.</p>
<p>But the discourse about resilience in information security has, to date, been far from poetic. Rather, it’s been sprinkled as a buzzword, floating along at a shallow level primarily in discussions of cyber insurance and how companies can transfer risk by buying policies. I believe this is a waste of its potentially torrential conceptual power. Resilience is ultimately about accepting reality and building a defensive strategy around reality.</p>
<p>As in the Matrix, resilience serves as the red pill — once you accept the reality, it’s impossible to go back to a strategy that ignores it. My goal in this talk is to show you how digging into this heart of resilience can drive a paradigm shift in how we architect security strategy (and I don’t throw the term “paradigm shift” around lightly).</p>
<p>I’ll first explore why the time for the resilience paradigm is nigh, and how our grief as an industry has led us to this point. I’ll next briefly share the etymology of resilience. Its application to information security is one of the newest, and there exists a rich history of its use in other domains — a history worth exploring to see if there are principles and findings to be shared.</p>
<p>Information security is not the only complex system, and ecological systems dealing with climate change and urban areas dealing with natural disasters represent analogical systems in which dynamics are nearly impossible to predict, and the number of interrelating factors is prohibitive to enumerate.</p>
<p>This cross-domain research presents a concept of resilience based on robustness, adaptability, and transformability. I’ll cover these three concepts in detail so we can understand how they fit under the umbrella of resilience. I’ll expand on this cross-domain lens, and it will serve as the one through which I’ll examine what resilience means in information security.</p>
<p>I am humbly attempting to define and establish a notion around what resilience means for information security — both in an intellectual and practical sense. I would be shocked if all of my thinking is on the mark. More than anything, I desperately want to encourage a discussion of first principles around resilience, and to begin a fruitful conversation around how practical implementations of resilience ideology for defensive security should look. I believe we have a fighting chance.</p>
<hr>
<h2 id="stages-of-grief-in-information-security">Stages of Grief in Information Security</h2>
<p><img src="/blog/img/resilience-02.jpg" alt="Image of a burning rose"></p>
<p>But first, why is there rising talk about the term “resilience,” despite the industry not having solidly established what it means? I propose that it is the result of the final stage of grief — acceptance — of the fact that there is not, and likely will not ever be, such a thing as an un-hackable organization or system.</p>
<p>Over the past twenty years, the infosec industry has grieved the fact that companies are ever-vulnerable to attack. Very little can be done against the latest exploit or attack vector that is currently unpublished and unknown. The industry has not fully coped with this grief. Like most grief, it isn’t a linear process, and these cycles have ebbed and flowed at various times in the industry’s history.</p>
<p>The first stage of grief is <strong>denial</strong> — clinging to a false, preferable reality. This manifested as companies being hesitant to deploy security solutions at all, believing that they weren’t truly at risk.</p>
<p><strong>Anger</strong> — recognizing the denial cannot continue, and becoming frustrated — seeing security as an unwanted necessity. This manifested in harsh penalties and legislation, prosecuting and punishing vulnerability researchers — even ones doing work for free or disclosing responsibly.</p>
<p><strong>Bargaining</strong> — the hope that the cause of grief can be avoided — resulted in the explosion of new security tools in an attempt to stop the problem</p>
<p><strong>Depression</strong> — despair at the recognition of the predicament — led to the refrain of more recent years in the vein of, “You’re going to get hacked, there’s nothing you can do about it.”</p>
<p>Finally, <strong>acceptance</strong> — the stage into which I believe we are now transitioning, understanding that there is an inevitability of successful attack, but recognition that there is an ability to prepare and that not all is hopeless.</p>
<p>Unfortunately, I fear the bargaining stage has set us up for a challenging road to implementing acceptance. The explosion of security tools in an attempt to avoid the problem has resulted in an untenable <a href="https://en.wikipedia.org/wiki/The_Market_for_Lemons">market for lemons</a> in which tools and services are prescribed regardless of real need.</p>
<p>Fear, uncertainty, and doubt (FUD) specifically preys on this desperation to bargain, and its use by marketing departments is little different than selling hope of a cure to those who are chronically ill and in their own bargaining stage of grief through alternative, disproved methods. More simply put, the bargaining stage is the demand for which snake oil is the supply.</p>
<p>The resulting depression is unfortunately not the antidote for snake oil — security nihilism is an inaccurate conclusion and does little to incentivize practitioners to pursue more resilient strategies than unproven ones. Therefore, in this blossoming acceptance phase, it is important we have a conversation about what actually works — and to begin, I’d like to delve into what resilience has meant before we as an industry began to espouse it.</p>
<hr>
<h2 id="etymology-of-resilience">Etymology of Resilience</h2>
<p>Up until the early 19th century, the primary meaning of resilience was to “rebound.” Its first use in the context of engineering was in 1858, to imply strength and ductility, or a material’s ability to stretch under tensile stress.<a name="back-1"></a><a href="#cite-1">[1]</a> The abstraction from this physical characteristic — the time it takes for a system to return to a pre-determined, single equilibrium — is the one which has persisted in the common understanding of resilience.</p>
<p>However, in the 1970s, resilience began being used in psychology — understood as a process of changing current behaviors to cope with an adverse condition, for reverting to a prior psychological state post-incident is unrealistic and can actually represent unhealthy coping strategies. The 1970s also saw the beginning of resilience’s use in ecology, but over time, the concept gradually expanded into use across the social sciences and with the two domains’ coupling, or socio-ecological systems.</p>
<p>Most recently, it began to be applied to climate change adaption in the early 2010s, including the natural disaster risk management space due to increases in natural disasters that by all evidence are caused by climate change.</p>
<h3 id="what-does-resilience-mean-for-complex-systems">What does resilience mean for complex systems?</h3>
<p>A complex system is one in which many of its underlying components interact with each other, and one in which it is very difficult to predict behavior. More simply put, it is a system with non-linear activity in the aggregate. Examples of complex systems in our daily lives include our universe, our planet’s climate, our cities, our brains, and even living cells.</p>
<p>Information security is also complex system. Defensively speaking, it is plagued by an inability to predict attacker actions, and it also consists of highly interconnected, dynamic relationships. Both sides of the security equation — defenders and attackers — are human. But there are additional relationships beyond the direct conflict, including users, governments, software vendors, service providers, and so forth. To unfurl these relationships and attempt to fit them into a predictive model is very simply prohibitive.</p>
<p>The first application of resilience through the lens of complex systems was by C.S. Holling in 1973, an ecologist who was one of the founders of ecological economics. Ecological resilience, he said, is measured by the amount of change that could be absorbed before the system’s underlying structure changes.<a name="back-2"></a><a href="#cite-2">[2]</a> He asserted that an ecological system can be highly resilient, but also exhibit a high degree of instability — and, in fact, that the proper reaction of an ecological system was to continually adapt, rather than attempt to return to a static equilibrium.[1]
Heidelbach, W. (September 28, 2016). Chestnut.</p>
<p>For example, eastern North American forests were once full of chestnut trees until a chestnut blight in the first half of the 20th century wiped them out.<a name="back-3"></a><a href="#cite-3">[3]</a> However, oak and hickory trees began spreading in its stead. The forests changed in appearance and composition, but still survived as forests.</p>
<p>Evolutionary resilience, borne from analyzing socio-ecological systems, operates under the assumption of complex systems that co-evolve, focusing on adaptation and transformation. Rejecting the idea of thresholds within which a system should fluctuate, it instead suggests multiple levels of controls and the ability to adapt the status quo by reorganizing or regenerating around the change, thereby creating a new status quo.</p>
<p>For example, communities can diversify their agricultural landscapes and production systems, designating some areas for soil conservation and organic agriculture while promoting multicropping in others. They can protect some forested areas while designating others for the community and focusing reforestation efforts there.</p>
<p>This notion of evolutionary resilience can be summarized as consisting of three central characteristics: robustness, adaptability, and transformability.<a name="back-4"></a><a href="#cite-4">[4]</a> The core notion is that in order for a complex system to be resilient, it must be able to withstand a shock, adjust so as to incur less damage, and be open to challenging previous decisions and goals.</p>
<p>I will be keeping in mind these three core characteristics in the context of information security. With robustness, you must be able to withstand an attack; with adaptability, you must be able to adjust your environment so you incur less damage when attacked; with transformability, you challenge your existing assumptions and decisions, and potentially migrate from existing infrastructure as well as defensive strategies or current methods used in the way you model and understand your threats.</p>
<figure style="float:right; max-width:40%; padding-left: 10px">
	<img src="/blog/img/resilience-03.jpg" alt="Picture of Hurricane Harvey's Eye">
	<figcaption>NASA/NOAA. (August 26, 2017). Hurricane Harvey’s Eye.<figcaption>
</figure>
<p>In most domains, robustness proved dominant in defensive strategy, and can be linked to the concept of engineering resilience — a mistake from the evolutionary resilience perspective. For example, barriers are a form of robustness, blocking storm surges. However, as seen recently with Hurricane Harvey, the primary source of damage was flooding from ongoing rain — highlighting the need for adaptability and transformability to incur less damage going forward and rethink your existing strategies.<a name="back-5"></a><a href="#cite-5">[5]</a></p>
<p>Instead, evolutionary resilience must also include adaptation and dynamic change towards the goal of preservation, with robustness as an ingredient rather than the sole objective.</p>
<p>Although the expression, “it’s not about the destination, it’s about the journey” is somewhat trite, it’s quite true for resilience. Resilience must be framed as a continuous, evolving, but sustainable process rather than a goal. As ecological economics scholar Peter Timmerman described, resilience is the building of “buffering capacity” into a system, to improve its ability to continually cope going forward.<a name="back-6"></a><a href="#cite-6">[6]</a></p>
<p>A focus only on robustness can also lead to a misleading presentation of the problem as one only based on reducing the risk itself. As in the previous example, the problem could be seen only as, “how can we withstand the hurricane?” instead of “we know the hurricane will hit us, how can we change so that it doesn’t damage our community as much?” This highlights the contrast between robustness and the adaptability and transformability characteristics, which accept that the risk will exist, and instead stress the need to reduce the potential damage from the risk and restructure around the risk.</p>
<p>Furthermore, the efforts around attack prediction represent yet another symptom of collective grief — it’s an endeavor to regain the illusion of control. I’ve given another related presentation at length about <a href="https://swagitda.com/speaking/Dangerous-Folly-Attack-Prediction-Shortridge-Art-into-Science-2018.pdf">why attack prediction should not be our goal</a>, so I will not elaborate further here. Suffice to say, prediction was attempted in other complex systems and not only failed miserably, but wasted precious time, money, and brainpower that could have been spent on a pragmatic aim: resilience — the need to design systems under the assumption the negative shock will not be predicted. As eloquently stated by Susan Elizabeth Hough<a name="back-7"></a><a href="#cite-7">[7]</a>,</p>
<blockquote>
<p>“A building doesn’t care if an earthquake or shaking was predicted or not; it will withstand the shaking, or it won’t.”</p>
</blockquote>
<p>While our industry has come to accept that there are many “unknown unknowns,” our strategy is still one based in hubris — that we can save ourselves in a breach with systems that can withstand unknown risks at unknown times with unknown faces. The evolutionary resilience approach embraces these unknowns, understanding that change is inevitable — ensuring the system survives by absorbing these unknown changes, naturally adapting and reorganizing around this unknown risk, keeping the option open of bearing its own new, unknown face.</p>
<hr>
<h2 id="robustness">Robustness</h2>
<p><img src="/blog/img/resilience-08.jpg" alt="Image of a bridge"><em>Image by <a href="https://unsplash.com/@spoony">Hieu Vu Minh</a></em></p>
<p>Robustness involves withstanding and resisting a negative event. Engineering used the concept of resilience only in terms of robustness, measured by how long it takes a system to return to its equilibrium after a shock. However, experiencing an acute stress event implies the normal state was vulnerable to the stress, and that it is thus an “undesirable state to go back to because it would perpetuate this vulnerability.”<a name="back-8"></a><a href="#cite-8">[8]</a></p>
<p>In disaster recovery, it’s dangerous to present the problem of flooding, for example, as simply one about excess water. If it’s simply about a physical issue, then solutions are presented that are restricted to just the physical issue. In reality, flooding is a problem because of people, who understandably don’t want to lose their homes or drown. It is unnecessarily restrictive to only consider technical solutions to address the excess water, rather than broader solutions to address the problem in a societal context.<a name="back-9"></a><a href="#cite-9">[9]</a></p>
<p>When it is believed that a technical control will help prevent a shock, then it tends to lead to larger potential damage. This is called the safe development paradox.<a name="back-10"></a><a href="#cite-10">[10]</a> The reason why it’s a paradox is that the stability and presumed safety gained by building a structural mitigation to the problem actually allows risk to accumulate over time due to the false sense of security, leading to a higher chance of catastrophic consequences.</p>
<p>The safe development paradox represents a maladaptive feedback loop — once a structural mitigation is in place, more development happens where it should not.<a name="back-11"></a><a href="#cite-11">[11]</a> As the development becomes entrenched, the need for structural mitigations becomes even greater — and once the mitigation is in place, more development occurs.</p>
<figure style="float:right; max-width:40%; padding-left: 10px">
	<img src="/blog/img/resilience-04.jpg" alt="Picture of pinecones burning">
	<figcaption>Picture by <a href="https://unsplash.com/@thomasbormans">Thomas Bormans</a>.<figcaption>
</figure>
<p>When fires are suppressed in forests that are fire-adapted, fuel builds up in the form of trees or shrubs.<a name="back-12"></a><a href="#cite-12">[12]</a> As more time passes without a fire, the probability of a ruinously-intense fire grows, posing more danger to nearby human settlements. This is exactly what happened in the mid-1990s in Florida as urban development expanded into fire-adapted pine forests and enjoyed trees and shrubs in their yards.[12] The result was fires during dry periods that resulted in higher damage than usual, destroying many homes in the process.</p>
<p>In security, implementing technical controls can lead to increased damage as well. Retroactively hardening or patching legacy systems in which vulnerabilities are frequently found, can lead to further development on top of these systems, and further entrenchment of those systems within the organization. Feeling like the threat is being prevented leads to development that relies on that assumption — and thus isn’t designed to absorb an attack.</p>
<p>In flood risk management, it’s known as the “levee paradox.”<a name="back-13"></a><a href="#cite-13">[13]</a> Building a levee can lead to a sense of the problem being prevented, supporting further development and construction on the risky floodplain.[9] For example, less than 3% of people living in Illinois in floodplains with levees in place carry flood insurance.[13] The levee clearly lowers people’s awareness of the risk and ability to respond appropriately to it.<a name="back-14"></a><a href="#cite-14">[14]</a></p>
<p>When implementing a robustness control, it’s essential to ensure that it isn’t encouraging further development within a vulnerable system that leaves it open to cataclysmic risk when the control fails. Don’t focus just on resistance in your controls. Doing so will simply “treat the symptoms of bad planning with structures.”[11]</p>
<p>There’s also a lesson here for cyber insurance. Back to the levee paradox, oftentimes areas with levees in place aren’t categorized as official floodplains. This means that homes or offices in those areas don’t have flood-related insurance requirements. The clear lesson I see is: firms offering cyber insurance should consider very carefully whether they exempt companies from certain requirements based on technical controls being in place.</p>
<p>Related to the safe development paradox is the fact that preventing a system from negative exposure means that the system will only function in the artificially stable state. In the levee paradox, it actually creates an artificially stable system which can only survive in dry conditions.</p>
<figure style="float:right; max-width:40%; padding-left: 10px">
	<img src="/blog/img/resilience-05.jpg" alt="Picture of coral">
	<figcaption>Picture by <a href="https://unsplash.com/@doto">Linus Nylund</a>.<figcaption>
</figure>
<p>Another example is with coral reefs. Marine reserves are maintained to protect coral from the damaging effects of climate change, such as ocean acidification and thermally-induced coral bleaching. However, unprotected coral actually proves more resilient to climate disturbance, since they’ve faced ongoing degradation due to exposure to the stressor and thus recomposed to have more disturbance-tolerant species.<a name="back-15"></a><a href="#cite-15">[15]</a></p>
<p>In information security, you must likewise expose your systems to stressors. Even if you’re building something to be internal-only, like APIs, you should design them with the same threat model as an externally-facing service — for instance, making sure you have data sanitization. Test your systems as if they were externally-exposed, to see if they are sufficiently resilient to global stressors. If it would take years to rebuild, reconsider what data you allow within the system.</p>
<p>The overwhelming focus to date in information security has been on robustness — how to withstand or resist an attack, before rebounding back to “normal.” The traditional components of security — firewalls, anti-virus, system hardening — are all components of a robustness strategy. Even when examining how startup security products are marketed, the words “stop,” or the more creative “thwart” are used, implying an improved ability to withstand an attack.</p>
<p>Remediation even plays into this singular focus on robustness. The goal of remediation within security is to most often fix any vulnerabilities, and, ideally, to return to “business as usual” by reversing damage from an attack. As we saw with the Equifax breach, there is absolutely no chance of “business as usual” when immutable data is compromised. Penetration tests often solely focus on vulnerabilities and what is needed to fix them, rather than proposing new technologies or architecture that would prove less vulnerable long-term.</p>
<p>Other domains have typically held this singular focus, as well. The engineering-led approaches sought to defy nature itself rather than allow the system to flux with nature. For example, the single equilibrium in flood risk management is to have dry conditions in floodplains so that people can continue living in them. Dikes, storm-surge barriers, and dams are all attempts to withstand a flood, and reflect engineering resilience approaches. Their goal is to keep the same artificial equilibrium, in spite of the water system’s natural behavior.[9]</p>
<p>An engineering-only focus leads to the current challenge of companies needing to constantly stay up to date on patches, but facing many hurdles in doing so — and having this be their primary line of defense. The model that must be embraced is one in which the system can survive even if patches aren’t immediately updated, or users still click on phishing links. Your systems must survive even if users download a pdf.zip.exe.</p>
<p>As we saw with coral, without palpable vulnerability through exposure to risk, it is unlikely that resilience will develop.[11] You need to assume that attackers will gain access to a system, and figure out how to reduce the impact. You need to actually practice and embrace disaster recovery, rather than just having a plan.</p>
<p>With all that said, robustness is absolutely important to resilience. But robustness needs to be performed correctly. Drawing from flood risk management, diversity is a cornerstone of robustness — there needs to be layers of controls and diversity of solutions.[9] For example, there are storm surge barriers, dikes, and dams for flood prevention.</p>
<figure style="float:right; max-width:40%; padding-left: 10px">
	<img src="/blog/img/resilience-06.jpg" alt="Picture of New York City">
	<figcaption>Picture by <a href="https://unsplash.com/@mdisc">Michael Discenza</a>.<figcaption>
</figure>
<p>New York City has published guidelines for climate change resiliency which also recommend a combination of controls. For example, for dealing with excess heat, they recommend backup generators to hybrid-power systems, using systems with higher heat tolerance, as well as passive cooling and ventilation through window shades or high-performance glazing.<a name="back-16"></a><a href="#cite-16">[16]</a></p>
<p>Diversity of controls helps provide redundancy in uncertain conditions. When complementing measures are in place, it’s less likely that there will be catastrophic damage through the failure of a singular control. But, the tradeoff is between efficiency and effectiveness. The easier route with lower upfront costs is to implement a single control. The effective route is to implement layered controls, which may cost more now, but will pay dividends in reduced consequences long-term.</p>
<p>I don’t believe this will be a new concept for many of you. For example, you could deploy a so-called APT-blocking appliance (aka the BlinkyBoxTM) on your network that purports to stop all attacks. However, what then happens when legitimate credentials are used to access a cloud-based service? Or, as we’ve seen recently with Kaspersky, what happens when the APT-blocking-box is hacked by the APT itself to gain access?</p>
<p>Diversity can also be seen through the lens of systems. While we think of fragmentation generally as poor to have, particularly in the context of asset management, there is an argument in its favor. Shared hosting providers can increase correlated risk. If there is a breach at one provider, or vulnerability in a key component or library used across all applications, then your risk exposure is far greater than it might have been otherwise.</p>
<p>The financial crisis in 2008 serves as a pertinent example of the dangers of ignoring correlated risk. There is something to be said for ensuring you have some level of diversity in your architecture. I am by no means the first to suggest that heterogeneity is important — Dan Geer was fired from @stake in 2003 for making that suggestion, specifically in regards to Microsoft’s hegemony.<a name="back-17"></a><a href="#cite-17">[17]</a></p>
<p>This sort of diversity also plays into the efficiency vs. effectiveness tradeoff. However, efficiency can actually lead to a more limited space in which you can operate. Being able to function using fragmented technologies and controls will ensure you can adapt much better to uncertainty. Systems diversity, through this lens, can provide the instability that can ensure survival. I posit that it is up for debate whether it is more optimal to have manageability through uniformity or limited impact of any one stressor through diversity.</p>
<p>Thinking in decision trees can help ensure robustness through proper diversity of controls. I’ve discussed decision trees towards information security strategy in prior talks, <a href="https://swagitda.com/speaking/us-17-Shortridge-Big-Game-Theory-Hunting.pdf">most notably at Black Hat</a>. Briefly, the goal should be to <a href="/blog/posts/choice-architecture-infosec-blue-teams">walk through what steps</a> an attacker would take to reach their goal in your organization. Naturally, there is not just one path an attacker will take; you have to consider what path they will take if they encounter a mitigation as well. From there, you can begin determining what cascading controls are necessary in order to raise the cost to the attacker as much as possible.</p>
<p>Raising the cost to the attacker serves as a bridge between robustness and adaptability. As frequently referenced, Dino Dai Zovi said, “Attackers will take the least cost path through an attack graph from their start node to their goal node.”<a name="back-18"></a><a href="#cite-18">[18]</a> If you can raise attacker cost, you can begin deterring attackers. Attackers will need greater resources and a greater level of sophistication if you do so. One way to raise cost is through robustness with strong, diversified controls. Another way is through adaptability.</p>
<hr>
<h2 id="adaptability">Adaptability</h2>
<p><img src="/blog/img/resilience-09.jpg" alt="Image of a chameleon"><em>Image by <a href="https://unsplash.com/@_cecilencieux">Cécile Brasseur</a></em></p>
<p>Adaptability concerns reducing the costs of damage incurred and keeping your options open to support transformability. The evolutionary approach is one in which the assumption is that conditions will naturally change over time, and thus the system itself needs to incur long-term change. Reversion to the preexisting state is not necessarily — and often wholly — undesirable.</p>
<p>The Intergovernmental Panel on Climate Change (IPCC) highlights the need for realism and warns about the dangers of incremental changes under the guise of adaptation.<a name="back-19"></a><a href="#cite-19">[19]</a> They specifically recommend questioning underlying assumptions and existing structures, acknowledging the inevitability of macro-level change, and making managed transformation the goal. Pretending you’re adapting while only undergoing incremental change creates a false sense of security — similar to the safe development paradox. You may alleviate symptoms in the short-term, but you can only cultivate resilience through meaningful change towards adapting to reality.</p>
<figure style="float:right; max-width:40%; padding-left: 10px">
	<img src="/blog/img/resilience-07.jpg" alt="Picture of a panda">
	<figcaption>Picture by <a href="https://unsplash.com/@djmle29n">Debbie Molle</a>.<figcaption>
</figure>
<p>A macro-level example of adaptability is in the realm of climate change. While traditional protection strategies for wildlife at risk due to climate change have been focused on preserving their existing habitats, more recent research proposes alternative approaches. Protected areas are in static locations, and tend to become increasingly isolated, leaving nowhere to go. Preserving a species in such an isolated, at-risk area results in “genetic ghettos.”<a name="back-20"></a><a href="#cite-20">[20]</a> The species becomes increasingly acclimated to this limited environment, which consequently staves off any potential for evolutionary adaptation.</p>
<p>Instead, wildlife naturally has shifted ranges in response to previous instances of climate change, in which preferable conditions are “tracked.” Recommendations now include helping connect disparate ecosystems together so that wildlife can more easily migrate. For example, in areas with urban environments, a narrow strip of land can be preserved, or another sort of route created, so that populations can connect to a different climactic area.</p>
<p>One can think of existing territories like legacy systems. We try to “preserve” these habitats through patching and retroactive hardening. The adaptive model from nature is to move to new territories that fit preferred conditions — ones in which the species can survive — which is similar, in effect, to moving to new infrastructure or a new mode of operation that is more resilient to the new threat.</p>
<p>As a highly tangible example, consider the case of database queries. The organization’s status quo might be that they use inline PHP code within the HTML of their web apps to perform database queries. If an injection vulnerability is discovered in an instance of this inline PHP code, they’ll fix that instance, but likely not conduct a full review across all of their inline PHP code. In this case, they’d be improving robustness by patching the code, but they’d be returning to their so-called “stable equilibrium.”</p>
<p>In contrast, embracing adaptability would mean the organization should instead remove inline queries, and use one class that accesses the database. This one class would be completely responsible for all sanitization. The result is not only that now you only have to fix issues in one place, but also that developer turnover can be managed — rather than writing their own new inline code, they can use the new library that you’ve built instead.</p>
<p>Preservation can also lead to misleading indicators of resilience. For example, static measurements such as high coral cover or fish abundance can be poor indicators of coral reef resilience.<a name="back-21"></a><a href="#cite-21">[21]</a> These measures can just reflect favorable conditions in the past and not accurately reflect when resilience is being eroded.</p>
<p>Likewise, in information security, organizations using a library with no known vulnerabilities may currently treat their security model as complete and not perform continuous revisions. The issue is that the release of new vulnerabilities or attacker methods is not always well-publicized. Instead, organizations should frequently review their security posture to ensure threat models are not based on past favorable conditions, even if the product does not change. As a recent example, you likely had to update your threat models after the release of <a href="https://en.wikipedia.org/wiki/EternalBlue">EternalBlue</a> — but it was still privately operational well before disclosure.</p>
<p>In the realm of climate change, moving members of a species that are used to warm areas to intermingle with its kind who live in colder locations can help the cold-adapted population actually survive long-term.[20] Applications built using legacy systems and libraries which have never been exposed to the outside world, which suddenly need exposure to external APIs, tend to fare extremely poorly in security terms.</p>
<p>As mentioned in the example of unprotected coral, the lack of the system’s exposure to the threat over their lifespan has led them to exist in a weakened, unpatched state. Security-wise, you should intermingle your internally-facing systems with your externally-facing systems to ensure they meet the standards of the evolving “global” threat model.</p>
<p>The goal for cities in the face of natural disasters is to maintain a flexible approach in order to properly adapt their response to the changing nature of their risks. If cities do not cultivate a process which assumes uncertainty and surprise in their model, then it’s safe to say they are being wholly unrealistic about the ways of the world.</p>
<p>As defenders, you should test attacker playbooks against yourself to determine how quickly you can adapt to attacker methods. I’m sure many of you wish you could have in-house red teams. For those who do have them, use them to your advantage in this way. I mentioned decision trees earlier as a way to determine which diverse set of controls to use — have your red teams map out the decision trees they created during their course of action to add realistic data into your own trees.</p>
<p>You also must test your ability to absorb the impact of an attack, and minimize the damage. One such test is through failure injection. <a href="https://github.com/Netflix/SimianArmy/wiki/Chaos-Monkey">Chaos Monkey</a>, part of Netflix’s suite of tools called the “Simian Army,” is a service which randomly kills instances in order to test their ability to withstand failure. In fact, Chaos Monkey is described as a resiliency tool.</p>
<p>While it was designed with a performance use case in mind, it can be repurposed for security. If your infrastructure is continually fluctuating, with instances killed at random, it makes it exceptionally difficult for attackers to persist. Attackers would have to conduct whatever they needed within an uncertain time frame. This is, of course, not impossible, but it absolutely raises the attacker’s cost and level of skill required.</p>
<p>Netflix’s goal with Chaos Monkey is to “design a cloud architecture where individual components can fail without affecting the availability of the entire system.”<a name="back-22"></a><a href="#cite-22">[22]</a> Defenders should make it their goal to design a security architecture where individual controls can fail without affecting the security of the entire system. As I mentioned earlier, if your system becomes completely compromised because a user clicks on a malicious link, you must rethink your security architecture.</p>
<p>Rethinking security architecture is no easy feat. Defenders are considerably hindered in their ability to be adaptive and flexible. Most commonly, people think of organizational pressure as the key deterrent, but I would argue the infosec industry itself is the primary limiter. Defenders face an overwhelming level of complexity and uncertainty due to the sheer number of security vendors and the fragmentation of the solution space.</p>
<p>I believe some of the challenges can be solved by changing the types of infrastructure that are used to promote adaptability and support transformability. Deploying Chaos Monkey is one such example centered on adaptability, but a grander example that blends into transformability is using a container-based ecosystem.</p>
<p>Many of you have likely heard of the container revolution, though may not have used them yourselves. While I’m not a container expert, I’ll explain why containers are a natural fit for evolutionary resilience. Jess Frazelle — “the Keyser Söze of containers”— highlighted in her DevOpsDays talk that containers represent potential salvation from the tradeoff between usability and security.<a name="back-23"></a><a href="#cite-23">[23]</a> I believe she’s absolutely correct.</p>
<p>As per Microsoft, containers are “a way to wrap up an application in its own isolated box” and are “an isolated, resource-controlled, and portable runtime environment.”<a name="back-24"></a><a href="#cite-24">[24]</a> A container serves as a layer of abstraction between an application and the host server — which can be of any kind, whether virtualized or bare metal. Because of this, it allows for easier migration to and from underlying infrastructure without having to rebuild applications.</p>
<p>The most common buzzwords I hear for containers are flexibility, portability, and scalability, making them a natural fit for both the adaptability and transformability characteristics. Just as attackers need repeatability and scalability, so do defenders — as well as something that can adapt over time to changes in attacker methods. It cannot be overstated how much a container environment bolsters flexibility and flattens complexity.</p>
<p>When something goes wrong — whether security related or not — the legacy approach makes determining the root cause an effort in untangling and dependency management. With containers, verifiably working systems are available in one neat package, facilitating far less messy remediation. Even implementing them into existing legacy systems can help more easily manage dependencies and licenses.</p>
<p>In the vein of Chaos Monkey, if applications are attacked while running inside a container, all that must be done is kill the container and restart it. There is no need for vulnerability scanning, firewalls, anti-virus, and all the other fragments of the security solution space. You can instead isolate and shut down infected containers as it happens.</p>
<figure style="float:right; max-width:40%; padding-left: 10px">
	<img src="/blog/img/resilience-11.jpg" alt="Picture of trash on a beach">
	<figcaption>Picture by <a href="https://unsplash.com/@dwoodhouse">Dustan Woodhouse</a>.<figcaption>
</figure>
You have to ensure adaptability to manage resilience erosion as well. In the case of coral, there are “pulse-type stressors,” or acute stressors, which include tropical cyclones, coral bleaching events, and destructive fishing.[21] But there are also “press-type stressors,” which are stressors occurring over longer periods of time, such as pollution, sedimentation, overfishing, ocean warming, and acidification. With enough of the press-type stressors wearing it down, coral reef resilience is overwhelmed when a pulse-type stressor occurs.
<p>Pulse-type stressors in information security can be thought of as new vulnerabilities or a new data breach. Press-type stressors can include large turnover of employees — particularly ones working on large projects — but I would say the most prevalent is complexity. As you add complexity to your applications and systems, it becomes more difficult to test every possible path to compromise, because the paths begin trending towards infinity. If you can no longer test every path because your system is too complex, you have eroded your resilience, a key part of which is flexibility — and will have neither adaptability or transformability.</p>
<hr>
<h2 id="transformability">Transformability</h2>
<p><img src="/blog/img/resilience-10.jpg" alt="Image of a butterfly"><em>Image by <a href="https://unsplash.com/@erinw">Erin Wilson</a></em></p>
<p>Transformability can be thought of challenging your existing assumptions and reorganizing your system.</p>
<p>Returning to our previous example of an organization removing inline PHP database queries in favor of a single class, the latter approach also bolsters transformability. Because it is just one library, it allows for easier migration as-needed depending on how the company’s environment, or the threat environment, changes. You are not leaving your options open when your web app is riddled with inline code. You must be able to review and revise your previous choices — for example by moving to new tools or libraries.</p>
<p>Research from other domains has explored the policy implications of transformability, and how to implement the concept on a practical level. Disaster recovery in urban areas is one of the most well-researched domains in this regard. Given urban areas are dynamic systems, evolutionary resilience suggests that policy should encourage recovery efforts that prioritize re-building the urban area into an improved — or even better, optimized — system.[8] For example, in flood-prone areas, the policy should be to change the location and not build in those areas, while also implementing flood-proof construction for periphery areas.</p>
<figure style="float:right; max-width:40%; padding-left: 10px">
	<img src="/blog/img/resilience-12.jpg" alt="Picture of Christchurch Cathedral">
	<figcaption>NZ Defence Force. (February 23, 2011). Christchurch Cathedral.<figcaption>
</figure>
As a tangible example of transformability, let’s explore Christchurch. In 2011, a devastating magnitude 6.3 earthquake hit Christchurch, the second most populous city in New Zealand at the time. It killed 185 people and damaged over 100,000 houses, with a financial cost to rebuild estimated at over $40 billion.
<p>After the quake, the Canterbury Earthquake Recovery Authority (CERA) designated a new “red zone” throughout the area. This red zone includes damaged or vulnerable land where they believe rebuilding would be “prolonged and uneconomic.”<a name="back-25"></a><a href="#cite-25">[25]</a> The assessment embraces transformability, rejecting the need to return to the status quo, and instead challenging the assumption that there should be buildings on the land at all.</p>
<p>As security professionals, you should work to identify what the red zones are within your IT systems. Organizations should identify which infrastructure or technologies present the most security challenges — whether through vulnerabilities or ongoing maintenance costs — and put them in the red zone for being phased out.</p>
<p>Defining the components of your own red zone calculation will be subjective, but I submit the following as potential criteria — systems that are directly exposed to external attacks, or entirely public facing, in particular:</p>
<ul>
<li>Those which expose complex or critical functionality and are accessible publicly</li>
<li>Newly deployed systems or architectures, particularly those developed by inexperienced professionals</li>
<li>Legacy systems using outdated libraries, software, or languages</li>
<li>Systems with no backups, or which can’t easily be restored</li>
<li>Any system with critical personally identifiable information (PII) or immutable data — such as in Equifax’s case</li>
<li>Systems with privileged access to other systems or accounts</li>
<li>Any system that has known or “accepted” risk associated with it</li>
<li>Easily fingerprintable or overly verbose systems</li>
<li>Anything that could be deemed a single point of failure for your organization</li>
<li>Systems that are prohibitive to patch or update</li>
</ul>
<p>Defining your security red zones isn’t about examining potential vulnerabilities or path to compromise in each of your systems. Instead, you want to identify any assets that fall under the red zone criteria, and attempt to move them out of the zone, into healthier systems.</p>
<p>For example, an organization might have an existing asset built using legacy technology, which now has to be exposed to public APIs. Furthermore, this asset consumes critical data and also has privileged access to backend APIs. This asset should likely be classified as being in the “red zone,” without actually assessing whether or not there are vulnerabilities. The goal is to move or rebuild the asset outside of the red zone and make it a safer system.</p>
<p>In this case, such measures could include:</p>
<ul>
<li>Locking down public exposure so that it’s only accessible via VPN</li>
<li>Rebuilding the asset using newer, non-legacy technologies (such as containers)</li>
<li>Avoiding storing critical data on this asset and proxy encrypted data further into the architecture’s core</li>
<li>Introducing security logging and monitoring</li>
<li>Locking down privileged access and enforcing the principle of least privilege</li>
</ul>
<p>By implementing all, or at least some, of these, the system would no longer be in the red zone. This would be similar to moving a power plant out of a flood plain, and instead building it in an elevated area with fortified materials and an early warning system.</p>
<p>Using the example of levees, researchers have proposed having planned decommission of levees ahead of known maintenance hurdles. This way, levees can be used as a stop-gap as communities embrace transformability and relocate. It’s unrealistic to assume that a community could uproot overnight, but it’s important that it isn’t treated as a permanent Band-Aid.</p>
<p>In security, it’s similarly unrealistic to assume you can transform overnight — and your organization would probably not be pleased with you. But, you need to be able to migrate. Like levees, you could have planned decommission of retroactive hardening and patching before moving off of legacy systems. This ensures you don’t renew on software or hardware before it becomes too embedded in your organization or costly to maintain.</p>
<p>In general, you should have plans in place to decommission technologies that will eventually be obsolete or replaced, even down to libraries, hashes, and software versions. Continually consider how you can prepare in advance for migration.</p>
<p>Evolutionary resilience research has highlighted the need for more collaborative planning across stakeholders in a complex system. Rather than relying on inferred knowledge towards a pre-defined goal, local groups should work together and compile their own information towards optimizing relevant processes in their system.</p>
<p>Drawing from flood risk management, those in charge of risk management should be the ones to communicate what realistic level of protection each sort of approach provides.[9] Otherwise, it’s difficult for communities to cultivate knowledge on their own of what protection is in place and what limitations remain for risk reduction.</p>
<p>The security function within an organization is also not an isolated unit. Security should foster collaboration across the business towards optimizing security processes. You all should also be open in sharing knowledge of what protections are in place, what risks the protection realistically reduces, what risk remains, and any uncertainties around the approach.</p>
<p>The most obvious group with whom security should partner is engineering, which I discuss further in another keynote, <a href="/blog/posts/security-as-a-product">Security as Product</a>. As is in the aforementioned case of containers, it’s possible that there are improvements engineering desires that might facilitate more adaptable security as well. The trend towards flexibility is perhaps the strongest in software development and engineering today, and security must embrace this trend as well. I highly recommend reading the recently released O’Reilly book on Agile Application Security for more in this vein.<a name="back-26"></a><a href="#cite-26">[26]</a></p>
<p>In this collaborative setting, the role of planners should be to manage transitions between states rather than create or mediate.<a name="back-27"></a><a href="#cite-27">[27]</a> I don’t think security professionals can fully remove the need to create or implement solutions to some extent. Focusing on managing the transition from the current state to a more secure state can potentially reduce some labor burden, however.</p>
<p>For example, drawing again on the transition to containers, the engineering group will conduct the majority of the labor towards this endeavor. Security should manage the project to ensure necessary controls are in place, such as detection of container compromise.</p>
<figure style="float:right; max-width:40%; padding-left: 10px">
	<img src="/blog/img/resilience-13.jpg" alt="Picture of people talking about tech">
	<figcaption>Image by <a href="https://unsplash.com/@nesabymakers">NESA by Makers</a><figcaption>
</figure>
As another example, security ideally should work with engineering to implement solutions like two-factor authentication. John “Four” Flynn at Facebook gave a great talk a few years ago about implementing 2FA at Facebook. Their goal was to put 2FA on SSH to make it hard for attackers to pivot into Facebook’s production environment.<a name="back-28"></a>[[28]](#cite-28) During the process, they thought very carefully about the user experience, realizing they needed to support frequent use, allow for a flexible range of factors, and minimize help desk requests.
<p>They decided to use DuoSecurity and YubiKey Nano — with the YubiKey, the developers only needed to touch the side of their laptop to SSH, and DuoSec’s cloud-based tokens ensured they’d still have access even if they lost the YubiKey. One of their key discoveries during this project was that:</p>
<blockquote>
<p>“You can actually implement security controls that affect every single thing people are doing and still make them love it in the process.”</p>
</blockquote>
<p>I recognize that while “software is eating the world,” not every company is yet a technology company. Potentially, you will have a limited IT group with whom to collaborate on technical efforts. This doesn’t mean you can’t collaborate, however. It’s well recognized that there is division between even security and risk or fraud groups, let alone general counsel and financial functions. There is someone at your organization who wants their job to be easier. Your job then needs to be how security can make that happen, or at least fit into their existing workflows.</p>
<p>For this sort of transformability to happen, responsive governance systems are needed. Defenders must implement decision-making processes that are quick to identify and respond to emerging threats. Part of this in ensuring that your organization is learning from prior experiences — such as through the decision tree process I mentioned before, in which you can update your models after a breach.</p>
<p>However, your organization’s entire community must be involved in this learning process and be prepared to continually evaluate strategy. Implementing a security culture in your organization is perhaps the best chance of doing so.</p>
<hr>
<h2 id="conclusion">Conclusion</h2>
<p>This is my humble attempt at a definition of resilience in information security:</p>
<blockquote>
<p><strong>Resilience in security means a flexible system that can absorb an attack and reorganize around the threat.</strong></p>
</blockquote>
<p>The system, in this case, likely is your organization, although this can apply to its underlying systems as well. Crucially, resilience in security is not the ability to withstand or prevent an attack. That’s the blue pill.</p>
<p>The red pill is that the reality is that attacks will happen to you, and you must architect your security around this fact. I showed you how deep the rabbit hole goes on what security strategy fits this reality. Robustness, adaptability, and transformability are the keys to survival in Wonderland.</p>
<p><strong>Robustness</strong>, while not the silver bullet, should be optimized through diversity of controls. <strong>Adaptability</strong> seeks to minimize the impact of an attack and keep your options open, and new types of infrastructure, such as containers, can enable it. <strong>Transformability</strong> demands you challenge your assumptions and reorganize your system around the reality — a reality that affects communities, which requires a collaborative effort.</p>
<p>My favorite fictional character growing up was Ian Malcolm, from Michael Crichton’s “Jurassic Park” novels. I believe the full quote of one of his most notable lines summarizes how you, as defenders, should think of your strategy <a name="back-29"></a><a href="#cite-29">[29]</a>:</p>
<blockquote>
<p>“Because the history of evolution is that life escapes all barriers. Life breaks free. Life expands to new territories. Painfully, perhaps even dangerously. But life finds a way.”</p>
</blockquote>
<p>Consider how you can escape barriers, consider how you can expand to new territories, consider how you can find a way to evolve — because attackers are doing all of these things. Doing so will likely be painful at first for your organization. Your job, as part of implementing transformability, is to manage these transitions and minimize the pain and danger. Much like with life, as per Malcolm’s quote, you can think of it as the survival of your organization’s data being at stake.</p>
<figure style="float:right; max-width:40%; padding-left: 10px">
	<img src="/blog/img/resilience-14.jpg" alt="Picture of a cat wearing a firefighter hat">
</figure>
Attacks will happen. Attackers will continue to evolve their methods. We can evolve our methods, too. We face a choice, as an industry: we can either continue to indulge ourselves in anger, bargaining, and depression, or strive towards acceptance.
<p>If we take this red pill of resilience, we can defend ourselves effectively and realistically. If we take the blue pill, we will keep attempting to rebound to an artificial equilibrium — relegating us to the role of a firefighting cat who is drunk on snake oil.</p>
<p>I am certain most of you are fed up with these dynamics. Instead of accepting snake oil, I encourage you to take the red pill of resilience instead.</p>
<hr>
<h2 id="references">References</h2>
<p><a name="cite-1"></a><a href="#back-1">[1]</a> Alexander, D. E. (2013). Resilience and disaster risk reduction: an etymological journey. Natural hazards and earth system sciences, 13(11), 2707–2716.</p>
<p><a name="cite-2"></a><a href="#back-2">[2]</a> Holling, C. S. (1996). Engineering resilience versus ecological resilience. Engineering within ecological constraints, 31(1996), 32.</p>
<p><a name="cite-3"></a><a href="#back-3">[3]</a> The American Chestnut Foundation. How Chestnut Blight Devastated the American Chestnut. Retrieved from <a href="https://www.acf.org/the-american-chestnut/">https://www.acf.org/the-american-chestnut/</a> (accessed September 2017).</p>
<p><a name="cite-4"></a><a href="#back-4">[4]</a> Restemeyer, B., Woltjer, J., &amp; van den Brink, M. (2015). A strategy-based framework for assessing the flood resilience of cities–A Hamburg case study. Planning Theory &amp; Practice, 16(1), 45–62.</p>
<p><a name="cite-5"></a><a href="#back-5">[5]</a> Blake, E.S. &amp; Zelinsky, D.A. (2018). National Hurricane Center Tropical Cyclone Report: Hurricane Harvey. National Oceanic and Atmospheric Administration.</p>
<p><a name="cite-6"></a><a href="#back-6">[6]</a> Timmermann, P. (1981). Vulnerability, resilience and the collapse of society. Environmental Monograph, 1, 1–42.</p>
<p><a name="cite-7"></a><a href="#back-7">[7]</a> Hough, S. E. (2016). Predicting the unpredictable: the tumultuous science of earthquake prediction. Princeton University Press.</p>
<p><a name="cite-8"></a><a href="#back-8">[8]</a> Sanchez, A. X., Osmond, P., &amp; van der Heijden, J. (2017). Are some forms of resilience more sustainable than others?. Procedia engineering, 180, 881–889.</p>
<p><a name="cite-9"></a><a href="#back-9">[9]</a> Tempels, B. (2016). Flood resilience: a co-evolutionary approach. Residents, spatial developments and flood risk management in the Dender basin.</p>
<p><a name="cite-10"></a><a href="#back-10">[10]</a> Burby, R. J. (2006). Hurricane Katrina and the paradoxes of government disaster policy: bringing about wise governmental decisions for hazardous areas. The Annals of the American Academy of Political and Social Science, 604(1), 171–191.</p>
<p><a name="cite-11"></a><a href="#back-11">[11]</a> Wenger, C. (2017). The oak or the reed: how resilience theories are translated into disaster management policies. Ecology and Society 22(3):18.</p>
<p><a name="cite-12"></a><a href="#back-12">[12]</a> Gunderson, L. (2010). Ecological and Human Community Resilience in Response to Natural Disasters. Ecology and Society 15(2): 18.</p>
<p><a name="cite-13"></a><a href="#back-13">[13]</a> Martindale, B., &amp; Osman P. (2007) Why the concerns with levees? They’re safe, right?. IASFM Fall 2007 Newsletter.</p>
<p><a name="cite-14"></a><a href="#back-14">[14]</a> Liao, K. H. (2012). A theory on urban resilience to floods — a basis for alternative planning practices. Ecology and Society 17(4): 48.</p>
<p><a name="cite-15"></a><a href="#back-15">[15]</a> Côté, I. M., &amp; Darling, E. S. (2010). Rethinking ecosystem resilience in the face of climate change. PLoS biology, 8(7), e1000438.</p>
<p><a name="cite-16"></a><a href="#back-16">[16]</a> NYC Mayor’s Office of Recovery and Resiliency. (2018). Climate Resiliency Design Guidelines.</p>
<p><a name="cite-17"></a><a href="#back-17">[17]</a> Verton, D. (October 1, 2003). Former @stake CTO Dan Geer on Microsoft report, firing. Retrieved from <a href="https://www.computerworld.com/article/2572315/security0/former--stake-cto-dan-geer-on-microsoft-report--firing.html">https://www.computerworld.com/article/2572315/security0/former--stake-cto-dan-geer-on-microsoft-report--firing.html</a></p>
<p><a name="cite-18"></a><a href="#back-18">[18]</a> Dai Zovi, D. Attacker “Math” 101.</p>
<p><a name="cite-19"></a><a href="#back-19">[19]</a> Intergovernmental Panel on Climate Change. (2014). Climate Change 2014 Synthesis Report Summary for Policymakers.</p>
<p><a name="cite-20"></a><a href="#back-20">[20]</a> Sgro, C. M., Lowe, A. J., &amp; Hoffmann, A. A. (2011). Building evolutionary resilience for conserving biodiversity under climate change. Evolutionary Applications, 4(2), 326–337.</p>
<p><a name="cite-21"></a><a href="#back-21">[21]</a> Anthony, K. R., Marshall, P. A., Abdulla, A., Beeden, R., Bergh, C., Black, R., … &amp; Green, A. (2015). Operationalizing resilience for adaptive coral reef management under global environmental change. Global change biology, 21(1), 48–61.</p>
<p><a name="cite-22"></a><a href="#back-22">[22]</a> Izrailevsky, Y., &amp; Tseitlin A. (July 18, 2011). The Netflix Simian Army. Retrieved from <a href="https://medium.com/netflix-techblog/the-netflix-simian-army-16e57fbab116">https://medium.com/netflix-techblog/the-netflix-simian-army-16e57fbab116</a>.</p>
<p><a name="cite-23"></a><a href="#back-23">[23]</a> Frazelle, J. (July 27, 2017). A Rant on Usable Security. Retrieved from <a href="https://blog.jessfraz.com/post/a-rant-on-usable-security/">https://blog.jessfraz.com/post/a-rant-on-usable-security/</a></p>
<p><a name="cite-24"></a><a href="#back-24">[24]</a> Brown, T., et al. Windows Containers. Retrieved from <a href="https://docs.microsoft.com/en-us/virtualization/windowscontainers/about/">https://docs.microsoft.com/en-us/virtualization/windowscontainers/about/</a> (accessed October 2017).</p>
<p><a name="cite-25"></a><a href="#back-25">[25]</a> Blundell, S. (April 19, 2016). Christchurch’s Game of Zones. Retrieved from <a href="https://www.noted.co.nz/currently/social-issues/christchurchs-game-of-zones/">https://www.noted.co.nz/currently/social-issues/christchurchs-game-of-zones/</a></p>
<p><a name="cite-26"></a><a href="#back-26">[26]</a> Bell, L., Bird, J., Brunton-Spall, M., Smith, R. (2017). Agile Application Security. O’Reilly Media.</p>
<p><a name="cite-27"></a><a href="#back-27">[27]</a> Batty, M. (2013). Complexity and Planning: Systems, Assemblages and Simulations, edited by Gert de Roo, Jean Hillier, and Joris van Wezemael. 2012. Farnham, UK and Burlington, Vermont: Ashgate Publishing. 443+ xviii. Journal of Regional Science, 53(4), 724–727.</p>
<p><a name="cite-28"></a><a href="#back-28">[28]</a> Flynn, J. (February 6, 2014). 2FAC: Facebook’s Internal Multi-factor Auth Platform — Security @ Scale 2014. Retrieved from <a href="https://www.youtube.com/watch?v=pY4FBGI7bHM">https://www.youtube.com/watch?v=pY4FBGI7bHM</a></p>
<p><a name="cite-29"></a><a href="#back-29">[29]</a> Crichton, M. (1990). Jurassic Park. Random House.</p>
]]></content>
        </item>
        
        <item>
            <title>Security as a Product</title>
            <link>https://swagitda.com/blog/posts/security-as-a-product/</link>
            <pubDate>Fri, 18 May 2018 17:15:09 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/security-as-a-product/</guid>
            <description>Originally given as the keynote at BSides Knoxville.
Security is a product, but we treat it like a sacred, immutable grail to preserve, unblemished by the sublunary needs of users. And yet, we wonder why defense remains stagnant, why we fail so consistently in progressing towards the glorious ideal of a “secure organization.” We will continue to fail — unless we treat security as a product. Are we trying to respect the phantasmal Elder Deities of Infosec and their stringent doctrine, or are we trying to ensure our organization can still thrive while operating in a perilous digital world?</description>
            <content type="html"><![CDATA[<p><em>Originally given as <a href="https://www.youtube.com/watch?v=Ia80fg7ivN4">the keynote</a> at BSides Knoxville.</em></p>
<p><img src="/blog/img/ball-of-lights.jpeg" alt="person clutching a ball of lights"></p>
<p>Security is a product, but we treat it like a sacred, immutable grail to preserve, unblemished by the sublunary needs of users. And yet, we wonder why defense remains stagnant, why we fail so consistently in progressing towards the glorious ideal of a “secure organization.” We will continue to fail — unless we treat security as a product. Are we trying to respect the phantasmal Elder Deities of Infosec and their stringent doctrine, or are we trying to ensure our organization can still thrive while operating in a perilous digital world?</p>
<p>One definition of a product I prefer is “something created through a process that provides benefits to a market.” Security as product, therefore, is created through a process that provides benefits to a market — in this case, the organization in which it operates. The somewhat religious belief I hear espoused is that designing security to benefit your organization will result in a blasphemous mimicry of true security. That couldn’t be further from the truth. It’s a mimicry of your duty as a security professional to follow your personal beliefs rather than pursue strategies that benefit your organization.</p>
<p>But perhaps you don’t believe me. You think there’s some level of objective “truth” that is foolish to discard in the name of benefitting your organization. Whatever that truth is, that’s now your product, and if it doesn’t benefit your organization, you’re attempting to sell it into a market that doesn’t want it.</p>
<p>I’m often left perplexed at how some security professionals can see victory in forcing through a change that users viscerally dislike, as if their dissatisfaction represents a blood sacrifice. How is that possibly success? Success is solving a real problem in a way that delivers consistent value. Success is fostering consensus so that you are supported by the organization in effecting meaningful change — even if you implement something adding to your customer’s burden.</p>
<p>For example, when requiring multi-round hashing rather than storing credentials in plaintext, relevant stakeholders in your organization must be included and understand the need for a noble sacrifice. You will fail if the security of your organization rests on users adopting a strategy that neither provides them value, nor is one they support.</p>
<p>As Sarah Jamie Lewis insightfully tweeted:</p>
<div class="center">
	<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">&quot;our software is secure if you use it correctly&quot; means &quot;our software is not secure&quot;</p>&mdash; Sarah Jamie Lewis (@SarahJamieLewis) <a href="https://twitter.com/SarahJamieLewis/status/996033014269296640?ref_src=twsrc%5Etfw">May 14, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
<p>Similarly, <em>if</em> your organization is secure if users follow your security policies correctly, your organization is not secure. Maintaining the dogmatic view that it’s “the users that must be wrong,” rather than accepting the situation for what it is — the failure of your security program — is why we continue to fail. How many more years are we going to lament that our users are poor at security before we actually start working on pragmatic solutions?</p>
<p>Pragmatism doesn’t require security sacrilege. All products, including security, are shared problems within an organization. Each stakeholder must feel they have a personal stake in whatever course of action is taken — a process called building consensus.</p>
<p>As a product manager, there are times when we will release changes or new features that may be contentious. If I pursue a strategy without regard for how my colleagues who interact with customers or potential customers every day feel, the product won’t succeed in the market, because my colleagues won’t have the confidence to sell it. If I come to my colleagues with evidence for why it is necessary, describe how it works towards the broader product vision, and actively listen to their concerns, we can design a strategy collectively in which all parties are confident — even in the face of uncomfortable change.</p>
<p>Security as a product doesn’t require the wearing down of strategies through compromise until they are rendered ineffective. It requires a purposeful strategy through an overarching vision of how security can support the organization’s survival in light of the fact that computers are somewhat terrible, but necessary for success.</p>
<p>At this point, I’ve mastered a stolid expression for when security professionals nonchalantly explain the improvisational nature of their strategy-making. Most assume I’m asking whether they have a strategy for a specific project and seem surprised when I ask if they’ve defined their long-term vision for their overall security program. In the same conversation, the CISO or security engineer with whom I’m speaking will unleash a passionate rant — perhaps you have heard some of these grievances, or uttered them yourself:</p>
<ul>
<li>“Things do sometimes sort of get accomplished… but slowly.”</li>
<li>“We don’t ever actually make progress, we’re just running around.”</li>
<li>“We keep making the same mistakes over and over — it doesn’t get better.”</li>
<li>“I don’t have any time to do research, I’m constantly in meetings where we don’t actually get anything done.”</li>
<li>“I just don’t even give a shit anymore, nothing changes.”</li>
</ul>
<p>I really do feel for your plight, but y’all can be tedious. There is clearly something amiss here that better or more tech nor people can fix — they will simply be likewise wasted. I hear these remonstrances nearly everywhere in infosec — from the smallest of teams to teams sprawling over multiple functional areas at Fortune 500 companies. There are countless passionate people working tirelessly, whom consistently feel like they aren’t accomplishing anything that is meaningfully improving security.</p>
<p>What is perhaps even worse is hearing that security teams have adopted “agile” methodology, then discovering that their tasks are based on the whims of the individual, the epics are ill-defined and focused on functional areas, and no one is looking at a higher level to see how many resources are being dedicated towards each effort.</p>
<p>What’s even more jarring is every time I play surrogate therapist — asking probing questions to discern why their teams are so inefficient at a macro level — they unabashedly disclose that their teams don’t have any overarching goals defined, let alone metrics to track progress.</p>
<p>And we remain shocked that we aren’t progressing?</p>
<hr>
<p>Of the “three pillars” of infosec — people, processes, and technology — I believe processes are most ignored and undervalued. I’ve grown exhausted by the number of articles about the “cyber skills shortage” as well as listening to — and speaking about — the pernicious complexity and misguidedness of the security technology space. Yet I don’t see nearly the same volume of fiery headlines and hot takes on Twitter about how our processes are failing us, despite the fact that processes are the underpinnings of how people work together and with technology.</p>
<p>As an example, I’ve been amazed at what our customers accomplished with Excel and two people prior to adopting our solution — managing vendor risk programs covering thousands of vendors across many lines of business. A trait in common with each of those customers succeeding despite their people and technology constraints is how easily they can articulate their process — and it’s because they’ve comprehensively defined it.</p>
<p>A process is “a series of actions or steps taken in order to achieve a particular end.” You can have the best people and the best technology, but if you cannot define to what end they can be used, and how they can be used, success is unlikely to manifest. You also must determine the “what” before the “how” — it’s prohibitive to determine the steps necessary until you define what the particular end should be. I believe there is insufficient attention paid in security programs to what particular ends should be. Is “making Organization, Inc. secure” really the pinnacle of defining goals for our security programs?</p>
<p>The foundation for any product is understand your goal for the product. Fundamentally, what is the product’s purpose? What are you trying to help users accomplish? Viewing security as a product forces you to define your goals and come to terms with your team’s purpose. It also ensures you’re prioritizing actions appropriately — honing in on what will actually improve the product and your customer’s experience.</p>
<p>If your company is publicly traded, have you read their annual report? Can you summarize the Risk Factors they outline in their <a href="https://en.wikipedia.org/wiki/Form_10-K">10-K</a>? The <a href="https://www.sec.gov/fast-answers/answersreada10khtm.html">Risk Factors section</a> is quite literally a cheat sheet, a ranking of your organization’s risks in order of their priority. If you do not understand the risks to the business’ ongoing operations from the organization’s perspective of priority, how could you possibly understand what is most essential to protect?</p>
<p>I assure you that you do not have to dive deeply into the mysterious waters of product management to improve your security program. The aforementioned rants by my blue team friends are painful primarily because they include examples of what you definitely <em>shouldn’t</em> do in product management if you want to create continuously successful products. Even <em>not</em> doing those things will help significantly — and doing the <em>right</em> things will empower you even more.</p>
<p>Because what lurks beneath the frustration expressed by so many in our industry is a sense of helplessness. We don’t feel empowered, we feel stifled and downtrodden. I would argue any profession in which you expend a lot of intellectual effort and time-capital into improving a problem, only to feel like you are running in place, will rapidly burn people out.</p>
<p>In infosec, despite a common understanding that reactive approaches to defense are misguided, we maintain reactive processes. Security teams are accustomed to receiving direction externally, feeling burdened with priorities that defy their beliefs of what is important — as if a secular organization should dictate the priorities of such a sacred order.</p>
<p>Once you adopt the mindset of security as a product, you can begin to take control. One of the “basics” of product management is that solely delivering exactly what customers demand, without understanding the motivation for their demands, will lead to poor outcomes and potentially monstrously disjointed user experiences. You have to proactively understand your customer’s perspective and look beneath the surface of what they are requesting to discern the underlying challenge or desire.</p>
<p>How many of you have worked in retail or other customer-facing service jobs? I have as well, at a department store and later at a frozen yogurt shop, and if security professionals believe they are treated poorly, I promise that you cannot fathom the depths of brutality customers can reach. I ask, because a cornerstone of many customer-facing service jobs is the notion of anticipating needs.</p>
<p>Anticipating needs means understanding your customer’s challenges, desires, and beliefs. For example, one method by which I sold higher-SKU merchandise in the department store was by efficiently learning about my individual customer. I asked questions about why they were shopping and what frustrates them sartorially.</p>
<p>Since I was in the contemporary dresses department, usually the woman was shopping in anticipation of an event, whether a date or party. I listened carefully to pick up on any clues indicating her challenges — for example, one with which I deeply relate is “I hate wearing dresses,” or “I’m going to be on my feet all night.”</p>
<p>Even a morsel of such data was sufficient for me to find additional options for her beyond the items she had chosen. Perhaps a dress with pockets and an elastic waist, that still looks chic while maximizing comfort. Many of the dress-wearing people reading can likely relate to the ecstasy of wearing a dress with pockets, which can both cache snacks or conceal fidgeting hands due to social anxiety. Or, I might offer a maxi dress, which conveniently veils one’s shoes, allowing the option of feet-sparing flats rather than heels.</p>
<p>I’m cognizant that I’m essentially describing a robust recommendation engine (more Netflix than Amazon) — but as it happens, humans can excel in this effort, too. I would imagine most would appreciate a professional faerie godparent constantly anticipating your needs and making your life easier, all without you having to request or nag.</p>
<p>Afforded the cover of not being, strictly speaking, a “security professional,” people are quite honest with me in how they perceive the security team. Security teams frequently are considered the opposite of the faerie godparent— more like a sulking demon that seems to relish an arduous professional life and decrees you are forbidden from doing the things you need to, without ever seeming to care about what those things are.</p>
<p>Security teams both rely primarily on direction and yet seem resentful of this dependence — but ironically also begrudge the notion of reaching out proactively to their organization’s stakeholders to discern what needs to be done.</p>
<p>This inconsistency of thinking leads me to somewhat believe that many security people fundamentally want to dictate what’s important to the company from a security perspective, based on their own opinions, so as to serve the Elder Infosec Deities. Frankly, it sometimes takes considerable effort not to adopt my best Regina George face after listening to a security person elaborately envisioning their Blue Team utopia (what I call a “Blutopia”) at great length and ask pointedly, “Have you ever considered that your opinions might be wrong?”</p>
<p>Part of the reason I don’t ask is that I truly don’t require additional help in amplifying social awkwardness. But the larger part is also that I don’t believe they would be deterred if their opinions are deemed “wrong” by someone else. My conclusion is this is because of the Steve Jobs Myth.</p>
<hr>
<p>I don’t like Steve Jobs. My personal opinion is that he was a jerk and is a wretched role model for leadership. However, I recognize that he is idolized by the type of people who are prioritizing their personal opinion over what their organization actually needs, because of this Steve Jobs Myth. The myth is that through the spellbinding magic of Jobs’ gut instinct alone, and defying all evidence and user analysis, Apple forged ahead with the iPhone and consequently revolutionized the cellular device market.</p>
<p>That isn’t actually what happened.</p>
<p>What actually happened is there was an experimental project initiated without Jobs’ knowledge, which received lukewarm reception by Jobs once presented to him because he believed cell phones “sucked.” However, he trusted the team to work through the technical details and even allowed the head of the project to hire Apple engineers from other projects. His insisted in return on seeing <a href="https://www.cnbc.com/2017/06/16/steve-jobs-iphone-creation-story-proves-even-the-smartest-executives-need-help-making-decisions.html">“an interface that might be intuitive and exciting to lay-users”</a> before he’d be convinced.</p>
<p>The Steve Jobs Myth perpetuates the idea that Jobs gave minimal thought to user needs — which generally makes some people feel empowered to not care, either — and that it is the only way to conceive brilliance and truly leave users awestruck. Jobs’ concern was actually that you cannot simply ask people, “What’s the next big thing?” and that <em>market</em> research is insufficient to conceive a product that customers will love.</p>
<p>However, he viewed <em>user</em> research as essential — as seen in his requirement for the continued development of the iPhone. What he understood is that people won’t always say — or even know — what they want, but through user research, you can see which preferences they truly hold based on how they behave.</p>
<p>Within behavioral economics, there’s a clear hierarchy between stated vs. revealed preferences. Humans can be proficient in fooling themselves in what their preferences are, or if they’re being interviewed, in saving face. For example, if someone asked me, “are you more likely to prepare chicken and broccoli for dinner, or a can of tuna?” I am not necessarily inclined to reveal that I’m sometimes indistinguishable from a cat in behavior and will answer the chicken and broccoli with my ideal self in mind. But if you observed the dinners I made that week, you would see cans of tuna — a vastly firmer source of truth for answering that question.</p>
<p>If you ask your organization, “Do you find SSO easy to use?” you might discover a variety of answers. Maybe they answer “yes” because they don’t want to feel less intelligent by not finding it easy, or they use it so infrequently that they’ve forgotten the frustration of their last use. Maybe they answer “no” because in their customer meeting an hour ago they unsuccessfully accessed a crucial piece of data because of an issue, which made them feel embarrassed in front of the customer. You might even find that people’s answers switch between one week and the next. None of this is particularly helpful.</p>
<p>You can examine revealed preferences instead, looking for the number customer support tickets filed for SSO, the number of multiple push notifications in a row, the number of password reset requests, or how many people re-enter the URL of the service after being directed to SSO. These metrics more accurately tell the “truth” of the user’s experience, and how much it’s aiding or hindering their work.</p>
<p>Another issue arising from the Jobs Myth is that its believers use it to justify proceeding with their projects, generally with the assumption that “users will learn to love it,” because they believe Steve Jobs’ ideas were so provocative and progressive that even if users didn’t know they wanted it, they’d want it in time. That is also thoroughly inaccurate. As Jobs himself <a href="http://www.businessinsider.com/steve-jobs-response-to-an-insult-is-an-example-everyone-should-follow-2017-7">stated</a>:</p>
<blockquote>
<p>“And one of the things I’ve always found is that you’ve got to start with the customer experience and work backwards to the technology. You can’t start with the technology and try to figure out where you’re going to try to sell it.”</p>
</blockquote>
<p>Simply because you personally believe something is valuable or important, does not mean it is. You have to understand the problems that are actually meaningful, and work backwards to how to solve them. This is not just an issue with blue teams, but also with infosec startup founders — the classic blunder of creating a hammer in search of a nail.</p>
<p>Your job is not to determine priorities in your sandboxed mindspace and convince the organization that securing something is of vital importance when it does not present material business risk. Your job is to determine priorities based on what veritably helps the organization and explain why your solution is the right one to help.</p>
<p>An extension of this fallacy is also the reverse — that security people can be presented with a valid solution to the organization’s problem but reject it because they personally don’t believe the problem is important.</p>
<p>As a real-world example, one security professional I know pushed for a specific product to be purchased in their organization. They presented the four-figure cost and offered a variety of use cases where it could be of use — such as simplifying the ability for engineers to implement early detection in the company’s infrastructure. They shopped around the idea to non-security groups on its usefulness and gained their buy-in as well. However, the person in charge of procurement held the personal opinion that this product type isn’t useful, and consequently pushed back on the request.</p>
<p>I see this so regularly I began calling it “Security Morals,” but I now think it should really be “Security Dogma” instead. What I mean by that specifically is that there are somewhat rigid “principles” common among security professionals that are treated as dogma. As aforementioned, there is a seemingly insatiable desire to please the Elder Infosec Deities by strictly adhering to their doctrine, even if it defies the organization’s needs.</p>
<p>In a SaaS product, if an engineer refuses to add a print button because they personally think it’s useless when you can “just” right click and select print, despite all user research indicating that users are at present confused how to print, their personal opinion will be demoted in favor of concrete evidence. If they did this regularly enough, they might be placed on a performance plan.</p>
<p>In security, similar behavior seems rewarded, as if performance is measured by how steadfast your belief is in Security Dogma. Such behavior would not be rewarded if viewing security as a product.</p>
<p>When speaking with defenders, I notice a non-trivial amount bristle at the notion that they have customers — that they aren’t a neutral force above the fray, akin to the Federal Reserve. It was in thinking through why so many defenders hate the concept of having customers that my notion of Security Dogma solidified — that there are principles of security treated as incontrovertibly true and mandatory to implement regardless of the reality of the organization, what determines its fortunes, or what endangers its continuing operation most.</p>
<p>Security professionals may view themselves as a heroic knight, but to others in the organization, they might look like the Knights Templar. As <a href="http://tvtropes.org/pmwiki/pmwiki.php/Main/KnightTemplar">in the trope</a>, even minor security offenses are treated as critical, enforcing “justice” is considered paramount and non-negotiable, and an egotistical complex emerges of interpreting resistance to your “noble” intentions as evidence of principles in need of correction. While you are not, in fact, a knight, you do have the opportunity to be a hero — but not by rescuing someone who is not actually in distress because you believe they need rescuing.</p>
<p><strong>Your customer is your organization.</strong> Imagine if you attempted to order food in an app and it told you “no” because the food was insufficiently healthy, while also never explaining how it defined “healthy” food. Would you enjoy the app? Being realistic, most of us would repeatedly rage at it, even when you begrudgingly conceded that it had a point about your midnight pizza endeavors. This is more than not being likable — which isn’t strictly necessary to be effective. You need to be respected. If you are perceived as dogmatic, I promise you that you will not engender the respect you need to be effective.</p>
<p>I’m usually astonished at how little security teams work on cultivating organizational buy-in, since that’s a core part of my job as a product manager. I personally don’t believe a security program can succeed without it. This doesn’t mean everything becomes watered down, worn meaningless by only acting on things which have perfect agreement.</p>
<p>It instead means ensuring that the organization feels as if it is a stakeholder in security, that it’s along for the journey, and that security is not their adversary, but a fellow team attempting to better the organization. You could actually never implement things that other teams specifically request and still foster a sense of consensus by presenting your point of view with a sense of empathy.</p>
<p>I’ve personally struggled to practice empathy consistently. Particularly for those of us who are on the spectrum, actively seeing the world from someone else’s vantage can feel unnatural. But I assure you it’s not impossible, and your job will become substantially easier when you begin listening to people and ensuring you understand their point of view, rather than trying to dismiss theirs and ram your own point of view down their throat. <a href="https://en.wikipedia.org/wiki/Active_listening">Active listening</a> is one of the most useful life skills you can develop.</p>
<p>Cultivating customer empathy is the first step you should take in your transition to treating security as a product. An example method is through <a href="https://en.wikipedia.org/wiki/5_Whys">the 5 Whys</a>. The goal is to dig deeper into why something is a problem and identify its root causes. For example:</p>
<ul>
<li>“Why do you not want to implement 2FA for Salesforce?”</li>
<li>“Why do you not want to add a step for salespeople to login to Salesforce?”</li>
<li>“Why can’t salespeople afford to take the additional time?”</li>
<li>“Why do salespeople need to log their call notes immediately after a call?”</li>
<li>“Why do salespeople need to transfer notes from Google Docs to Salesforce?”</li>
</ul>
<p>The root cause is arguably that there is friction between the notes salespeople take during a call and where they are meant to log the call. The solution might be to integrate Google Docs into Salesforce, meaning the user has to log into only one service during the course of their work — meaning implementing 2FA will be more palatable. As in this case, you may hear answers that do not seem to be pertinent to the security team, as they are squarely in the business domain — but your role is to connect the dots between business operations and security risks that threaten them.</p>
<p>I strongly believe your highest value as a security professional is, perhaps, in empathizing with the organization’s business risk and identifying where digital risks arise that amplify or solidify business risk. Your customer knows what endangers them — but they do not know how that danger manifests through digital means.</p>
<p>Once you feel you truly understand where customers are struggling, you can begin architecting your vision. Consider your vision for your security program as its story that will unfold over time. Themes serve as the heart of stories, the foundation for the central idea the author is attempting to convey. The plot — or the events that unfold within the story — supports the theme and carries the story towards its goal.</p>
<p>In a security as product model, you will also have themes. Those themes will also have plots — courses of work that drive towards the stated goal and the actions you need to take within those courses of work. Before defining any of the work, however, you have to envision the overarching story. Few people are naturally proficient storytellers, but you can practice by expressing your program’s story through a caricatured, fairy-tale lens.</p>
<hr>
<p>At the dawn of the year, our band of heroes embarked on their quest in Engineersville. They heard the cries from the local farmers of meager yields and slow harvests due to bugs. It would not suffice simply for the heroes to kill all bugs as they appeared — after all, there are many quests elsewhere to complete. They knew their noble purpose was now to help the farmers ensure a bountiful, efficient harvest that they could sustain on their own.</p>
<p>Our heroes’ first goal was to reduce the amount of time it took to squash bugs spotted in the fields, as the bugs could hurt the harvest if they were left alive. Come spring’s first blossom, our heroes transitioned to their second goal — ensuring fewer bugs were being introduced to the crops. They helped the farmers map out how their field architecture would look ahead of planting to determine where bugs could spring up.</p>
<p>As summer began sizzling, they toiled to ensure that their tools could be used by the locals as well, beginning the work on crafting one master tool the locals could use that would automatically determine which specialized tool was best for reducing bugs in the type of fields being sown.</p>
<p>As the first leaves of autumn fell, our heroes tested this magical tool among a small group of farmers, carefully analyzing results and finally releasing it to all locals so that they could begin their next year empowered to have a bug-free harvest. This meant the heroes would have to do even less work of patching and helping locals tend to their fields, allowing them to focus on new quests.</p>
<p>(A wizard hat is optional in crafting stories, but recommended.)</p>
<hr>
<p>Are there any security principles truly sacrificed in this story? The overarching goal is to reduce the number of vulnerabilities in production. As in this story, there may be multiple themes that are part of the same story — reducing the mean time to fix vulnerabilities, adding threat modelling in the design phase to introduce fewer bugs, and creating an automated tool that abstracts multiple security products away from the engineer so they can test their code easily and efficiently during development.</p>
<p>The goal is still fundamentally a security goal, but the themes show customer empathy. The engineers want minimal friction in their workflows. As close as you can provide “push button, get security,” the more productive they will be. Your team, as a stakeholder, is also not ignored. The two initial themes are enablers to the longer-term goal, reducing workload off your team to support progress towards an even more efficient solution that will reduce workloads further.</p>
<p>It is essential to view it as a full story and not be disheartened that your end-goal cannot be accomplished immediately. Setting themes and dreaming up your vision can inspire you so fully that you find yourself with a cornucopia of ideas. Unless you are exceptionally fortunate, the vast majority of teams will not have the resources to pursue every theme and must prioritize them.</p>
<p>Prioritization is one of those tasks that’s very easily said — you “just” rank which themes are most important to you — but is formidable in practice. When I build roadmaps in my work, there is often an excruciating “this or that” decision that requires you to push back work on something which still would absolutely benefit customers… just not as much as the other theme.</p>
<p>My first word of caution to you is avoiding prioritizing themes based on what you <em>feel</em> is most important. Waging a war of opinions is one in which everyone loses — and that’s ultimately what you will be doing, unless you prefer a dictatorship style, if you use your personal views as the basis for your prioritization.</p>
<p>Instead, you must again return to the perspective of your customer. While you personally may believe the theme of “reducing the volume of emails with malicious attachments” is the most important one, your organization may have their deployment frequency and lead time metrics hampered by an arduous appsec process, which more tangibly affects business performance.</p>
<p>How do you differentiate which themes to prioritize? You collect and analyze data — both qualitative and quantitative. A good engineering program will be tracking metrics such as availability, customer tickets, deployment frequency, error rates, lead time, <a href="http://kpilibrary.com/kpis/mean-time-to-detect-mttd-2">mean time to detect (MTTD)</a>, and <a href="http://kpilibrary.com/kpis/mean-time-to-repair-mttr">mean time to repair or recovery (MTTR)</a>. Ask engineering how those metrics are being impacted by security requirements. Ask engineers how they would explain some of the mutual challenges you face — you may be surprised at how aligned DevOps engineering teams are with security (but that is a topic for another time).</p>
<p>If you aren’t tracking metrics on your security program, you should be, as it’s essential for measuring progress in a product. This includes your own MTTD and MTTR — such as how quickly you remediate product security tickets. It should also include measuring the frequency of configuration management changes, such as firewall rule updates, patching, hardening — anything to measure the tempo of your program.</p>
<p>You can also measure how resources — specifically your security team’s time — are being used. Are they spending half of their time extinguishing fires? Is a third of their day dedicated to configuring your SIEM? Do they lose a week each month asking routine questions for threat modelling exercises? These represent opportunities for automation, as there is benefit in reducing the cost of your recurring security tasks and freeing up resources for more impactful streams of work. You should also poll how they want to spend their time, to ensure you retain your talent and avoid needing to worry about the “pipeline problem” in the first place.</p>
<p>Beyond this, you also need to quantitatively measure how your organization perceives the efficacy of your program. For example, conduct the equivalent of <a href="https://en.wikipedia.org/wiki/Net_Promoter">NPS surveys</a> for the security organization, where teams with whom security interacts rate how satisfied they are with the security team. I’d recommend keeping the NPS anonymous with the option of entering a comment to give more detail. After all, security people can sometimes come across as a bit intimidating, and you want to find out the truth.</p>
<p>Quantitative data won’t necessarily tell the entire picture, however. Qualitative data helps fill in detail and may even expose concerns that are difficult to discern from quantitative data. Talk with a selection of individuals across different roles and levels in your organization to hear their feedback on how security can better meet their needs and work with them. You should also ask people on your team, from junior to senior, to give their feedback as well. Again, anonymous surveys can be your friend here in order to promote honesty.</p>
<p>My security fairy tale above could be an example of hitting the nexus of what your data is telling you, thus rising in priority. Your engineers are dissatisfied with having to wrestle with security testing products themselves, and their lead time to deploy is suffering. Half of your product security team’s time is spent on patching and last-minute security testing before GA, because engineering finds it too onerous to currently conduct earlier in the process. If you have three product security people making $100,000 each, you are spending $12,500 per month on something your customer doesn’t like anyway. And perhaps as a last data point, your product security team has expressed the desire to do more research and build custom tools.</p>
<p>A project to build a custom tool that lets engineers self-serve security testing in the development process and to standardize a threat model for the design stage would tangibly improve the data points you have collected. It also happens to be straightforward to measure, which makes likelihood of success even greater, since you can more easily determine what more needs to be done to drive the story.</p>
<p>There are also a few economic angles to consider when prioritizing. First is opportunity cost. By supporting legacy tech with time and money, from what else are you taking away resources? Some of the CISOs I most admire share — coincidentally or not — the trait of thinking in terms of monetary costs of work. This importantly includes pricing in the “total cost” of a security product, which includes the amount of maintenance, tuning, tweaking, and troubleshooting that your team will have to perform on an ongoing basis. Any expenditure of effort by your security team on an action is directly taking away investment into another action.</p>
<p>Second is the sunk cost fallacy. Just because you’ve invested a lot of time and money into something already, doesn’t mean it’s still worth pursuing. Throwing strong resources at weak purposes will deteriorate your product. As in the aforementioned example of opportunity cost, if a legacy security product requires substantial ongoing maintenance to perform as you need, prioritizing a theme of moving to a newer, less burdensome product might be necessary. While this may add a short-term resource sink, it will allow the plot in your story to ultimately move forward.</p>
<hr>
<p>You now feel confident which with themes you prioritized — you know what your story will tell, in what order. However, this story is a shared one, as any security initiatives will inherently be shared due to the nature of affecting the organization. Your customer must be brought along in your journey, and feel like they have a stake in your story.</p>
<p>When you’re soliciting feedback from other people, it’s an opportunity to grow the working relationship — and ultimately engender trust. Rather than nixing their ideas on the spot if you don’t think they’re worthwhile, use language like, “I hadn’t considered that — my team will have to look into it.” You don’t want to promise that all suggestions will be implemented, or you’ll result in a lot of disappointed people, but you do want to make people feel as if they’ve been heard. And, if you do end up implementing something they suggested, or a use case they emphasized, they’ll be delighted.</p>
<p>Be transparent with your story. To start, determine who the right stakeholders are in each organization and ask if you can bring by coffee and treats while you present the story to them. Ask them what they think of it — are there any assumptions with which they disagree? Are there any risks that haven’t been captured? How do they feel it will impact them? Ask open-ended questions so as not to guide them. Before trust is established, phrasing a question as “How will this help you or not?” may compel them to be supportive rather than expressing the full range of their impressions.</p>
<p>As someone working on a product with a third party risk management use case, I can attest that no matter your industry, some of your organization’s prospective customers are asking sales about your security practices. Presenting your vision and progress towards that vision gives them a differentiator to reference, even if far removed from the primary use case of whatever your organization is offering.</p>
<p>Connect with product managers or whomever is designing whatever your organization offers. Not only will it benefit you by receiving feedback, whether to prioritize or to determine the “how,” but it will inspire them to keep you abreast of their own roadmaps. Having security included earlier in the product process will only serve to benefit the entire organization.</p>
<p>As far as how you present your story, some sort of visual aid is generally advisable, rather than purely speaking to it. If you’ve seen <a href="https://swagitda.com/speaking/index.html">my slide presentations before</a>, you can likely guess that I expend substantial effort into how my ideas are visually presented. As a product manager, the slides I create describing my project are not nearly so sparse and beautiful — but I do always consider what I want the listener to take away and leave the rest to voiceover rather than text on the slide.</p>
<p>Bear in mind that while technical meat may sound delicious to you, it can be a repellent to colleagues elsewhere in the business. Your goal is to cultivate consensus around your themes — around the journey of your security program, not the intricate details of the plot. You need to express, in accessible terms, what the theme is, the value it brings to the organization, and any risks or considerations that will be shared challenges across the organization.</p>
<p>Returning to our fairy tale, a slide deck could be presented as follows:</p>
<ul>
<li>Our vision is to reduce the number of vulnerabilities in production</li>
<li>Our goals are to reduce the lead time to deployment, mean time to patch, and security team time spent on application testing</li>
<li>The primary benefit Organization, Inc. is less friction for engineers to test for security vulnerabilities, allowing for our products to be released more quickly</li>
<li>The secondary benefit to Organization, Inc. is reducing the cost of security testing, helping with scalability as well as freeing up resources to accomplish other security goals</li>
<li>We will need to partner with the Engineering team to understand workflows and ensure a security testing orchestrator is deployed appropriately into workflows</li>
<li>We will need to partner with PM to introduce threat modelling during the design phase, which will require a near-term time tradeoff for longer-term cost reduction</li>
</ul>
<p>You begin by inspiring stakeholders, then end with what you need from them to accomplish the vision. This has another benefit of putting those requirements on their radar in advance of when they will need to execute upon them, resulting in quicker turnaround times for you.</p>
<hr>
<p>By the end of the prioritization process, I hope you feel emboldened by the knowledge of which themes are most important to accomplish, and in which order. Now is the time of execution, defining which steps need to be taken towards your goal.</p>
<p>If you have a program manager, this is exactly where to loop them in. If you do not, or cannot loan one from another team for advice, then please do not pretend to be one. That is, you should not assume you understand the abilities and constraints of your team members and assign tasks to them without checking with them first.</p>
<p>While you can lead the charge on the “what,” you must include others in figuring out the “how.” Look to the real Steve Jobs, not the fallacious Steve Jobs Myth, and recall how he trusted the project lead to determine the underlying technical detail so long as his requirements were met. Depending on the size of your team, there will perhaps only be one or two individuals able to take on tasks. Where I see security managers often fail is vacillating between extremes of giving sparse direction and minimal feedback to delving too far in the weeds.</p>
<p>Through the process I outlined, you already defined the requirements of the project through the need to present across the organization — so there isn’t necessarily much more work to be done on your end, save for clarifying requirements on request.</p>
<p>If you want to really make an impact, begin tackling your security debt. You may be familiar with technical debt, which is when quality is sacrificed for speed, typically with the false promise of “we’ll fix it later.” Ironically, by not treating security as a product, you are vastly more likely to accumulate security debt as part of your crusade to integrate your gospel.</p>
<p>Embracing security as a product involves treating it almost as a living thing, one which decays and requires nurturing to stay alive. For each “shortcut” you take, are you considering what challenges will be created later? Did you document why you can’t address it effectively today, for example because there will be a superior way to fix the problem if you wait? How frequently are you returning to those shortcuts and paying down your debt?</p>
<p>There is power in ownership. The <a href="https://en.wikipedia.org/wiki/Endowment_effect">endowment effect</a> is a discovery by behavioral economics that people ascribe more value to things they own, far more than they “rationally” should. Your security program being a product means you own that product — it is <em>your</em> vision and <em>your</em> story. In a fashion, you can consciously nudge yourself into a mindset that will inherently encourage you to take better care of your security program.</p>
<p>I stress this because a lamentable consequence of the nihilism I see in defenders is they cease to care about the security of their organization on a time horizon that surpasses their planned tenure. With the tumultuous turnover of security talent in most organizations, if the strategy is Security Dogma, devotion to it dies when the believer leaves, and a new messenger of the Elder Infosec Deities comes in to spread their own interpretation of the Dogma.</p>
<p>By creating your vision for the security program, you describe a map for the security program’s journey. An incoming hero unburdened by zealotry can see where they are in the journey and the end destination. It’s unlikely that every stop on the journey will be entirely discarded unless there is scant evidence for its value. What is more likely is that the “how” will change most drastically, while the overarching quest — your vision, and to some extent, your legacy — remains intact.</p>
<p>The product process even aids you when switching organizations. What is changing is the end customer — not the process. Even so, just as when I helped women pick out dresses, there will be customers with characteristics in common to each other, rendering your maps meaningful beyond the initial customer.</p>
<p>And if you want to rise the ranks, the practice of articulating a clear vision and fostering consensus will only serve to demonstrate competency. It can demonstrate to your executives or your board of directors that you understand them as a customer and will nourish their trust in your ability to deftly manage risk in a way that supports their success.</p>
<hr>
<p>This is the fairy-tale ending to my own vision I shared with you today — that you can ride into the sunset knowing you were a hero in the way that helped the realm prosper. The fanatics who sought to serve spurious justice will never reach their dream of security nirvana, wailing relentlessly into the wind about their persecution at the hands of locals wanting to prosper.</p>
<p>Inspire your organization with your story of how security can allow it to thrive and make them feel they have a part to play in it. Your band of heroes can and should include colleagues outside of security, who will be far more willing to aid you in your quest — however long or arduous — if you take the time to discuss its purpose to them from a position of empathy.</p>
<p>Security is a product, and reluctance to embrace that is like rejecting scientific evidence in deference to zealotry. There is a way forward that does not rely on worshiping the Elder Infosec Gods through enforcing Security Dogma, which is, in fact, the path of least resistance — despite being less dictatorial.</p>
<p>Quixotism in the name of security purity will crumble as a foundation for a “Blutopia,” but a pragmatic approach, the support of devoted followers within your organization, and a visionary quest just might be the right start to our collective journey.</p>
]]></content>
        </item>
        
        <item>
            <title>2018 Cyber Security Predictions</title>
            <link>https://swagitda.com/blog/posts/2018-cybersecurity-predictions/</link>
            <pubDate>Thu, 21 Dec 2017 16:52:25 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/2018-cybersecurity-predictions/</guid>
            <description>Fed up with ridiculous infosec predictions for the upcoming year, I decided to aggregate them all and use the power of Markov Chains to generate my own list. What follows is the result, lightly edited solely for readability. I hope to be pioneering the next-gen AI-powered thought leadering market segment.
In 2018, security. Cyber security people will die. We’ve long debated where security people will die. We expect this lucrative trend to continue through 2018.</description>
            <content type="html"><![CDATA[<p><em>Fed up with ridiculous infosec predictions for the upcoming year, I decided to aggregate them all and use the power of Markov Chains to generate my own list. What follows is the result, lightly edited solely for readability. I hope to be pioneering the next-gen AI-powered thought leadering market segment.</em></p>
<p><img src="/blog/img/cyber-dynomite.png" alt="cyber dynomite"></p>
<p>In 2018, security. Cyber security people will die. We’ve long debated where security people will die. We expect this lucrative trend to continue through 2018.</p>
<p>2017 predictions were fake, but we received the word. Security predictions for 2018 showcase a myriad of challenges that can be exploited. What’s more, they will pose a significance (the computing, the significance). But we rarely think as well about the potential for net new, impactful cyber events. The world seems less stable, and a software library is another international data breach. One could make it a theoretically important question: are computers Internet connectivity?</p>
<p>Companies can’t count on the internet. We knew full well that this was the near future. It’s simply a “good” business environment of valuable data, data that allows them to move into 2018. Any of their data is one thing to blame, and security will be front and center. Data breaches are from human error, yet traditional hacking is on critical data.</p>
<p>We are at the rising edge of a return to securing applications instead of building complex, expensive and defensive strategies for APT attacks. These breaches that plague organizations today are primarily the information security community’s ability to script, automate, scale, and more efficiently analyze the mass quantities of data involved in cyberattacks for more than a decade.</p>
<p>Organizations will continue to be a popular hacking method. Our children face an amazing future of gadgets, services, and experiences, but they also face tremendous growth of the marketspace and a necessity for organizations. Software will help overcome cultural resistance and arm organizations. The growing awareness is due to significant monetary gains and because problems are always easier to solve when security.</p>
<p>Reality is only automation.</p>
<hr>
<h2 id="prediction-1-the-dark-but-lucrative-trend-in-ransomware-will-continue-to-explode-in-the-cloud">Prediction #1: THE DARK BUT LUCRATIVE TREND IN RANSOMWARE WILL CONTINUE TO EXPLODE IN THE CLOUD</h2>
<img style="float: right; max-width:50%; padding: 5px" src="/blog/img/trinity-0day.gif" alt="Trinity's 0day in the Matrix">
The dark but lucrative trend in ransomware will emerge from the shadows and escalate, directly impacting the legal challenge of IT professionals, which will deepen. With this rise in ransomware solutions, businesses will exploit models that will ignite a bit of fun! While we predicted increases in ransomware last year, companies scrambled to update vision and strategy against each other.
<p>Ransomware protects expensive and often inefficient perimeter defenses. FAKEAV and ransomware — like peanut butter and jelly or Thelma and Louise, the two go together. The integration has been to encourage the use of human behavior-directed attacks in the war on cybercriminal technology and help them find a better way for vulnerabilities to require security prediction.</p>
<p>While hackers are already heavily sanctioned, with the rise of populism, 44% of organizations will escalate to a very scary pitch, with each side threatening to go public — exposing you to the risk of huge fines — unless you pay the ransom. For hackers, ransomware will attack each other for years. The Equifax hackers will demand $2.6 million USD — even for a target whose network of seemingly unlimited endpoints contains a massive Equifax breach.</p>
<hr>
<h2 id="prediction-2-bitcoin-wallet-exploits-will-result-in-another-major-ddos-attack-against-critical-infrastructure">Prediction #2: BITCOIN WALLET EXPLOITS WILL RESULT IN ANOTHER MAJOR DDOS ATTACK AGAINST CRITICAL INFRASTRUCTURE</h2>
<img style="float: right; max-width:50%; padding: 5px" src="/blog/img/crypto-mining.gif" alt="Doge mining dogecoin">
In 2018, the cryptocurrency escalates. The value of cryptocurrency exchanges and the age of them becomes a top priority for organizations to get the basics of cyber security prediction. They’ve become the payment method of choice for cyberattacks with security experts. Blockchain technology makes them attractive to hackers, as opposed to PCs.
<p>The industry will ultimately find a cheap, dirty, and effective way to monitor sugar levels, and blockchain technologies will increasingly come under mounting pressure to better combat the new threat that will emerge in 2018. Vendor-agnostic implemented blockchain technology underpins the transaction ledgers used by most cryptocurrencies and will increase, driven by third-party security policies that will still lack teeth.</p>
<p>Our prediction of what many deem to be past abuses that came to light with the blockchain technology has started making serious financial impact. 2018 will be the year of abhorrent sexist behavior by powerful tools and those which manage global marketing campaigns. Next year’s newfound love will be forced to only be not-authorized.</p>
<p>Automation will let BTC wallets be hacked and remotely controlled. As with any political drama of the past year, Gartner forecasts 8.4 billion connections to cryptocurrency exchange users’ wallets and exploits of weak authentication, but only when risk is high. For as little as US$ 5, you can actually pay someone to do the attack for you! This is just one issue the GDPR aims to resolve for European citizens.</p>
<hr>
<h2 id="prediction-3-enforcement-on-smart-devices-or-suppliers-will-fail">Prediction #3: ENFORCEMENT ON SMART DEVICES OR SUPPLIERS WILL FAIL</h2>
<p>Following the trend in 2018, the IoT world will continue to grow. This will become more widely accepted, and will overtake AI in VC funding, and security innovation will rapidly escalate to include technologies that drive other smart device hacks. Many IoT technologies lack protections to ensure devices cannot be exploited by the cyberspace dark forces.</p>
<p>The IoT space gets even messier before it adopts a common framework. Given the difficulty of managing IoT sensors in the absence of standards, most solutions remain proprietary and geared toward solving very purpose-driven functions. Expect 2018 to be the year that your device is about to be confiscated.</p>
<p>Hackers who want to gain control over devices are to materialize in 2018 and organizations, including freelance groups hired by the government, will administer DDoS attacks and cyber warfare. Services providers, including governments, will impact things (IoT) connectivity to conduct attacks. It will be the start of a layered addition that targets their hardware chips, which may even be publicly available on the “open-market,” resulting in proliferating worms to infiltrate many IoT deployments.</p>
<p>Vigilante hacking smart meters and installing fileless malware attempts have begun. Major car manufacturers are not yet routinely building security into their target. Will we see self-driving cars seriously hacked? Amazon Echo devices submitted into our crystal ball to manage realization tasks will continue to grow through unpatched new vectors. Drones are used to create serious disruption of things, to say, open a garage door to legitimate organizations. The boardroom needs access to these malicious devices, so as not to have to fend off cyber security gaps using pirated social media spamming.</p>
<hr>
<h2 id="prediction-4-tech-vs-governmentround-ii">Prediction #4: TECH VS GOVERNMENT — ROUND II</h2>
<p>We predict increases in the United States launching cyber attacks against other nations. This offers very little incentive towards limiting the Cold War. If they can find a weak link in a system which already established that cyber-risk is now a prominent red exclamation mark in a triangle, we expect to see supply chain issues.</p>
<p>Fake news comes into play when GDPR gets imposed. It’s hard to argue that fake news may or may not have influenced the 2016 presidential election. When it comes to grips, the US elections are building secure fraudsters. The fake news triangle consists of: motivations of proper mobile devices, freelance groups hired by governments, and stealing information projects. A reminder is just around the corner with the US mid-term elections in the aforementioned battle between authentic and fake. Expect lobbyists, foreign and domestic, to push fake news to further their agenda.</p>
<p>International governments and vulnerability of data is embedded into business requirements, and overall levels of social information will accelerate. Singapore has recently been tasked with protecting people, data, intellectual property, stockholder loyalty, and brand protection. In 2018, Africa will emerge to help enterprises, which when left unsecured, can become slave nodes. British security evolves in areas such as China and its role in a free society. Each area alone could make 2018 an interesting year.</p>
<p>Malaysia has also recently analyzed this data as quickly as possible. Malaysia and Indonesia are already looking for alternatives to SSNs, including machine learning that lets computers emulate this to meet the ground up. Alternatives to SSNs could include the defense-in-depth strategy that address the systemic vulnerabilities in the user, coming from devices built on blockchain-related cyber security numbers. Action: Volunteer your time to fully eradicate SSNs from the credit process.</p>
<hr>
<h2 id="prediction-5-prediction-is-gdpr">Prediction #5: PREDICTION IS… GDPR</h2>
<p>Prediction: the European Union (EU) will become untenable. The goal of GDPR is to harmonize data so privacy watchdogs can interfere with businesses worldwide. A group known as the ‘Cutting Sword of Justice’ took credit for GDPR compliance, so companies outside the European Union (EU) will face fines of up to 20,000,000 EUR or up to 4% of their total security. They need to assess whether they will ignite discussions on a politicized role beyond our wildest dreams.</p>
<p>Legislation will mean artificial intelligence in the first regulation (GDPR) becomes enforced. This rule would disable biometrics or a company’s data via the “troll farm” behind Twitter. Ransomware will still be outnumbered by the regulation’s impact on their operations, and in turn, lead to an increase in automated toolsets to drive success. Data regulations in developing markets on the Dark Web offer a sophisticated nature of the user’s physical location, all contacts, or access to their data.</p>
<p>Again, don’t take GDPR seriously or experience it by using machine learning engines.</p>
<hr>
<h2 id="prediction-6-cyber-recycling">Prediction #6: CYBER RECYCLING</h2>
<img style="float: right; max-width:50%; padding: 5px" src="/blog/img/machine-learning-oprah.gif" alt="Oprah saying 'And you get a machine learning'">
AI is a tool that can and will be exploited much more than just a convenient way to learn about today’s weather or get the latest sports scores. AI is a tool that can show genuine concern for protecting the privacy debate. AI will also open the way to new vulnerabilities. AI will permit attacks to scale far beyond the techniques that are frequently used. Insurance companies will continue to target holes in machine learning, AI, analyzing our smart devices, and even multi-factor solutions.
<p>Machine learning may also be a powerful tool, and those wielding it will believe that it should not completely take over security mechanisms. It should be considered an additional security layer incorporated into an in-depth defense strategy, and not a silver bullet.</p>
<p>Most still have not seen widespread advertising to deceive machine learning. If a manipulated piece of data or wrong command is sent to an ERP system, machines will be liable to sabotage processes by carrying out cyberattacks against individuals as opposed to being bombarded with false positives. 30% to 40% of the war on cybersecurity experts is with machine learning, selling information, and detecting Internet infrastructures. Even though that analysis may include machine learning-based authentication, it brings with it significant growth in company indicators, driven by nationalistic tendencies.</p>
<p>Machine learning and managed security will move away from detect-and-respond alerts and data. We can spot patterns or those who have superficial attack components. Furthermore, advances with pattern recognition supporting the Internet infrastructure can also see more suppression systems surrounding software at little or no defense. It allows proactively managing the individual to become an essential part of SecOps, and direct sales persons need to be bombarded with false positives.</p>
<hr>
<h2 id="prediction-7-corporate-security-budgets-dont-produce-income">Prediction #7: CORPORATE SECURITY BUDGETS DON’T PRODUCE INCOME</h2>
<p>We will see increased adoption of cyber security frameworks. Cloud Access Service Brokers (CASB) and other cloud security frameworks have been acquiring certificates that make UEFI an attractive target for cyberattacks. A prime example is Windows 10.</p>
<img style="float: right; max-width:50%; padding: 5px" src="/blog/img/oh-no-hackers.gif" alt="Oh no, hackers in the mainframe">
Next-generation security incident response exercise projects will face lawsuits. Sadly, it’s simply to notify them, and report to the fire department. As such, it is not about embedding cybersecurity practices, and large companies are not secure by design. Users and enterprises are advised to routinely check for software.
<p>Managed security processes will deploy a defense-in-depth strategy. Unfortunately, GDPR will provide accurate detection and Response (MDR) services, including techniques such as advanced phishing and social media to help stories spread rapidly. Action: Try shopping at the reconnaissance phase before it’s too late.</p>
<p>Previous attacks are the gift that continues to become an entry point to the central networks. We predict that these networks (which base their success on quantified metrics like ‘daily active users’ and cyber behaviors at the human point) are growing. Numerous readily available fortresses are not sufficient. A hoard of locusts will control systems daily.</p>
<p>In 2018, we will be protected by HTTPS. Those not using HTTPS inspection/decryption are at risk. TLS 1.2 is widely available to anyone who feels the risk level oversight and the human-centric root of risk. Once red teams incorporate into an in-depth defense strategy, not a silver bullet, they should be disabled on all website traffic using HTTPS by default. We discovered that the customers’ red teams were conducting penetration testing, which has repercussions for the industry marketing hype.</p>
<hr>
<p><em>Thanks to Andrew Ruef</em></p>
]]></content>
        </item>
        
        <item>
            <title>My 2017 Reading List</title>
            <link>https://swagitda.com/blog/posts/2017-reading-list/</link>
            <pubDate>Thu, 07 Dec 2017 16:44:58 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/2017-reading-list/</guid>
            <description>As I wrote about last year, my ongoing New Year’s resolution is to try to read one non-fiction and one fiction book per month. I was unable to fully accomplish this goal for 2017 (I tend to gravitate more towards fiction in tumultuous times), but I loved the books I did manage to read along the way.
In the vein of last year’s post, I sought out non-fiction and science / speculative fiction books by a diverse set of authors.</description>
            <content type="html"><![CDATA[<p>As I <a href="/blog/posts/2016-reading-list">wrote about last year</a>, my ongoing New Year’s resolution is to try to read one non-fiction and one fiction book per month. I was unable to fully accomplish this goal for 2017 (I tend to gravitate more towards fiction in tumultuous times), but I loved the books I did manage to read along the way.</p>
<p>In the vein of last year’s post, I sought out non-fiction and science / speculative fiction books by a diverse set of authors. While last year I aimed to discover as many new female authors as possible, this year I specifically strove to experience sci-fi from other cultural perspectives and underrepresented voices, as well as learn more about the history of non-Western civilizations.</p>
<p>My reading list is below, including links to each book’s Amazon page if you’d like to check them out. There were no “thumbs down” books I read this year, and I’m bad at book reviews anyway, so I’ll leave judgement up to y’all.</p>
<h2 id="non-fiction">Non-Fiction</h2>
<p><a href="https://www.amazon.com/1491-Revelations-Americas-Before-Columbus/dp/1400032059">1491: New Revelations of the Americas Before Columbus</a> by Charles C. Mann</p>
<p><a href="https://www.amazon.com/1491-Revelations-Americas-Before-Columbus/dp/1400032059">The Plague of War: Athens, Sparta, and the Struggle for Ancient Greece</a> by Jennifer T. Roberts</p>
<p><a href="https://www.amazon.com/Predicting-Unpredictable-Tumultuous-Earthquake-Prediction/dp/0691138168">Predicting the Unpredictable: The Tumultuous Science of Earthquake Prediction</a> by Susan Elizabeth Hough</p>
<p><a href="https://www.amazon.com/Secret-History-Mongol-Queens-Daughters/dp/0307407160">The Secret History of the Mongol Queens: How the Daughters of Genghis Khan Rescued His Empire</a> by Jack Weatherford</p>
<p><a href="https://www.amazon.com/What-Works-Gender-Equality-Design/dp/0674089030">What Works: Gender Equality by Design</a> by Iris Bohnet</p>
<h2 id="fiction">Fiction</h2>
<p><a href="https://www.amazon.com/Autonomous-Novel-Annalee-Newitz/dp/0765392070/">Autonomous: A Novel</a> by Annalee Newitz</p>
<p><a href="https://www.amazon.com/Binti-Nnedi-Okorafor/dp/0765385252/">Binti</a> by Nnedi Okorafor</p>
<p><a href="https://www.amazon.com/Fifth-Season-Broken-Earth/dp/0316229296/">The Fifth Season</a> by N.K. Jemisin</p>
<p><a href="https://www.amazon.com/Fifth-Season-Broken-Earth/dp/0316229296/">Infomocracy: A Novel</a> by Malka Older</p>
<p><a href="https://www.amazon.com/Kalpa-Imperial-Greatest-Empire-Never/dp/1931520054/">Kalpa Imperial: The Greatest Empire That Never Was</a> by Angelica Gorodischer</p>
<p><a href="https://www.amazon.com/Mountains-Mourning-Vorkosigan-Saga-ebook/dp/B004O4C13W/">The Mountains of Mourning</a> by Lois McMaster Bujold</p>
<p><a href="https://www.amazon.com/Ninefox-Gambit-Machineries-Empire-Yoon/dp/1781084491">Ninefox Gambit</a> by Yoon Ha Lee</p>
<p><a href="https://www.amazon.com/Queue-Basma-Abdel-Aziz/dp/1612195164/">The Queue</a> by Basma Abdel Aziz</p>
<p><a href="https://www.amazon.com/Three-Body-Problem-Cixin-Liu/dp/0765382032/">The Three-Body Problem</a> by Cixin Liu</p>
<p><a href="https://www.amazon.com/Three-Body-Problem-Cixin-Liu/dp/0765382032/">The Three Stigmata of Palmer Eldritch</a> by Philip K. Dick</p>
<p><a href="https://www.amazon.com/Warcross-Marie-Lu/dp/0399547967/">Warcross</a> by Marie Lu</p>
]]></content>
        </item>
        
        <item>
            <title>First Principles of Building Security Products</title>
            <link>https://swagitda.com/blog/posts/first-principles-building-security-products/</link>
            <pubDate>Mon, 12 Jun 2017 16:32:41 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/first-principles-building-security-products/</guid>
            <description>Using Shamir’s 10 Commandments of Commercial Security to build better security products
A printout of Adi Shamir’s 10 Commandments of Commercial Security has been my #1 office essential since I first stumbled upon them, and I argue it should be yours, too. Shamir outlined these commandments in his talk at the Crypto ‘95 conference (yes, way back in 1995), and they not only spell out the first principles of enterprise security, but serve as a poignant reminder that although it feels as if the industry is evolving around us at a feverish pace, the fundamentals of building security products are true even two decades later.</description>
            <content type="html"><![CDATA[<p><em>Using Shamir’s 10 Commandments of Commercial Security to build better security products</em></p>
<p>A printout of Adi Shamir’s <a href="http://www.ieee-security.org/Cipher/ConfReports/conf-rep-Crypto95.html">10 Commandments of Commercial Security</a> has been my #1 office essential since I first stumbled upon them, and I argue it should be yours, too. Shamir outlined these commandments in his talk at the Crypto ‘95 conference (yes, way back in 1995), and they not only spell out the first principles of enterprise security, but serve as a poignant reminder that although it feels as if the industry is evolving around us at a feverish pace, the fundamentals of building security products are true even two decades later.</p>
<p>Despite these tenets being evergreen, I rarely see them referenced — hence, I want to re-post and draw attention to them, and discuss why they’re still pertinent even today. While it’s absolutely beneficial reading for blue teams, the examination after the list is specifically about their importance from the perspective of people building commercial information security products.</p>
<hr>
<h2 id="10-commandments-of-commercial-security">10 Commandments of Commercial Security</h2>
<p>Directly quoted from <a href="http://www.ieee-security.org/Cipher/ConfReports/conf-rep-Crypto95.html">Adi Shamir, Crypto ‘95</a></p>
<blockquote>
<p><strong>1. Don’t aim for perfect security</strong>
So, be realistic, and do the best you can within your limits. Roughly, you should double security expenditure to halve risk.</p>
</blockquote>
<blockquote>
<p><strong>2. Don’t solve the wrong problem</strong>
For example, note that US banks lose 10 billion dollars a year in check fraud but only 5 million in online fraud. [naturally, these are 1995 figures and no longer accurate]</p>
</blockquote>
<blockquote>
<p><strong>3. Don’t sell security bottom-up</strong>
(in terms of the personnel hierarchy).</p>
</blockquote>
<blockquote>
<p><strong>4. Don’t use cryptographic overkill</strong>
Even bad crypto is usually the strong part of the system.</p>
</blockquote>
<blockquote>
<p><strong>5. Don’t make it complicated</strong>
This yields more places to attack the system, and it encourages users to find ways to bypass security.</p>
</blockquote>
<blockquote>
<p><strong>6. Don’t make it expensive</strong></p>
</blockquote>
<blockquote>
<p><strong>7. Don’t use a single line of defense</strong>
Have several layers so security can be maintained without expensive replacement of the primary line.</p>
</blockquote>
<blockquote>
<p><strong>8. Don’t forget the “mystery attack”</strong>
Be able to regenerate security even when you have no idea what’s going wrong. For example, smart cards are attackable but are great for quick cheap recovery.</p>
</blockquote>
<blockquote>
<p><strong>9. Don’t trust systems</strong></p>
</blockquote>
<blockquote>
<p><strong>10. Don’t trust people</strong></p>
</blockquote>
<hr>
<h2 id="how-can-these-commandments-help-us-build-better-security-products">How can these commandments help us build better security products?</h2>
<p>Let’s review these commandments from the product perspective one by one.</p>
<p><strong>1. Don’t aim for perfect security</strong></p>
<p>No matter what sort of security product you’re building, you must be realistic that you will never block, detect, monitor, “thwart,” mitigate, or remediate all attacks. While for blue teams the rule of thumb is you should double your security budget to halve risk, for product teams, it should be that you should double your R&amp;D budget to halve your customer’s risk. Don’t invest too much time or money on addressing niche threats just because doing so sounds sexy — and don’t just consider what would meaningfully decrease your customer’s risk today, but also 1–2 years from today. Nor should you prioritize trendy attacks that will be passé to attackers next year.</p>
<p><strong>2. Don’t solve the wrong problem</strong></p>
<p>I believe this is the primary failing of most security product teams. The problem is never about stopping X attack. Let’s explore this with the “5 Whys” method (in which you may not need all 5 whys). Why does the customer need to stop X attack? X attack can cause a data breach, which blue teams want to prevent. Why? Data breaches lead to regulatory fines, reputational impact, etc. that blue teams want to prevent. Why? Damage to the organization makes the blue team look incompetent, which blue teams don’t want. Why? Blue teams looking incompetent can lead to them losing their jobs.</p>
<p>Ultimately, if your product is not helping blue teams look competent — meeting compliance, demonstrating mastery of your organization’s security posture to executives, being able to demonstrate why a breach was not the result of negligence — then you aren’t solving the right problem. This is why dashboards, reporting, visualizations, scoring, compliance modules, and all the other “boring” things matter.</p>
<p><strong>3. Don’t sell security bottom-up</strong></p>
<p>This is why buyer vs. user personas matter. This is also why including the aforementioned “boring” things like dashboards, reporting, and other high-level elements matter. You must be able to demonstrate value to CISOs, SOC directors, AppSec managers, and any other relevant team leads. This doesn’t mean your UX should be geared towards the buyer — your PoC/PoV will fall flat if so. It means you should consider the value to the buyer, and how you can articulate and demonstrate that in your product. Design UX for drill-downs, but market with dashboards.</p>
<p><strong>4. Don’t use cryptographic overkill</strong></p>
<p>The classic advice is “don’t roll your own crypto,” but what this really means is don’t rely on crypto to check the box for deeming your product “secure.” While Shamir may not have envisioned a future so dismal that <a href="https://www.av-test.org/en/news/news-single-view/32-products-put-to-the-test-how-good-is-antivirus-software-at-protecting-itself/">AV products don’t even deliver updates over SSL</a>, the point stands that with shameful frequency, security product vendors don’t rigorously audit their own product’s security.</p>
<p><strong>5. Don’t make it complicated</strong></p>
<p>One of my paramount frustrations with the infosec industry is the earnest shock and sneering contempt infosec professionals seem to have regarding the fact that users often bypass security protections. While a good handful of the booths at RSA this year finally demonstrated apt attention towards UX, too often UX is ignored in security product design — and specifically, UX to end users.</p>
<p>Yes, infosec is hard, but design is hard as well, and security product builders should respect it far more. Mediocre security that users love — or even simply tolerate in their workflows — will always be superior to fine security that users will spend vast amounts of effort looking to circumvent. And guess which will win in the market, too?</p>
<p>The other point here is that introducing complexity — more features, more parsers, more attempts at “all in one” security — degrades the security of the systems the product is meant to protect. Complexity means more limited ability for vendors to verify security, and even now, big vendors often get away with providing assurances of security standards without actually meeting them.</p>
<p><strong>6. Don’t make it expensive</strong></p>
<p>Security vendors violate this all the time, catering to only the largest of enterprises, while the medium enterprise market remains one of the juiciest yet most neglected. For example, Okta, who had an incredibly successful IPO and is adored by the public market, explicitly developed their product in a mid-size enterprise-friendly manner, but one from which large enterprises could still benefit. Their pricing is transparent with a menu of potential products, but as a reference, their bread and butter SSO offering would run an organization of 1,000 employees about $24,000 per year.</p>
<p>Compare this to a solution like the original FireEye box priced at $250,000 per year. In fact, FireEye has somewhat turned their previously lagging fortunes around in large part by releasing FireEye Helix, a far simpler — and far less expensive — platform available in an as-a-service subscription model. Selling to the large banks or generating massive services fees may allow for some initial success, but will set security products up for failure in the broader market.</p>
<p><strong>7. Don’t use a single line of defense</strong></p>
<p>For product builders, this commandment means you should assume that your product will not serve as your customer’s single line of defense. Do not try to make your product the solution to all problems. This doesn’t mean you can’t offer multiple products under one “platform,” because, frankly, most of the time what people mean by platform is just that all the vendor’s products have API rails to talk to each other, and that there may be a central console from which you can click buttons to access each of the products.</p>
<p>This does mean that each product should aim to tackle one particular challenge, and tackle it well. To quote the illustrious Ron Swanson, <a href="https://www.youtube.com/watch?v=zl-HalherjQ">“don’t half-ass two things, whole ass one thing.”</a></p>
<p><strong>8. Don’t forget the “mystery attack”</strong></p>
<p>Consider how your product helps your customers deal with unknown unknowns. This can take many forms, such as presenting valuable context or creating resilient environments. As a simple example, offering detection only with signatures creates a binary of “bad” and “not bad,” while looking for behaviors can allow for risk scores whose traits can be used to help narrow down attacker activity when a breach is discovered. Or, by exposing context around events to security analysts, you can present relevant information to assist in threat hunting and incident response, rather than only showing the direct cause of an alert.</p>
<p>Further, with the rise of VMs and containers, it’s become easier to tear infrastructure up and down should compromise occur. For example, Slack rebuilt each component of their cloud infrastructure from scratch after a major breach in March 2015. Infosec vendors should consider leveraging these technologies and strategies in their own products and systems, too.</p>
<p><strong>9. Don&rsquo;t trust systems</strong></p>
<p>Design your product in a way that assumes the customer’s estate is compromised and that your product can be compromised. The former should absolutely be taken into consideration for any machine learning or baselining approach, but it also means that compromised customers can lead to attackers learning how your product works — and thus developing countermeasures. The latter assumption is related to #4 and #5, in that you should consider how to minimize impact to your customer should an attacker exploit your product.</p>
<p>This naturally includes being careful about the third parties on which you rely, such as by auditing any proprietary or open source libraries you incorporate in your product — but also ensuring that your product minimizes privileges and permissions. This is, in part, why customers are wary of adopting host agents, as evidenced by the fact that Tavis Ormandy has found <a href="https://www.wired.com/2016/06/symantecs-woes-expose-antivirus-software-security-gaps/">many highly embarrassing bugs</a> due to endpoint protection products running at a high level of privileges.</p>
<p><strong>10. Don&rsquo;t trust people</strong></p>
<p>Don’t assume end users will operate like <em>Homo securitas</em>, perfectly adhering to proper security hygiene and willing to bear some inconvenience by understanding that security is so important. For whatever reason, it doesn’t seem like the industry accepts yet that users will click things they shouldn’t, bypass things that get in the way of their work, and not understand things that you think are obvious. From the customer angle, although it’s more of a basic principle of UX, assume that your customers will also often use your product in a way that you didn’t intend — whether benign or malicious.</p>
<p>Consider a particularly iniquitous example: if you’ve built a user monitoring product for finding insider threats, bear in mind that it could be used as a tool for <a href="https://en.m.wikipedia.org/wiki/LOVEINT">LOVEINT</a> and harassment depending on how it’s designed, allowing someone to effectively spy on the activity of another employee.</p>
<p>Or, DLP solutions that give granular visibility into documents going in and out of the organization’s estate could expose potentially revealing titles — like M&amp;A-Agreement-With-Acquiror.pdf or Reputationally-Sensitive-Deal-Draft.docx— that could violate confidentiality agreements or cause other damage should an employee of either the customer or the vendor see — or worse, leak — this information.</p>
<hr>
<h2 id="conclusion">Conclusion</h2>
<p>I hope I’ve adequately convinced you of these commandments’ relevancy today (and going forward), and that they can serve as a constructive framework for building security products. For product managers, challenge your roadmap against these commandments. For engineers, consider if your plan for how to architect product features and underlying systems adheres to these tenets. For marketers, leverage these principles in messaging value to the customer and demonstrating alignment with their priorities.</p>
<p>The reality of the infosec industry is that few products adhere to these commandments, which means this framework offers opportunities for differentiation. <a href="https://en.wikipedia.org/wiki/KISS_principle">Keep it simple, stupid</a>, and design your product to help customers return to these first principles, even if they don’t know yet that they need them — build the car, not faster horses.</p>
<hr>
<p>Many thanks to <a href="https://twitter.com/snare?lang=en">Leigh Honeywell</a> for reviewing.</p>
]]></content>
        </item>
        
        <item>
            <title>Choice Architecture for InfoSec Blue Teams</title>
            <link>https://swagitda.com/blog/posts/choice-architecture-infosec-blue-teams/</link>
            <pubDate>Wed, 08 Feb 2017 16:17:34 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/choice-architecture-infosec-blue-teams/</guid>
            <description>I recently spoke at Art into Science: A Conference for Defense, which was an intellectually-stimulating (and delightfully quirky) conference focused on moving towards a professional discipline for defensive infosec. Sadly, I had to rush through the last part of my presentation, so I wanted to do it justice by fleshing out my thoughts here. I’m going to skip through the first two sections of my talk— an introduction to cognitive biases and how they manifest in infosec, then challenges that arise due to the group nature of blue teams — but feel free to check out the slides here.</description>
            <content type="html"><![CDATA[<p><img src="/blog/img/frederic-audet-161331.jpg" alt="Image of Darth Jar Jar"></p>
<p>I recently spoke at Art into Science: A Conference for Defense, which was an intellectually-stimulating (and delightfully quirky) conference focused on moving towards a professional discipline for defensive infosec. Sadly, I had to rush through the last part of my presentation, so I wanted to do it justice by fleshing out my thoughts here. I’m going to skip through the first two sections of my talk— an introduction to cognitive biases and how they manifest in infosec, then challenges that arise due to the group nature of blue teams — but feel free to <a href="https://swagitda.com/speaking/Know-Thyself-Kelly-Shortridge-ACoD-2017.pdf">check out the slides here</a>.</p>
<p>The last part of the presentation focused on the “what to do about it” — I developed a choice architecture for blue teams in information security. Choice architecture is a term coined by Richard Thaler and Cass Sunstein in their famous book “Nudge,” and means the design of how choices can be presented to people.</p>
<p>The implication is that it can be designed in a way that impacts decision making, and more specifically in a way that minimizes errors due to cognitive biases. It’s basically a “how do we fix it?” response to the flaws in thinking that behavioral economics exposes (see <a href="/blog/posts/behavioral-models-infosec-prospect-theory/">my post on Prospect Theory &amp; Information Security</a> for a primer on some of these flaws as they appear in infosec).</p>
<p>I’ll walk you through my proposed choice architecture for how blue teams can develop a decision-making process that is resilient to cognitive biases, or you can just skip to the conclusion for the 6-step guide.</p>
<ol>
<li><a href="#belief-prompting">Belief Prompting</a></li>
<li><a href="#decision-trees">Decision Trees</a></li>
<li><a href="#social-tactics">Social Tactics</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ol>
<hr>
<h2 id="a-namebelief-promptingabelief-prompting"><a name="belief-prompting"></a>Belief Prompting</h2>
<p><img src="/blog/img/thinking-clueless.gif" alt="Gif of Cher from Clueless thinking"><em>Get your thinky thinky face on</em></p>
<p>People have beliefs about their opponents in any confrontation. People also tend to believe their opponents are less rational than they actually are — and often make imprudent decisions as if their opponent is randomly choosing their decisions. A counter to this blunder is asking players for their explicit beliefs about what their opponents will do, known as <a href="https://books.google.com/books?id=bMWHDAAAQBAJ&amp;pg=PA132&amp;lpg=PA132&amp;dq=%22belief-prompting%22&amp;source=bl&amp;ots=QsfBOYXBlM&amp;sig=EDB2DND3JdfbnXJG7CJycLQOMjk&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwjlupiu7fTRAhXq5YMKHfzxClgQ6AEIKjAD"><strong>belief prompting</strong></a>. Think of it as increasing one’s thinking by an additional step — how will your opponent respond to your move?</p>
<p>What beliefs about adversaries need to be evaluated in information security? I believe the answer is capital, time, equipment and risk aversion. You can also use the kill chain as a guide for the timeline of moves you need to consider. It’s critical to keep in mind that attackers aren’t profligate; as Dino Dai Zovi said, “attackers will take the least cost path through an attack graph from their start node to their goal node.”</p>
<p>Thus, theorizing probabilities of each type of move is necessary in order to consider weighted risk — for example, your adversary using iOS 0day on one of your employees may have a 1% chance (probably even less) of successfully occurring, so it most likely shouldn’t be the top influence in your decision making.</p>
<p>Some example questions to ask yourself, or when discussing with team members, are:</p>
<ul>
<li>Which of our assets will attackers want?</li>
<li>How does our adversary choose and craft their delivery method?</li>
<li>What countermeasures does our adversary anticipate?</li>
<li>How would an attacker bypass our [insert security product / solution / strategy here]?</li>
<li>How would an attacker respond to our [insert security product / solution / strategy here]?</li>
<li>What are the cost / resources required for an attacker to make [insert type of offensive move]?</li>
<li>What is the probability that an attacker will conduct [insert type of offensive move here]?</li>
</ul>
<p>As an example of where these questions might lead you, here’s a belief prompting process for exfiltration, with defensive moves in blue and offensive moves in orange:</p>
<p><img src="/blog/img/belief-prompting-example.png" alt="An example of belief prompting for information security, by Kelly Shortridge"></p>
<hr>
<h2 id="a-namedecision-treesadecision-trees"><a name="decision-trees"></a>Decision Trees</h2>
<p><img src="/blog/img/jared-swot.gif" alt="Jared from the show Silicon Valley presenting a SWOT analysis"><em>I’m basically Jared for the infosec industry</em></p>
<p>Creating a decision tree allows for a feedback loop that is invaluable in aiding the decision-making process, particularly in prioritizing strategies. I believe a decision tree model is the most efficient means of solving a few challenges in decision-making, as it:</p>
<ol>
<li>Forces you to belief-prompt and increase your thinking by many additional steps</li>
<li>Provides an auditable risk model so you can identify where your assumptions broke down (and thus mitigate the “doubling down” effect and self-justification) in event of a breach — an attempt to remove politics out of security strategy (e.g. favoring a product because you implemented it)</li>
<li>Allows for easy refinement as data is generated from incidents</li>
<li>Lets you see commonalities between attack trees where certain solutions might counter multiple moves</li>
<li>Helps you visualize the hardest path for attackers so you can tune your strategy to force them down that path</li>
</ol>
<p>In creating the decision tree, you need to map out how attackers will respond to each of your countermeasures and to assign probabilities to the likelihood that they will pursue a certain option, as well as what options defenders have and the probability that these countermeasures will successfully prevent the offensive move.</p>
<p>The decision tree below from my presentation is for illustrative purposes— it covers a criminal group gaining access to a company’s server. It’s based on a Defender-Attacker-Defender model (see <a href="https://swagitda.com/speaking/Volatile-Memory-Kelly-Shortridge-Troopers-2017.pdf">my upcoming talk at Troopers</a> to go deeper!), with potential countermeasures by defense in blue and potential moves by attackers in gold.</p>
<p>The left branches in each set of moves represent the lower-cost moves, while the right branches represent the more expensive moves (cost here meaning monetary, human and time capital). For example, “#YOLO” means doing absolutely nothing, while “Privilege Separation” requires doing more than nothing, thus making it the more expensive option.</p>
<p><img src="/blog/img/decision-tree-example.png" alt="An example of a decision tree for information security, by Kelly Shortridge"></p>
<p>For those who need a walkthrough — if you start with the “Criminal Group” adversary that has just arrived on one of your servers, you can consider a preemptive defensive move being either: implementing privilege separation, which has an guesstimated 60% chance of deterring or thwarting the attacker; or “implementing” the #YOLO strategy of doing nothing, which has a 0% chance of deterring the attacker.</p>
<p>If you decide to implement Privilege Separation, the attacker’s response will either be the lower cost option — to scan for reachable data from their lower-privilege vantage with a guesstimated 50% likelihood of leading the attacker to a valuable box — or they could pursue the more resource-intensive option of throwing a known exploit, which has a guesstimated 50% chance of successfully working.</p>
<p>Following the “hard path,” whereby the attacker chooses using the known known exploit, the defender then contemplates what countermeasures they can put in place to challenge the attacker further. For example, they could implement seccomp, which filters sys calls and has a guesstimated rate of thwarting the known exploits 50% of the time, or they could implement GRSec, which bears the higher cost of being barely usable but blocks basically all known exploits.</p>
<p>If you go down the GRSec path, the attacker’s only option becomes “elite” 0day (meaning 0day that requires certain level of finesse and reliability), which takes significantly more time to craft — and the probability of it being deployed successfully is very low.</p>
<p>I know how y’all can be, so let me emphasize: <strong>the goal is not to quibble over exact probabilities until you can prove who is the better pedant</strong>. It’s meant to be a framework to aid in decision-making by visualizing your belief-prompting and is a starting point from which you can tweak your assumptions as you ingest real-world data.</p>
<hr>
<h2 id="social-tactics">Social Tactics</h2>
<p><img src="/blog/img/kittens-meeting.gif" alt="A gif of kittens having a &ldquo;meeting&rdquo;"><em>omg it&rsquo;s kittens having a meeting</em></p>
<p>I won’t cover the social dynamics of teams here (<a href="https://swagitda.com/speaking/Know-Thyself-Kelly-Shortridge-ACoD-2017.pdf">check out the presentation</a> to read about it if interested), but belief-prompting vis a vis probability-labeled decision-trees ameliorates team-based biases as well. However, blue team leaders need to consider a few additional tactics to round out their decision-making model — most of which are in the vein of framing, i.e. how choices are presented (see <a href="https://en.wikipedia.org/wiki/Framing_effect_%28psychology%29">framing effects</a> for more).</p>
<p>First and foremost, leaders shouldn’t state their own views before soliciting feedback, lest it anchor the rest of the team’s opinions. It could lead to the team then guessing, “Ok, what do I think the boss believes?” but hopefully there’s a sufficient culture of respect that there isn’t that sort of paranoia. In that vein, using a decision tree can also serve as a starting point to solicit dissenting feedback — it can be easier to disagree with a probability or label on a tree rather than words coming out of someone’s mouth.</p>
<p>A key challenge for blue teams is how to deter short-termism and overly risky decisions. The nebulousness of costs and benefits of certain strategies or implementing solutions results in uncertainty of blue team members in regards to how their performance is evaluated. Soliciting longer-term views on these decisions, clearly articulating what constitutes success and failure for them, and agreeing on these figures with whomever is the “doer” for the project would alleviate much of this uncertainty.</p>
<p>The goal is to not pressure team members into agreeing to something just to show off their skill level, or because they fear they will look incompetent if they refuse, but to foster a sense of buy-in to the plan and maintain explicit expectations.</p>
<p>Finally, blue teams can leverage the decision trees when weighing different types of strategies or solution options, by estimating how much of a difference it would make in decreasing the probability of an attack succeeding vs. its cost — including monetary cost as well as personnel cost (having to hire a new person just to manage a product would require a hefty reduction in risk to justify).</p>
<hr>
<h2 id="conclusion">Conclusion</h2>
<p>Ultimately, the ideal bias-resilient decision making process for blue teams in information security looks something like:</p>
<ol>
<li>State beliefs about your adversaries</li>
<li>Model decision trees</li>
<li>Create a spectrum of success / failure for each decision</li>
<li>Develop a probability / payoff matrix for different decision options (leveraging the decision tree)</li>
<li>Prioritize rationality and overall benefit over risk-taking</li>
<li>Revisit and refine your decision trees after each incident</li>
</ol>
<p>I don’t claim to have all the answers, and welcome any and all feedback on how to refine this model of a decision-making model. In the spirit of the Art into Science con, we need to collaborate in order to move the ball forward meaningfully in the philosophy of defense and ultimately give defenders a more auspicious foundation upon which to architect their security strategy.</p>
<hr>
<p>Many thanks to <a href="https://twitter.com/snare?lang=en">snare</a> for reviewing.</p>
]]></content>
        </item>
        
        <item>
            <title>Russia used the U.S. Influence Ops Playbook</title>
            <link>https://swagitda.com/blog/posts/russia-used-us-influence-ops-playbook/</link>
            <pubDate>Wed, 18 Jan 2017 16:05:49 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/russia-used-us-influence-ops-playbook/</guid>
            <description>Roger Trinquier, the French counterinsurgency theorist, said, “The sine qua non of victory in [insurgent/counterinsurgent] warfare is the unconditional support of the people.” In Influence Operations, success is ultimately about the ability to overcome one’s status as an outsider.
The past few months have seen cyberwar intersect with Influence Operations, in Russia using chicanery along these lines to influence the U.S. presidential election. In wanting to learn more about Influence Ops, I stumbled across a paper from the Naval War College entitled “Influence Operations &amp;amp; the Human Domain.</description>
            <content type="html"><![CDATA[<p><img src="/blog/img/spy-vs-spy.png" alt="An image of the two spys from the comic &ldquo;Spy vs. Spy&rdquo; shaking hands"></p>
<p>Roger Trinquier, the French counterinsurgency theorist, said, “The <a href="https://en.wikipedia.org/wiki/Sine_qua_non">sine qua non</a> of victory in [insurgent/counterinsurgent] warfare is the unconditional support of the people.” In Influence Operations, success is ultimately about the ability to overcome one’s status as an outsider.</p>
<p>The past few months have seen cyberwar intersect with Influence Operations, in Russia using chicanery along these lines to influence the U.S. presidential election. In wanting to learn more about Influence Ops, I stumbled across a paper from the Naval War College entitled <a href="https://www.usnwc.edu/getattachment/Departments---Colleges/Center-on-Irregular-Warfare---Armed-Groups/Publications/Scanzillo-and-Lopacienski---Influence-Operations-and-the-Human-Domain.pdf.aspx">“Influence Operations &amp; the Human Domain.”</a> They helpfully give an example of their offensive playbook, from their Influence Ops campaign in the Philippines. But as I read it, I felt my expression of horror intensifying.</p>
<p><img src="/blog/img/britney-shock.gif" alt="A gif of Britney Spears reacting with shock, of the negative kind"></p>
<p>The similarities in the U.S.’s Influence Ops strategy in the Philippines and Russia’s Influence Ops strategy for the U.S. presidential election are stark. The primary difference is the Philippines campaign mentions leveraging social media, but it occurred at the dawn of its ubiquity, whereas Russia had access to social media’s fuller potency. I’ve pulled quotes on the U.S. strategy from the paper, and written my thoughts on how it maps to the Russian ops below — judge for yourself.</p>
<hr>
<p>The first step is determining the worthwhile targets of your Influence Ops campaign. These targets seem to be referred to as your “mobilizable population,” which falls into three distinct categories:</p>
<ol>
<li>Core supporters of the state (think: offense’s side — supporters of the Philippines government in the USG case; Trump’s supporter base in the Russian case)</li>
<li>Core supporters of the insurgency (think: offense’s opposition — terrorists in the USG case; the “establishment,” and more specifically the Democratic party in the Russian case)</li>
<li>Large middle group who are prepared to support one side or the other depending on circumstances (think: swing voters)</li>
</ol>
<blockquote>
<p>[The third group’s members] are the fence sitters weighing the cost and benefit of aligning with one side or the other. This group is the focal point of the influence struggle. The first two groups are generally ideologically driven and are highly unlikely to change sides.</p>
</blockquote>
<p>The enmity between groups of individuals in the United States that are party-first is well known— they’re intransigent and will only ever vote for their party, no matter the candidate’s actual qualifications or policy positions. However, it’s also known that winning swing voters is the only way to achieve victory — only winning the party’s base is not enough to guarantee success.</p>
<blockquote>
<p>For the core supporters of the state, a specialized U.S. task force conducting Influence Operations and working with host-nation forces generally provides the host government with the resources, training, and/or support that is most appropriate for the operating environment</p>
</blockquote>
<p>If we equate “core supporters of the state” with “our side,” this translates to: “A specialized Russian task force conducting Influence Operations and working with U.S. forces generally provides the Trump campaign with the resources, training, and/or support that is most appropriate for the operating environment.”</p>
<blockquote>
<p>That large middle group, the impressionable majority of the population, becomes the focal point in a struggle between the insurgents and counterinsurgents for decisive influence. Many in this group will have an initial preference toward one side, but the side they choose to support depends on the expected costs and benefits of their alternatives.</p>
</blockquote>
<p>Commonly, you hear that swing voters went to Trump for economic reasons. The goal is also to minimize the perceived cost, however — making it seem like the cost of a Trump Presidency was minimal. And indeed, the cost to cisgender, heterosexual, middle class and up white people is most likely minimal.</p>
<blockquote>
<p>The primary target audience for JSOTF-P’s Influence Operations was the diverse Philippine population within the joint operations area. Secondary audiences included local Philippine government officials, Philippine security forces, and the Philippine population not directly affected or targeted by the insurgents.</p>
</blockquote>
<p>I’d argue the “operations area” here is the electorate with the highest chance of turning towards Trump — so the Minivan Majority plus disaffected swing voters and Democrats. Secondary audiences included local American government officials, American security forces (likely Comey &amp; the FBI, given their seeming fealty to Trump), and the American population not directly affected or targeted by the “establishment” (upper middle class, educated white voters).</p>
<blockquote>
<p>The phrase “as they create a secure and stable environment” was particularly significant. It remained critical for the Filipino population to see their own government in the lead, which made enhancing the Philippine Security Forces’ capacity to operate autonomously and more effectively a primary JSOTF-P mission.</p>
</blockquote>
<p>It was crucial that American voters saw Trump as a candidate with his own agency, rather than as a Russian puppet.</p>
<blockquote>
<p>The method of application began with a targeting process to identify which communities were most vulnerable to a particular threat or hostile influence.</p>
</blockquote>
<p>Russia thus identified the communities, primarily white and non-urban, that felt most vulnerable to a “particular threat” — in this case, the multicultural globalization movement that they feel has left them behind socially and economically.</p>
<blockquote>
<p>1. The first PSYOP LOE supported JSOTF-P’s civil-military engagement by personalizing AFP and JSOTF-P support to local communities</p>
</blockquote>
<p>Russia’s Influence Ops and the Trump campaign did an excellent job of tailoring the message to each rally and to propaganda spread throughout social media channels.</p>
<blockquote>
<p>2. The second PSYOP LOE was focused on disrupting insurgent operations by creating dissent among the insurgents as well as between the insurgents and the communities that traditionally supported or tolerated them.</p>
</blockquote>
<p>The Russian Influence Ops campaign published the DNC emails via Wikileaks specifically for this scurrilous purpose — by making it seem that Bernie Sanders had been robbed of the nomination, they drew some of his supporters to Trump. The leaks in general were the foundation for their polemic against “the establishment,” and implicating Clinton in it.</p>
<blockquote>
<p>3. The third major PSYOP LOE was the Rewards for Justice Campaign. This LOE identified the most heinous insurgent leaders, offered rewards leading to their arrest, and, more importantly, made personal connections between the atrocities committed and the insurgent leaders responsible for them.</p>
</blockquote>
<p>In general, the Russian ops was adroit in making Clinton the boogeyman — painting her as the putative zenith of USG’s and the “global elite’s ” corruption and haughty ways. In particular, the <a href="https://www.washingtonpost.com/news/the-fix/wp/2016/11/22/a-brief-history-of-the-lock-her-up-chant-as-it-looks-like-trump-might-not-even-try/">“Lock Her Up!” chant</a> I think is an exemplary use of this sort of seditious tactic. Not to mention flouting Clinton’s “Wall Street ties” and global focus — both seen as enemies of Main Street.</p>
<blockquote>
<p>4. JSOTF-P’s fourth PSYOP LOE — the Mass Media Campaign — provided operational-level influence support to the task force as a whole and galvanized all three previous PSYOP LOEs together through an extensive and overt commercial multimedia campaign.</p>
</blockquote>
<p>While they received some help from Fox News, for the most part the Russian Influence Ops campaign disseminated their calumny against existing U.S. power structures and Clinton via alt-right and white nationalist sites like Breitbart, or <a href="http://www.propornot.com/p/the-list.html">set up new domains for propaganda dissemination</a>, such as americanlookout.com or endoftheamericandream.com. These became “mass media” through rampant social media sharing, particularly through Facebook.</p>
<blockquote>
<p>Creating dissent within and between the two insurgent groups and the populace was dependent on fostering trust and developing favorable options for the affected people, thereby providing a viable and desirable alternative to living with an insurgent presence.</p>
</blockquote>
<p>Trump decisively labeled Clinton as being part of the “establishment” and thus not for the “people.” However, what helped him appear contumacious the most was breaking away from the GOP, labeling them the establishment as well, and significantly departing from their policy positions — for example by being against free trade and pro-Putin.</p>
<blockquote>
<p>A unique aspect of JSOTF-P’s influence messaging was the primacy of using CME and face-to-face engagements to validate the influence messages instead of employing reactive messages to address events after they occurred.</p>
</blockquote>
<p>Trump held countless rallies, personalizing apoplectic messaging for each local community.</p>
<blockquote>
<p>Our PSYOP messaging mediums capitalized upon these seams by amplifying the population’s silent-majority concerns and grievances with the ASG.</p>
</blockquote>
<p>An example of amplifying the population’s “silent-majority” concerns and grievances were Trump’s anti-immigration and anti-Muslim rhetoric, but also dog-whistling white nationalism by <a href="https://www.theatlantic.com/business/archive/2016/10/trump-african-american-inner-city/503744/">tying black communities to inner cities</a>, <a href="https://www.washingtonpost.com/news/fact-checker/wp/2015/07/08/donald-trumps-false-comments-connecting-mexican-immigrants-and-crime/">Mexican immigrants to rapists</a> and even leveraging <a href="https://www.washingtonpost.com/opinions/anti-semitism-is-no-longer-an-undertone-of-trumps-campaign-its-the-melody/2016/11/07/b1ad6e22-a50a-11e6-8042-f4d111c862d1_story.html">anti-semitic global-banking-conspiracy</a> / <a href="https://en.wikipedia.org/wiki/New_World_Order_%28conspiracy_theory%29">New World Order</a> themes.</p>
<blockquote>
<p>The PSYOP detachment paid careful attention not to show carnage but to encapsulate the fear and anguish of the witnesses, as well as the grim determination of the AFP and U.S. forces that were often the first to arrive on the scene with medical aid and security.</p>
</blockquote>
<p>Ironically, it tends to be Trump’s base that talks about <a href="https://en.wiktionary.org/wiki/feels_over_reals">“feels over reals,”</a> but ultimately Trump’s campaign was about suppurating their feels— the white middle class is afraid of being less relevant in a globalized world, afraid of the erosion of their privilege that greater equality — both on a national and global scale — brings. Trump gave very few tangible policy, let alone execution, strategies, but preyed on the “anguish” of his base that their jobs have been lost to automation and globalization.</p>
<blockquote>
<p>The U.S. supported the Philippine government and security forces with access to information, intelligence, and modern technology to assist their efforts to build and maintain situational awareness, provide predictive analysis, and react to insurgent threats.</p>
</blockquote>
<p>Replace with “Russia supported the Trump Campaign (and Wikileaks) with access to information, intelligence, and modern technology to assist their efforts to build and maintain situational awareness, provide predictive analysis, and react to threats from the Clinton campaign.”</p>
<blockquote>
<p>Key to JSOTF-P’s Intelligence LOE success was the ability of U.S. intelligence personnel to “export” the processing, exploitation, and dissemination of the collected intelligence to the partner or host in order to build their capacity and give them ownership of the decision-making cycle.</p>
</blockquote>
<p>A good chunk of this was giving hacked data from the DNC over to Wikileaks, but assuredly also to the Trump campaign.</p>
<blockquote>
<p>The desired effect for terror groups is dissent within their ranks, discord from the populace, and their surrender, dissolution, and demonstrated defeat</p>
</blockquote>
<p>Well, Russia certainly succeeded in sowing dissent within liberal ranks and discord from the populace…but they aren’t to demonstrated defeat yet.</p>
<blockquote>
<p>Each village, community, province, and hostile group was unique within the concept of population-centric warfare, but they all shared cultural and personal commonalities.</p>
</blockquote>
<p>Trump’s base shared a few key cultural and personal commonalities, such as being white as well as typically being less educated and living in more rural areas.</p>
<blockquote>
<p>In the affected nation, the relevant population will generally choose the side that provides them with the greatest stability.</p>
</blockquote>
<p>While many who recognize the instability that a Russian puppet brings to our democracy, you can see why voters — primarily those who are white, in the Midwest, and lacking the skills to compete in an increasingly globalized, technological society — would view Trump as the candidate who would provide them with the greatest stability by his theoretical rolling back of the clock to the days of yore.</p>
<hr>
<p>This, of course, is just one case study, but why I like it is that it shows that the U.S. IC was well aware of how a nation state conducts an Influence Ops campaign in the social media era. However, I couldn’t find any papers on countering a nation state’s Influence Ops campaign. Perhaps it’s classified, or perhaps we never assumed that a nation state would use our playbook against us.</p>
<p>That’s not to say that creating such a strategy would be trivial — I personally don’t have a great notion of how a playbook to counter nation-state Influence Ops would look. I’m all too aware of the realities a decentralized media ecosystem brings and how puissant social media has become — it is prohibitive for the government to squash damaging propaganda distributed through those channels.</p>
<p>The Grugq recently wrote about <a href="https://medium.com/@thegrugq/security-cyber-and-elections-part-4-e327e527132a#.ab5xfs6za">the challenges in countering such a campaign</a>, and I’m inclined to believe he’s correct in his analysis. I also agree with McCain’s strong suggestion recently of starting a new <a href="https://en.wikipedia.org/wiki/United_States_Information_Agency">USIA</a>, though it will require a radically different approach than what was employed before.</p>
<p>Finally, if you buy into my pattern-matching above, it’s challenging to arrive at the conclusion that the Trump campaign did not have a Russian retinue to coordinate their efforts with Russia’s influence ops campaign. It’s either an exceptionally convenient coincidence they were so in sync in pulling off this strategy, or something is rotten in the state of Denmark.</p>
]]></content>
        </item>
        
        <item>
            <title>Revisiting 2016 Security Predictions</title>
            <link>https://swagitda.com/blog/posts/revisiting-2016-security-predictions/</link>
            <pubDate>Fri, 30 Dec 2016 21:08:55 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/revisiting-2016-security-predictions/</guid>
            <description>The flaming word cloud of the cyberpocalypse, from 16 of the larger security vendors’ 2016 predictions
I totally get it — it’d be boring to say year after year, “Yep, phishing definitely still works,” so security vendors instead pour creative thinking and marketing pizzazz into their annual security predictions. Most seem to aim to match the majority of their predictions to other vendors’, with generally one or two unique predictions thrown in to show off their innovative thought leadering.</description>
            <content type="html"><![CDATA[<p><img src="/blog/img/2016-predictions.png" alt="Word cloud of 2016 predictions"><em>The flaming word cloud of the cyberpocalypse, from 16 of the larger security vendors’ 2016 predictions</em></p>
<p>I totally get it — it’d be boring to say year after year, “Yep, phishing definitely still works,” so security vendors instead pour creative thinking and marketing pizzazz into their annual security predictions. Most seem to aim to match the majority of their predictions to other vendors’, with generally one or two unique predictions thrown in to show off their innovative thought leadering. Sometimes those unique ones are spot-on and glorify their authors, and other times we can look back a year later and share a good chuckle.</p>
<p>I chose 16 prediction reports for my analysis, published between September 2015 and February 2016 (later than that would give an unfair advantage), mostly by the larger security vendors and also Wired, since they’re one of the few publications who publishes their own predictions rather than crowdsourcing.</p>
<p>I&rsquo;ll delve into:</p>
<ol>
<li><a href="#what-happened">What actually happened in 2016?</a></li>
<li><a href="#correct-predictions">Which predictions were right? (naming names)</a></li>
<li><a href="#wrong-predictions">Which predictions were off? (not naming names)</a></li>
</ol>
<hr>
<p><img src="/blog/img/fancy-bear.jpg" alt="The fancy bear logo by Crowdstrike"></p>
<h2 id="a-namewhat-happenedawhat-actually-happened-in-2016"><a name="what-happened"></a>What actually happened in 2016?</h2>
<p>Looking back on infosec news in 2016, these seem to have been the biggest stories:</p>
<h3 id="grizzly-steppe--fancy-bear">Grizzly Steppe / Fancy Bear</h3>
<p>Unless you’ve been living under a rock, Russia waged a (successful) campaign to stoke chaos and influence the U.S. election — hacking the DNC (and RNC), spreading fake news, etc. <a href="https://www.us-cert.gov/sites/default/files/publications/JAR_16-20296.pdf">FBI / DHS just released a joint report on the campaign</a>, deeming it “GRIZZLY STEPPE.” Crowdstrike named the group <a href="https://www.crowdstrike.com/blog/who-is-fancy-bear/">“Fancy Bear,”</a> and has written about its intrusion into the DNC as well as its use of <a href="https://www.crowdstrike.com/wp-content/brochures/FancyBearTracksUkrainianArtillery.pdf">Android malware to infiltrate Ukranian field artillery units</a> (which seemed to be a response to skeptics of attributing the DNC hack to Russia).</p>
<p>So how was this epic, history-shaping attack conducted? The initial delivery vector was spear-phishing…if it ain’t broke, don’t fix it. To be fair, this was “sophisticated” as far as spear-phishing goes — using legitimate domains and then spoofing a Google suspicious account activity email (not something obvious like malware.delivery.plzclick.ru), which ultimately tricked recipients into entering in their passwords through a fake webmail domain that appeared to be a password reset page. Then, the credentials were used to harvest the emails, exfiltrate them through encrypted communications and create the #Podesta debacle.</p>
<h3 id="mirai-botnet-dyn-ddos">Mirai Botnet (Dyn DDoS)</h3>
<p>People panicked when Dyn, a DNS service provider, was getting DDoSed, breaking the internet even more than Kim Kardashian. Then, we found out that the nemesis was a botnet composed of <a href="http://www.theregister.co.uk/2016/10/21/dyn_dns_ddos_explained/">hundreds of thousands connected devices</a>, serving as a zombie army of “things” for their overlords. All Mirai did was log into devices by using the factory default passwords, which was successful enough to infect over 1 million devices.</p>
<p>The author of Mirai open sourced it, and given that the security of IoT devices hasn’t radically improved in the past few months, and consumers are generally allergic to security responsibility, <a href="https://www.wired.com/2016/12/botnet-broke-internet-isnt-going-away/">it’s easy to imagine massive IoT botnets happening again</a>.</p>
<h3 id="crypto-ransomware-boom">Crypto-ransomware boom</h3>
<p>Most recently, San Francisco’s Municipal Transportation Agency <a href="http://arstechnica.com/security/2016/11/san-francisco-muni-hit-by-black-friday-ransomware-attack/">was infected by ransomware (specifically HDDCryptor)</a>, with the attackers demanding $73k in exchange for restoring the data. However, SFMTA decided instead to let riders ride for free for a bit, and then fixed the problem by using a backup to restore their systems. The initial access was gained by a vulnerability involving Oracle’s WebLogic server and the Apache Commons library (a deserialization vulnerability), and SFMTA only became a target because the attackers used a web scanner to find vulnerable servers.</p>
<p><a href="https://www.wired.com/2016/02/hack-brief-hackers-are-holding-an-la-hospitals-computers-hostage/">Hollywood Presbyterian Medical Center in Los Angeles was also held hostage</a> through the ransomware “Locky,” but ended up paying only $17k in BTC vs. the initial demand of $3.4 million. Locky ended up infecting a few other hospitals, as well, and is particularly nasty because it looks for and erases Volume Shadow Copy files, which means automatic backups are erased.</p>
<h3 id="swift-wire-transfer-hax">SWIFT wire transfer hax</h3>
<p><a href="https://www.wired.com/2016/05/insane-81m-bangladesh-bank-heist-heres-know/">Hackers stole $81 million from accounts at Bangladesh’s central bank</a> within a few hours, and that wasn’t the only bank they attacked. They achieved this by getting bank employees’ credentials to SWIFT, the network between banks that processes most of the world’s wire transfers. There’s nothing concrete on how they got the credentials, but we do know they used malware to subvert SWIFT’s software for recording money transfers — which is far from ideal. It resulted in SWIFT to push for 2FA, which should help in the future.</p>
<h3 id="adult-friend-finder">Adult Friend Finder</h3>
<p>This breach received perfect 10 on the <a href="http://breachlevelindex.com/top-data-breaches">breach level index</a> — <a href="http://breachlevelindex.com/top-data-breaches">over 400 million records were exposed</a>. There isn’t much information on the breach yet, but it appears the passwords were kept in plaintext or used SHA1. The attackers allegedly exploited a <a href="http://www.csoonline.com/article/3132533/security/researcher-says-adult-friend-finder-vulnerable-to-file-inclusion-vulnerabilities.html">local file inclusion vulnerability</a>, meaning it’s yet another web app attack.</p>
<p>Honorable mention goes to two other hookup sites that were breached and stored their passwords in plaintext. Fling.com had credentials for <a href="http://www.ibtimes.co.uk/fling-com-breach-passwords-sexual-preferences-40-million-users-sale-dark-web-1558711">40 million of its users on sale for 0.8888BTC</a> in May (~$400 at the time). Mate1.com had <a href="https://motherboard.vice.com/read/hacker-claims-to-have-sold-27m-dating-site-passwords-mate1-com-hell-forum">over 27 million plaintext passwords for sale</a>, but for 20BTC in February (~$8,700 at the time). For Mate1, the hacker said that they compromised the server and dumped the MySQL database, with no further details.</p>
<h3 id="yahoo-data-breach">Yahoo data breach</h3>
<p><a href="http://www.nytimes.com/2016/12/14/technology/yahoo-hack.html?_r=0">It affected 1 billion user accounts</a>…which was surprising because most people never thought Yahoo had that many users. I won’t be counting this towards scoring the predictions, given the actual attack happened in 2013. But, there’s no denying it received substantial coverage, and will be an interesting case study going forward if it results in <a href="https://techcrunch.com/2016/10/06/report-verizon-wants-1-billion-discount-after-yahoo-privacy-concerns/">Verizon successfully reducing the purchase price of the acquisition</a>…or not acquiring them at all.</p>
<hr>
<p><img src="/blog/img/bad-cyberart-09.jpg" alt="A crystal ball"></p>
<h2 id="a-namecorrect-predictionsawhich-predictions-were-right-naming-names"><a name="correct-predictions"></a>Which predictions were right? (naming names)</h2>
<p>Spear phishing was mentioned 11 times total in all of the predictions — half of those were about mobile-specific spear phishing, and the rest mostly about the need to train employees on how to look out for it. Only McAfee and Sophos made any mention of hackers using “sophisticated” spear phishing more often, and even then it was a minor point in their larger reports. Election-themed phishing was predicted by Forcepoint, which I cover below, but no mention of spear phishing methods specifically. So, no one really wins on this one.</p>
<p>Kaspersky and Intel Security accurately predicted — although embedded rather than one of their primary predictions — that libraries used by servers (particularly open source libraries) would increasingly be targets, which was relevant in the SFMTA case. Otherwise, web app / server-side app attacks were virtually ignored — despite being a prevalent attack vector year after year. And exactly zero of the reports mentioned anything about SWIFT, or wire transfers more generally — the focus was primarily on credit card systems.</p>
<p>But other events fared better in their coverage:</p>
<h3 id="influence-operations--us-election-themed-attacks">Influence operations &amp; U.S. election-themed attacks</h3>
<p>First up, ForcePoint (Raytheon) hit the nail directly on the head with their prediction on U.S. election-related influence operations. While a few others brought up electronic voting systems, ForcePoint specifically called out the fake news phenomenon (albeit missing involvement by nation-state threat actors):</p>
<blockquote>
<pre><code>Information on social media is often spread and accepted before fact can catch up with fiction, giving determined hacktivists an opening to misrepresent and/or misdirect the public’s perception of individuals and events… 
</code></pre>
<p>…the other hand suggests there’s little to prevent incendiary, inaccurate information from virally spreading and being accepted by the public as factual. Even if such information is later corrected, this false information lives forever on the Internet, with the potential to inform opinions and as a result misinform — and potentially direct the actions of — the electorate.</p>
</blockquote>
<p>They also correctly predicted the use of election-themed phishing campaigns, and even that candidates would be targeted:</p>
<blockquote>
<p>However, given the influence the choice of a U.S. President can have…it’s not hard to envision a circumstance where factions hoping to gain insight or advantage in an election or following it, might target a candidate or groups involved in promoting them for useful data in keeping ahead of or undermining the competition</p>
</blockquote>
<p>So, congrats on them for being right, however unfortunate for the rest of us.</p>
<h3 id="iot-botnets">IoT Botnets</h3>
<p>The other big winner is Wired, who predicted the Mirai botnet, or what they called “the rise of the IoT Zombie Botnet.”</p>
<blockquote>
<p>One trend we’ve already spotted is the commandeering of IoT devices for botnets. Instead of hackers hijacking your laptop for their zombie army, they will commandeer large networks of IoT devices — like CCTV surveillance cameras, smart TVs, and home automation systems.</p>
</blockquote>
<p>Anomali also gets some credit for this, too, although it was a minor point in their larger prediction about IoT exploitation.</p>
<h3 id="ransomwareto-a-certain-extent">Ransomware…to a certain extent</h3>
<p>This was easily one the safest predictions to make last year, which is probably why nearly all the vendors mentioned it. Some took a more hyperbolic approach and overshot its impact and potential damage. Others head-scratching-ly said that ransomware will “go corporate,” although there had already been plenty of documented cases of corporate ransomware before 2016. But technically they weren’t wrong about it hurting businesses more, so I’ll allow it.</p>
<p>Many warned about potential extortion, in which the attackers would threaten to go public with data in the hopes of receiving a higher ransom, but for obvious reasons we probably wouldn’t hear about those cases publicly, so the jury’s still out. I’d argue this fear was overblown, given we saw three major hookup site breaches, credentials for which were being sold on dark web forums (when they could’ve been used for extortion).</p>
<p>Predictions that ransomware would become cross-platform were also technically accurate, as there are now documented cases of ransomware for <a href="http://www.computerworld.com/article/3113658/security/new-ransomware-threat-deletes-files-from-linux-web-servers.html">Linux</a> and <a href="http://www.theregister.co.uk/2016/03/09/first_macosx_ransomware_actually_linux_port/">Mac</a> — although not many documented families of ransomware for these platforms as of yet. I’d personally say Linux ransomware could be a possibility for 2017 — after all, it’s what constitutes modern infrastructure for most enterprises.</p>
<h3 id="attacks-hidden-in-ssl-vs-cleartext">Attacks hidden in SSL vs cleartext</h3>
<p>According to an <a href="https://www.a10networks.com/news/cybersecurity-report-organizations-victimized-by-malware-hidden-in-encrypted-traffic">A10 Networks / Ponemon study</a> from this summer 41% of attacks used malware hidden in SSL traffic to evade detection. Appliances have a difficult time quickly inspecting SSL traffic to detect malware, making it a new headache for enterprises. And turns out A10 Networks was the only one to predict this trend.</p>
<hr>
<p><img src="/blog/img/bad-cyberart-10.png" alt="A digital thumbs down"></p>
<h2 id="a-namewrong-predictionsawhich-predictions-were-off-not-naming-names"><a name="wrong-predictions"></a>Which predictions were off? (not naming names)</h2>
<h3 id="iot-in-theory-but-not-reality">IoT in theory, but not reality</h3>
<blockquote>
<p>We won’t see widespread examples of attackers getting IoT devices to run arbitrary code any time soon.</p>
</blockquote>
<p>Welp…see the aforementioned Mirai botnet.</p>
<h3 id="pki-ubiquity">PKI ubiquity</h3>
<blockquote>
<p>In 2016, we expect that PKI will become ubiquitous security technology within the IoT market.</p>
</blockquote>
<p>A safe prediction for 2017 is that PKI will continue to be a mess, and so will IoT security.</p>
<h3 id="drone-hackpocalypse">Drone hackpocalypse</h3>
<blockquote>
<p>However, drones also present a wide range of risks, from privacy invasion to corporate espionage to terrorism.</p>
</blockquote>
<p>Sure, but realistically it’s confined to nation-state level for now, so it’s dubious if it belongs in a predictions report aimed at corporate CISOs. Some <a href="https://www.wired.com/2016/03/hacker-says-can-hijack-35k-police-drone-mile-away/">research</a> <a href="https://hub.jhu.edu/2016/06/08/hacking-drones-security-flaws/">was</a> <a href="http://arstechnica.com/security/2016/10/drone-hijacker-gives-hackers-complete-control-of-aircraft-in-midflight/">published</a> on how to hack drones, but there’s nothing confirmed in-the-wild. Amazon also just <a href="http://qz.com/873920/amazon-has-a-plan-to-defend-drones-from-hackers-and-bow-and-arrow-wielding-troublemakers/">published a patent</a> for protecting its delivery drones against hacking…and against bows and arrows. My guess is this prediction is supposed to fall under the <a href="http://qz.com/873920/amazon-has-a-plan-to-defend-drones-from-hackers-and-bow-and-arrow-wielding-troublemakers/">Rule of Cool</a> rather than having a logical basis for impact to enterprises.</p>
<h3 id="terrorists-pick-up-the-cyberbomb">Terrorists pick up the (cyber)bomb</h3>
<blockquote>
<p>In 2016, we will increasingly see the convergence of physical and cyber terrorism aimed at wreaking far-reaching havoc.</p>
</blockquote>
<p>Terrorists did not become cyber ninjas blowing up power plants all over the place. The Grugq has <a href="https://medium.com/@thegrugq/isis-cyber-security-skills-suck-cc3466aa73f7#.jhezy91mj">already written</a> <a href="https://medium.com/@thegrugq/just-the-facts-isis-encryption-c70f258c0f7#.e1ovjsbl8">about this</a>. <a href="http://cybersquirrel1.com/">Squirrels are still the better conductors of cyber war ops</a> against our critical infrastructure.</p>
<h3 id="post-quantum-crypto">Post-quantum crypto</h3>
<blockquote>
<p>“The cryptopocalypse is nigh.” (due to quantum computing)</p>
</blockquote>
<p>Nope. Probably a prediction that can be safely shelved for a few years.</p>
<h3 id="cyber-insurance-changes-everything">Cyber. insurance. changes. everything.</h3>
<blockquote>
<p>The cyber insurance market will dramatically disrupt businesses in the next 12 months.
In 2016 many companies will turn to cyber insurance as another layer of protection, particularly as cyber attacks start mirroring physical world attacks.</p>
</blockquote>
<p>Looks like most companies still think insurance is <a href="https://www.sans.org/reading-room/whitepapers/analyst/bridging-insurance-infosec-gap-2016-cyber-insurance-survey-37062">inadequate risk mitigation</a>. According to the <a href="https://www.sans.org/reading-room/whitepapers/analyst/bridging-insurance-infosec-gap-2016-cyber-insurance-survey-37062">SANS survey</a>, only 33.5% of companies have cyber insurance. What’s more, <a href="http://www.partnerre.com/assets/uploads/docs/PartnerRe_Cyber_Liability_Trends_Survey_2016.pdf">83% of respondents to a PartnerRe survey</a> said that cyber insurance policies are only “sometimes” meeting the needs of insured companies. So, while it may be blossoming as a new “check the box” item, it’s nowhere near disrupting enterprise security strategies yet.</p>
<h3 id="mobile-app-exploitation">Mobile app exploitation</h3>
<blockquote>
<p>With the growing amount of malware and the vulnerabilities present in legitimate mobile apps, a major breach is bound to happen, potentially on a massive scale.</p>
</blockquote>
<p>While many of the predictions highlighted mobile as an attack vector in general, where they specifically got it wrong is in thinking that vulnerabilities in mobile apps would be exploited. Why expend the effort when malicious apps still work just fine? See: <a href="https://www.crowdstrike.com/blog/danger-close-fancy-bear-tracking-ukrainian-field-artillery-units/">the poisoned app Fancy Bear used to hack Ukranian field artillery units</a>. There haven’t been any major corporate breaches directly tied to mobile malware, though I’ll concede it’s possible they just aren’t public. Mobile malware grew at a very healthy pace in 2016, however:</p>
<p><img src="/blog/img/new-mobile-malware-2016.png" alt="Chart of new mobile malware by McAfee Labs"></p>
<h3 id="wearables-as-the-new-sexy-attack-vector">Wearables as the new sexy attack vector</h3>
<blockquote>
<p>Initially, we doubt that a smartphone will be completely compromised by an attack through a wearables device, but we expect to see the control apps for wearables compromised in the next 12 to 18 months in a way that will provide valuable data for spear-phishing attacks.</p>
</blockquote>
<p>There’s been research on hacking them, but as far as I can find, no evidence that hacking wearables has ever been used as part of a corporate data breach. The only headlines in 2016 are variations of “Hackers targeting your wearables data?” or “Can Wearable Technology Threaten the Security of Your Biz?” so I’ll invoke <a href="https://en.wikipedia.org/wiki/Betteridge%27s_law_of_headlines">Betteridge’s law of headlines</a> and say the answer is no.</p>
<h3 id="remote-controlled-cars">Remote-controlled cars</h3>
<blockquote>
<p>Attacks on automobile systems will increase rapidly in 2016 due to the rapid increase in connected automobile hardware built without foundational security principles.</p>
</blockquote>
<p>This didn’t happen. <a href="https://www.wired.com/2016/08/jeep-hackers-return-high-speed-steering-acceleration-hacks/">Seriously cool research</a>, but no reports in the wild — just because something can be hacked doesn’t mean it’s easily hacked.</p>
<div class="center">
	<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Why is it that every headline is &#39;product X easily hacked&#39;. Hacking a car was hard. Hacking is hard. It is good that it is hard.</p>&mdash; Chris Valasek (@nudehaberdasher) <a href="https://twitter.com/nudehaberdasher/status/805419828756496384?ref_src=twsrc%5Etfw">December 4, 2016</a></blockquote>
	<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
<h3 id="password-reuse-attacks-will-decline">Password reuse attacks will decline</h3>
<blockquote>
<p>Password reuse attacks will begin to decline… people are starting to adopt password managers… Advancements in biometrics are also helping the cause…most major Internet layers are also adding two-factor authentication as a standard option</p>
</blockquote>
<p>All of those things might be true, but not enough to make a dent. These are entities publicly victims to password reuse attacks in this year alone: <a href="https://www.carbonite.com/en/cloud-backup/business/resources/carbonite-blog/carbonite-password-attack/">Carbonite</a>, <a href="https://threatpost.com/gotomypc-suffers-major-password-reuse-attack/118781/">Citrix GoToMyPC</a>, <a href="http://www.bbc.com/news/technology-38070985">Deliveroo</a>, <a href="https://techcrunch.com/2016/06/16/github-accounts-targeted-in-password-reuse-attack/">GitHub</a>, <a href="http://www.batblue.com/groupon-users-hit-password-reuse-attack/">Groupon</a>, <a href="http://www.vanityfair.com/news/2016/06/mark-zuckerberg-terrible-password-revealed-in-hack">Mark Zuckerberg</a>, <a href="http://arstechnica.com/security/2016/06/teamviewer-users-are-being-hacked-in-bulk-and-we-still-dont-know-how/">TeamViewer</a>, <a href="https://www.itgovernance.co.uk/blog/uk-national-lottery-password-reuse-attacks-what-are-the-chances/">U.K. National Lottery</a>. Further, Patrick Heim, Dropbox’s Head of Trust &amp; Security said in September that <a href="http://www.cso.com.au/article/606531/99-compromised-user-accounts-come-from-password-reuse-cso-heavy-hitters-reveal/">“99% of compromised user accounts come from password reuse.”</a> Seems more like wishful thinking / “it’s-2016-how-is-this-still-happening?!” than a prediction.</p>
<hr>
<h2 id="conclusion">Conclusion</h2>
<p>I’ve already started reading some of the 2017 predictions — being diplomatic, I’ll say I’m looking forward to seeing how the next year unfolds. I saw one list described as not containing any “wows,” which I think accurately pinpoints the problem with these lists in general.</p>
<p>It’s more an exercise in taking a provocative stance to raise attention and be able to tell customers how your product addresses this important upcoming issue, rather than a probability-weighted list of the actual threats enterprises will face in the upcoming year — users will keep clicking on things they shouldn’t, injection vulnerabilities are still in all the things, and not enough people use 2FA or encrypt their users’ credentials.</p>
<p>In conclusion, my ultimate 2017 prediction is that I’ll have plenty of content for an equivalent of this post next year.</p>
]]></content>
        </item>
        
        <item>
            <title>My 2016 Reading List</title>
            <link>https://swagitda.com/blog/posts/2016-reading-list/</link>
            <pubDate>Mon, 26 Dec 2016 21:03:57 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/2016-reading-list/</guid>
            <description>Two years ago, I made my New Years Resolution to read one fiction and one non-fiction book each month, and I’ve (mostly) kept it up since then. But towards the end of 2015, it suddenly occurred to me that the vast majority of the authors I read were men. So, I made my 2016 resolution to flip that ratio, while still sticking to the genres to which I gravitate, namely science fiction and popular science (with a bit of history thrown in).</description>
            <content type="html"><![CDATA[<p>Two years ago, I made my New Years Resolution to read one fiction and one non-fiction book each month, and I’ve (mostly) kept it up since then. But towards the end of 2015, it suddenly occurred to me that the vast majority of the authors I read were men. So, I made my 2016 resolution to flip that ratio, while still sticking to the genres to which I gravitate, namely science fiction and popular science (with a bit of history thrown in).</p>
<p>Before I get to the list, I feel like these posts typically have a “what I learned from it” component. The only real difference I found was that there were far more female characters involved or female scientists highlighted — and for their research, not their sex.</p>
<p>I certainly didn’t lack for subject variety — I read about gravitational waves, extinction theory, Antarctica, parasites, machine learning and the women who were the first “computers” on the pop-sci side, to the absolutely-bonkers 14th century in Europe, the Great Migration, and the U.S. criminal justice system on the non-science history side. All the sci-fi novels I read were entertaining, thought-provoking, and full of rich world-building like any other good sci-fi — just with greater representation of women in the action.</p>
<p>I realize some people might think this is a useless exercise, or “reverse sexism.” I’d say it’s more in the model of Ruth Bader Ginsburg’s response to “When will there be enough women on the Supreme Court?” — when all nine justices are women. I went a year reading books that were ~90% by men (realistically, many more years than that), without it even registering. The goal should be to get to the point where it isn’t considered weird or “SJW” to read books 90% by women, as well.</p>
<p>The key point to me is visibility — the reality is that women, in many fields, struggle to gain visibility for their accomplishments. I’d assume for genres like popular science or science fiction that it’s similar to Hollywood, in that backing work by women is seen as a “gamble.” I’m aware that my individual Kindle purchase doesn’t amount to much, but if more people adopt a similar strategy and recommend these books to their avid-reader friends, then it starts to amount to something of significance.</p>
<p>Going forward, I’ll aim for closer to a 50/50 ratio and diversify my picks along other lines, such as ethnicity, religion, and gender identity. As anyone who reads a lot can likely attest, it’s always such a challenge to narrow down your next book selection from the thousands of options available. So to all who might potentially hate on this strategy, just view my method as a particularly socially-conscious selection engine.</p>
<p>Without further ado, here’s my reading list from this past year, including links to each book’s Amazon page so you can learn more — I make no illusions about being a masterful book reviewer, but just assume all of these books get a hearty thumbs up from me.</p>
<h2 id="non-fiction">Non-Fiction</h2>
<p><a href="https://www.amazon.com/gp/product/B004R1Q296">A Distant Mirror: The Calamitous 14th Century</a> by Barbara W. Tuchman</p>
<p><a href="https://www.amazon.com/gp/product/B006R8PHW0">Antarctica: An Intimate Portrait of a Mysterious Continent</a> by Gabrielle Walker</p>
<p><a href="https://www.amazon.com/gp/product/B017QLQLQW">Black Hole Blues and Other Songs from Outer Space</a> by Janna Levin</p>
<p><a href="https://www.amazon.com/gp/product/B00T3CU1ZK/">Dark Matter and the Dinosaurs: The Astounding Interconnectedness of the Universe</a> by Lisa Randall</p>
<p><a href="https://www.amazon.com/gp/product/B0067NCQVU">The New Jim Crow</a> by Michelle Alexander</p>
<p><a href="https://www.amazon.com/gp/product/B013CATQPY">Rise of the Rocket Girls: The Women Who Propelled Us, from Missiles to the Moon to Mars</a> by Nathalia Holt</p>
<p><a href="https://www.amazon.com/gp/product/B00EGJE4G2">The Sixth Extinction: An Unnatural History</a> by Elizabeth Kolbert</p>
<p><a href="https://www.amazon.com/gp/product/B011H55MY0">This Is Your Brain on Parasites: How Tiny Creatures Manipulate Our Behavior and Shape Society</a> by Kathleen McAuliffe</p>
<p><a href="https://www.amazon.com/gp/product/B003EY7JGM">The Warmth of Other Suns: The Epic Story of America’s Great Migration</a> by Isabelle Wilkerson</p>
<p><a href="https://www.amazon.com/gp/product/B019B6VCL">Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy</a> by Cathy O’Neil</p>
<h2 id="fiction">Fiction</h2>
<p><a href="https://www.amazon.com/gp/product/B00BAXFDLM">Ancillary Justice (Imperial Radch Book 1)</a> by Ann Leckie</p>
<p><a href="https://www.amazon.com/gp/product/B008HALO0U">Bloodchild: And Other Stories</a> by Octavia E. Butler</p>
<p><a href="https://www.amazon.com/gp/product/B005CRQ3MA/">Gravity’s Rainbow</a> by Thomas Pynchon (the token male author ;)</p>
<p><a href="https://www.amazon.com/gp/product/B003JFJHTS">The Handmaid’s Tale</a> by Margaret Atwood</p>
<p><a href="https://www.amazon.com/gp/product/B003JFJHTS">The Left Hand of Darkness</a> by Ursula Le Guin</p>
<p><a href="https://www.amazon.com/gp/product/B009LL3YRU">Ink</a> by Sabrina Vourvoulias</p>
<p><a href="https://www.amazon.com/gp/product/B00GU38B4S">Synners</a> by Pat Cadigan</p>
<p><a href="https://www.amazon.com/gp/product/B006VXFGJU">The Waves</a> by Virginia Woolf</p>
]]></content>
        </item>
        
        <item>
            <title>3 questions on cybersecurity that should be asked in the debates</title>
            <link>https://swagitda.com/blog/posts/3-questions-cybersecurity-debates/</link>
            <pubDate>Fri, 30 Sep 2016 20:41:38 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/3-questions-cybersecurity-debates/</guid>
            <description>A citizen’s guide (or to sound smart at cocktail parties) While the first U.S. presidential debate included an open-ended, broad question about each candidate’s stance on cybersecurity, it accomplished little in helping citizens understand the candidates’ actual policy positions — nor why cybersecurity policies are relevant at all on the national scale. Saying “cybersecurity is important” for the U.S. today is like saying “having a military is important.”
But, it was also clear from the responses, such as bringing up Daesh’s use of the internet for recruitment or using the term “the cyber,” that there’s a lack of mainstream understanding of what cybersecurity actually means in a policy context (the argument against the term “cyber” and its derivatives is left for another day).</description>
            <content type="html"><![CDATA[<p><em>A citizen’s guide (or to sound smart at cocktail parties)</em>
<img src="/blog/img/code-murica-flag.jpg" alt="Murica flag, cyber edition"></p>
<p>While the first U.S. presidential debate included an open-ended, broad question about each candidate’s stance on cybersecurity, it accomplished little in helping citizens understand the candidates’ actual policy positions — nor why cybersecurity policies are relevant at all on the national scale. Saying “cybersecurity is important” for the U.S. today is like saying “having a military is important.”</p>
<p>But, it was also clear from the responses, such as bringing up Daesh’s use of the internet for recruitment or using the term “the cyber,” that there’s a lack of mainstream understanding of what cybersecurity actually means in a policy context (the argument against the term “cyber” and its derivatives is left for another day).</p>
<p>Here’s my best attempt at a definition as far as most citizens are concerned: cybersecurity at the national level includes 1) methods and resources to conduct geopolitical, intelligence-gathering, or offensive operations, and 2) methods and resources to defend against digital attacks that might threaten national security, individual liberties, or our economic viability.</p>
<p>Simply put, cybersecurity is the newest domain both for warfare and way of life, and thus has policy implications at a national scale. It would be a grave mistake to underestimate the importance of cybersecurity in geopolitical strategy and how much our “life, liberty and the pursuit of happiness” depends on it today.</p>
<p>So, without further ado, here are the three questions I think are worthy of being asked at the next two debates, as well as why you, as a citizen, should care about their answers. If you think a question is worth asking, vote for it by clicking the relevant link below. (Author note: after the conclusion of the debates, the question site was disabled &ndash; these now link to the relevant sections in the post).</p>
<ol>
<li><a href="#crypto-backdoors">Do you support federally mandated encryption backdoors?</a></li>
<li><a href="#critical-infra">How would you improve protection of critical infrastructure from cyber attacks?</a></li>
<li><a href="#deterrence-offense">What balance would you strike between cyber deterrence and offensive cyber operations on other nations?</a></li>
</ol>
<hr>
<p><img src="blog/img/bad-cyberart-05.jpg" alt="Code dripping over the White House"></p>
<h2 id="a-namecrypto-backdoorsado-you-support-federally-mandated-encryption-back-doors"><a name="crypto-backdoors"></a>Do you support federally mandated encryption back doors?</h2>
<h3 id="what-wed-learn">What we’d learn</h3>
<p>The way the candidates answer this question primarily will show to what degree they are aligned to constitutional rights plus the needs and desires of citizens vs. what “the powers that be” (primarily the FBI) say is necessary. Secondarily, it will show how open they are to listening to expert opinions in a particular area, as the overwhelming majority of cybersecurity professionals are vehemently and publicly against encryption backdoors.</p>
<h3 id="the-context">The context</h3>
<p>There have been multiple encryption debates throughout the years, but the most recent focuses on encryption backdoors. Let’s start with a basic definition of encryption: it’s a “process of ciphering information in such a way that only authorized parties can read it.” It’s not hyperbole to say encryption is part of everything you use online — from online banking, online shopping, email, electronic medical records to Facebook chat. It is a fundamental part of what makes the internet economy as we know work by adding in a layer of trust.</p>
<p>Now, what’s a backdoor? A backdoor is an intentionally-placed method of bypassing a security mechanism in software, and is most often used to gain unauthorized access to something. In the context of encryption backdoors, it is specifically to obtain the “plaintext” or raw data. For example, encrypted data might look like “IUFdjxi/FI8+2zv/WbEUq=M+b…” while the plaintext says “I like pizza.”</p>
<p>By way of analogy, an encryption backdoor is similar to designing a physical lock with a master key that can always open the lock if needed. It’d be naive to assume that only the designated owner of the master key (for example, the government) could unlock the lock. Someone else could examine the way the lock is designed, deduce how the master key looks, and create one on their own.</p>
<p>The implications for an encryption backdoor are even worse than that analogy — at least in the physical lock case, there’s a slight barrier in that physical proximity is still needed to use the master key. In the digital case, a hacker doesn’t even have to move in order to use the master key across a bunch of different digital “locks” in any location in the world.</p>
<p>The FBI has been the most notable proponent of encryption backdoors, as highlighted in their <a href="/blog/posts/apple-vs-fbi-privacy-inequality/">battle with Apple earlier this year</a>. Further, in 2007, a <a href="http://www.nytimes.com/2013/09/06/us/nsa-foils-much-internet-encryption.html">backdoor was discovered in the encryption algorithm supported by the NSA</a>, which would have meant that companies who adopted the NSA’s recommend encryption algorithm would have developed software susceptible to attack or data interception. The argument in favor of encryption backdoors generally rests on the use of encryption by criminals or other bad actors, and the worry that encryption allows them to “go dark” (i.e. make it harder for someone to intercept or access their data).</p>
<p>However, the overwhelming majority of cybersecurity experts are against backdoors, primarily because there’s absolutely no way to ensure that these “trap doors” aren’t discovered by hackers, criminals or combative nation-states and used against American citizens, corporations, banks, utilities, troops or the government itself. It cannot be stressed enough that the <a href="http://docs.house.gov/meetings/IF/IF02/20160419/104812/HHRG-114-IF02-Wstate-BlazeM-20160419-U3.pdf">“harsh technical realities make a [lawful access only] solution effectively impossible.”</a></p>
<p>Requiring encryption backdoors also would place a huge financial and resource burden on private enterprises by requiring software developers to design systems in a way that allows law enforcement to gain access as needed — or desired. Further, no matter how you decide who is granted access to the “master key” for these backdoors, they immediately become an attractive and lucrative target for cyberattack — potentially pouring many millions of dollars of extra risk onto the shoulders of private enterprises.</p>
<h3 id="why-you-should-care">Why you should care</h3>
<p>If you’d include yourself among people who care about the following, <em>you should be strongly against requiring — or the even existence of — encryption backdoors:</em></p>
<ul>
<li>The First Amendment, free speech and freedom of the press</li>
<li>The Second Amendment (encryption software has historically been classified as a munition — a military weapon — by the government, which means that citizens arguably have the right to use encryption to defend their personal data, without it being rendered ineffective due to a backdoor)</li>
<li>The Fourth Amendment (keeping data safe in event of an “unreasonable search and seizure”)</li>
<li>Criminal justice reform</li>
<li>Eliminating discrimination</li>
<li>Stopping people from stealing your personal data or assets</li>
<li>Stopping people from stealing corporate data or assets</li>
<li>Protecting critical infrastructure</li>
<li>Protecting hospital systems and medical devices</li>
<li>Keeping our troops safe</li>
<li>and many other things, but I have a tendency to ramble as-is</li>
</ul>
<p>As you can recognize from the list, this isn’t a partisan issue.</p>
<p>Many people use the “I have nothing to hide” argument when first hearing about the encryption debate. That also happens to be irrelevant — given the prevalence of digital communications in our modern lives, encryption is essential in preserving our constitutional rights.</p>
<p>But it’s also way beyond that. As I mentioned above, encryption is used in nearly everything you do online these days, and not just your communications. Purposefully backdooring encryption leaves an open hole for hackers to get your healthcare data, personal pictures of your kids, drain your bank account, run up your credit card, or steal your identity. <strong>The vibrant, useful, trillion-dollar internet economy as we know it would not and could not exist without encryption.</strong></p>
<p>As Matt Blaze, a leading expert on encryption, said in <a href="http://docs.house.gov/meetings/IF/IF02/20160419/104812/HHRG-114-IF02-Wstate-BlazeM-20160419-U3.pdf">his recent testimony before Congress</a>:</p>
<blockquote>
<p>This is not simply a matter of weighing the desires for personal privacy and for safeguards against government abuse against the need for improved law enforcement… [Backdoors] will provide rich, attractive targets not only for relatively petty criminals such as identity thieves, but also for organized crime, terrorists, and hostile intelligence services. It is not an exaggeration to understand these risks as a significant threat to our economy and to national security.</p>
</blockquote>
<hr>
<p><img src="blog/img/bad-cyberart-06.jpg" alt="Power lines, but with code on them for some reason"></p>
<h2 id="a-namecritical-infraahow-would-you-improve-protection-of-critical-infrastructure-from-cyber-attacks"><a name="critical-infra"></a>How would you improve protection of critical infrastructure from cyber attacks?</h2>
<p><em>With the follow-up: “Would you include election and electronic voting systems under the definition of critical infrastructure?”</em></p>
<h3 id="what-wed-learn-1">What we&rsquo;d learn</h3>
<p>Each candidate would outline their plans for for the federal government’s role in protecting critical infrastructure. Additionally, we’d hear each candidate’s proposals for addressing and solving some of the key challenges in protecting critical infrastructure in order to judge how much they recognize the threat and how effective they’d be in preserving our national security, economy and way of life.</p>
<h3 id="the-context-1">The context</h3>
<p>Critical infrastructure, as per the Patriot Act, is defined as:</p>
<blockquote>
<p>systems and assets, whether physical or virtual, so vital to the U.S. that the incapacity or destruction of such systems or assets would have a debilitating impact on security, national economic security, national public health or safety, or any combination of those matters</p>
</blockquote>
<p>The NIST Cybersecurity Framework suggests a host of industries fall under this label, including agriculture, water, public health, emergency services, government, defense, information &amp; telecommunications, energy, transportation &amp; shipping, banking &amp; finance, chemicals &amp; hazardous materials, post, national monuments &amp; icons and critical manufacturing.</p>
<p>Many would argue that the list should also include election and electronic voting systems, as they are a vital component of maintaining democratic elections (and I personally would agree). Particularly in light of the recent revelations that Russian actors <a href="https://www.wired.com/2016/07/heres-know-russia-dnc-hack/">hacked the DNC</a> as well as the <a href="https://www.washingtonpost.com/world/national-security/fbi-is-investigating-foreign-hacks-of-state-election-systems/2016/08/29/6e758ff4-6e00-11e6-8365-b19e428a975e_story.html">Illinois and Arizona election systems</a> (and <a href="http://abcnews.go.com/US/russian-hackers-targeted-half-states-voter-registration-systems/story?id=42435822&amp;cid=abcn_tco">attempted to hack many more</a>), the plea by information security experts to have the security of voting systems be taken more seriously is steadily gaining legitimacy.</p>
<p>The reason why federal-level protection of critical infrastructure from cyber attacks is up for debate is that, currently, the onus is primarily on the private sector to defend itself. However, the same isn’t true for physical threats such as potential terrorist attacks — should the owner of the World Trade Center have conducted their own anti-terrorism operations and had fighter jets ready to escort a hijacked plane? Of course not.</p>
<p>If the federal government is in charge of protecting national security, then it’s logical to suggest that they should also take the lead on <strong>all</strong> national security, including securing national infrastructure. However, given the complexities of our physical and virtual infrastructure, and consequently the large number of industries that fall under the critical infrastructure label, there is disagreement over the extent to which the federal government should help bolster their cybersecurity. We, as citizens, should hear what the candidates respective positions are on this important issue.</p>
<p>Additionally, the <em>how</em> to do it is potentially more subjective and could include anything from recommending minimal security standards (which is the default, albeit ineffective, strategy) to imposing fines on software vendors for vulnerabilities or conducting cyber deterrence (which I dig into more in the last question). I, for one, would like to know the candidates ideas on the “how to” as well.</p>
<h3 id="why-you-should-care-1">Why you should care</h3>
<p>If you care about our national security, you should care about this question. It’s safe to say it’s a bipartisan desire for the local power plant not to blow up, to avoid a food crisis or not have our financial system come to a standstill.</p>
<p>The reason why you should care about each candidate’s specific answer to the question is because the level of cybersecurity in critical infrastructure is, in general, alarmingly poor, increasing the likelihood and severity of devastation of a cyber attack on critical infrastructure at any time. While I don’t condone <a href="https://en.wikipedia.org/wiki/Fear,_uncertainty_and_doubt">FUD</a> (fear, uncertainty and doubt as a media strategy), I will say that it’s far better to act now to reduce the probability of a calamitous digital attack on our critical infrastructure than keep our fingers crossed that it won’t happen.</p>
<p>There are a few cybersecurity challenges faced by these industries, though. First, there’s a massive shortage of talent, and those who are practitioners generally go to industries who can pay the most (like tech and financial services). Perhaps workers in declining industries could be given incentives to retrain with cybersecurity skills. Second, critical infrastructure systems usually are complex and a lot of infrastructure software is old, and it’s difficult to install or integrate security measures after the fact.</p>
<p>Third, a single private entity won’t have the same level of information about potential digital threats as the federal government, nor the resources to prevent against every possible scenario. By leveraging the U.S. intelligence community’s data, private entities in critical industries could be given a “heads up” on potential threats and guidance on the tactics, techniques and procedures of groups likely to target them in a cyberattack.</p>
<hr>
<p><img src="blog/img/bad-cyberart-07.jpg" alt="AFB Central Control facility"></p>
<h2 id="a-namedeterrence-offenseawhat-balance-would-you-strike-between-cyber-deterrence-and-offensive-cyber-operations-on-other-nations"><a name="deterrence-offense"></a>What balance would you strike between cyber deterrence and offensive cyber operations on other nations?</h2>
<p><em>With the follow-up: “What role do you think cyber deterrence plays in cyberwarfare?”</em></p>
<h3 id="what-wed-learn-2">What we&rsquo;d learn</h3>
<p>The candidates’ answers to this question should reveal:</p>
<ol>
<li>How they’d invest in and preserve our advantage in the “cyberwar” arena — from technology to human capital</li>
<li>How they’d use offensive cyber operations — would it be covert geopolitical influencing or upfront display of capability? Would we be the first-movers on offense or focused on attacking back?</li>
</ol>
<h3 id="the-context-2">The context</h3>
<p>The domains of warfare were traditionally Land, Sea, Air and Space, but Information Operations (i.e. the digital domain) became the fifth dimension for the U.S. Military in 1995. Since then, information operations, or “cyberwarfare” as dubbed by the media, has become a crucial component of military strategy due to the proliferation of digital systems globally and their importance in all areas of modern life.</p>
<p>The two main types of cyberwarfare are espionage and sabotage. Espionage is used for spying purposes to gain intelligence; for example, the <a href="http://arstechnica.com/security/2015/06/epic-fail-how-opm-hackers-tapped-the-mother-lode-of-espionage-data/">hack of the Office of Personnel Management</a> (presumably by China) was to gain intelligence on people who work for various U.S. government agencies. Sabotage is used to disrupt adversaries’ systems for geopolitical or military gain. For example, rather than conducting some sort of strike on Iran’s nuclear facilities, the U.S. leveraged its offensive cybersecurity capabilities to covertly disrupt Iran’s nuclear program in an attack later dubbed <a href="https://en.wikipedia.org/wiki/Stuxnet">“Stuxnet.”</a></p>
<p>Cyberwarfare is particularly reliant on intelligence (part of why the NSA has expanded so much over the past two decades), and thus most operations tend to fly under the radar. It would reduce a government’s advantage to reveal capabilities or methods, since then adversaries could better thwart attacks or repackage the attack for their own use.</p>
<p>This highlights the difficulty of cyber deterrence. Being able to attribute cyber attacks to a specific nation-state requires revealing, in part, how you were able to figure out who did it. If you don’t present evidence, it can be dismissed as a baseless accusation, which isn’t great for geopolitical maneuvering. Even then, <a href="https://medium.com/@thegrugq/idle-thoughts-on-cyber-82170b2b7280#.k2d7gfrsr">attribution is notoriously difficult</a> since attackers can attempt to mask their digital tracks, including by making it appear that their attack originated from a different location or by using a different language than their own.</p>
<p>In any case, to dissuade adversaries from attacking us, the U.S. has to make it clear that the intelligence community will figure out who is behind any attacks against us, retaliate swiftly and inflict significant damage…all without revealing the extent of our capabilities.</p>
<h3 id="why-you-should-care-2">Why you should care</h3>
<p>It is evident that the U.S. currently has a decisive advantage in the nation-state cybersecurity arena — anyone suggesting otherwise, as seen in this election, is misinformed. We began preparing for, and conducting, offensive cyber operations about a decade before others, giving us a significant head start.</p>
<p>Further, the dominance we have over global digital infrastructure is extremely difficult to replicate and that fact makes our cyber operations smoother to conduct. For example, <a href="http://www.theatlantic.com/international/archive/2013/07/the-creepy-long-standing-practice-of-undersea-cable-tapping/277855/">as revealed by the Snowden leaks</a>, the U.S. taps into undersea fiber optic cables that serve as the fundamental communication rails of the internet — giving access to any data that is transmitted over these cables.</p>
<p>To be clear, Russia, China and Iran all have highly intelligent and capable cybersecurity teams (to varying degrees of size and sophistication). But we can conduct offensive cybersecurity operations on a bigger scale. We not only can perform equally as sophisticated attacks, but we also possess a formidable information advantage to better craft attacks and anticipate attacks against us.</p>
<p>This doesn’t mean we’ll never be attacked, due to the aforementioned abilities of our adversaries — though the cyber deterrence strategy is meant to dissuade others from attacking us by showing our muscle. While we currently have superior offensive cybersecurity capabilities that give us a geopolitical advantage, this does not make us invulnerable to the potentially devastating effects of cyberattack against us by a capable nation-state.</p>
<p>On the other hand, an offensive operation presents the risk of being caught, which might be viewed as a declaration of war — thus leading to retaliation against us (which isn’t ideal). So, we have to be judicious in how we leverage our offensive cybersecurity capabilities to balance optimizing our foreign policy goals while protecting our own national security.</p>
<hr>
<p><img src="blog/img/bad-cyberart-08.jpg" alt="Map of the USA but with code on it"></p>
<h2 id="conclusion">Conclusion</h2>
<p>Do I think these questions will be asked at the debates? No (but fingers crossed). I don’t think there’s a sufficient public understanding of the multifarious policy issues presented by cybersecurity — largely because the media coverage of cybersecurity is notoriously terrible.</p>
<p>However, raising voter awareness of these issues still is critically important. Real change won’t happen if it’s just the information security or privacy community who is concerned…and it really shouldn’t just be them, since cybersecurity issues affect all citizens.</p>
<p>Cybersecurity’s importance in our nation’s ecosystem only will grow, so starting the discussion of these issues now means there’ll be a deeper consciousness of them among voters in the next election — and a greater ability of “the people” to ensure their rights and security are preserved as we march past the point of no return into digital dependence.</p>
]]></content>
        </item>
        
        <item>
            <title>Behavioral Models of InfoSec: Prospect Theory</title>
            <link>https://swagitda.com/blog/posts/behavioral-models-infosec-prospect-theory/</link>
            <pubDate>Mon, 01 Aug 2016 20:20:59 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/behavioral-models-infosec-prospect-theory/</guid>
            <description>To those in the information security / cyber security industry, it’s an accepted truth that there exists a pernicious incentive structure that overwhelmingly puts the odds in the attacker’s favor. The consistent narrative is that defenders make irrational decisions and focus on the wrong problems while vendors peddle FUD and snake oil that not just fails to bolster the defensive cause, but inflicts ongoing harm.
But, I’ve seen less in the way of seeking to understand defenders’ irrational decision making patterns and why the industry is the way it currently is…and even less about how to fix this toxic feedback loop.</description>
            <content type="html"><![CDATA[<p>To those in the information security / cyber security industry, it’s an accepted truth that there exists a pernicious incentive structure that overwhelmingly puts the odds in the attacker’s favor. The consistent narrative is that defenders make irrational decisions and focus on the wrong problems while vendors peddle FUD and snake oil that not just fails to bolster the defensive cause, but inflicts ongoing harm.</p>
<p>But, I’ve seen less in the way of seeking to understand defenders’ irrational decision making patterns and why the industry is the way it currently is…and even less about how to fix this toxic feedback loop. So, armed with my modest background in behavioral economics from undergrad, I’ve decided to take a stab at examining the “why” and proposing some ways to twist these incentives in the defense’s favor.</p>
<p>My hope is that this kicks off a series where I examine different theories within behavioral economics against evidence within infosec. The tl;dr background on behavioral econ is that traditional economics views people as rational decision-making machines (i.e. “Homo economicus”) that can perfectly perform cost benefit analyses and choose an objectively optimal outcome.</p>
<p>Behavioral econ, in contrast, recognizes that our brains are wired in a way that has been optimal for evolution, so it measures how people actually behave vs. how they optimally behave. We have quirks in our thinking that result in us making “irrational” decisions, but for understandable reasons.</p>
<p>This post will cover the O.G. theory in behavioral econ, Prospect Theory, as the first of many (potential) theories to help explain some of the dynamics of the infosec market.</p>
<h3 id="table-of-contents">Table of Contents:</h3>
<ol>
<li><a href="#what-is-prospect-theory">What is Prospect Theory?</a></li>
<li><a href="#defense-vs-offense">Defense vs. Offense</a></li>
<li><a href="#infosec-ref-points">InfoSec Reference Points</a></li>
<li><a href="#infosec-examples">Empirical Examples from InfoSec</a></li>
<li><a href="#infosec-incentives">Incentives in InfoSec</a></li>
<li><a href="#fixing-incentives">Fixing Incentives</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ol>
<h2 id="a-namewhat-is-prospect-theoryawhat-is-prospect-theory"><a name="what-is-prospect-theory"></a>What is Prospect Theory?</h2>
<p><a href="https://en.wikipedia.org/wiki/Prospect_theory">Prospect Theory</a> is a theory in behavioral econ that helps explain how people make decisions between options that bear certain probabilities and risk. The main thesis in Prospect Theory is that people make decisions by evaluating potential gains and losses through the lens of probability, rather than looking at the final, “objective” outcome. This relies on the decision-maker setting a reference point against which they measure outcomes.</p>
<p>Let’s consider a simple example to get a better sense of what this means in practice, using data from the original paper on Prospect Theory:</p>
<p>Decision #1: A) 100% chance of receiving $3,000 vs. B) 80% chance of receiving $4,000, but a 20% chance of receiving nothing</p>
<p>A’s expected outcome is $3,000 while B’s is $3,200…but 80% of subjects choose option A because it represents a guaranteed gain. Homo Economicus would scoff at these silly people and choose B.</p>
<p>Decision #2: C) 100% chance of losing $3,000 vs. D) 80% chance of losing $4,000, but a 20% chance of losing nothing</p>
<p>C’s expected outcome is losing $3,000 while D’s is losing $3,200. Homo Economicus naturally chooses C, but turns out 92% of people choose D for having the small chance of losing nothing.</p>
<p><img src="/blog/img/prospect-theory-01.jpg" alt="A standard Prospect Theory graph"><em>A standard Prospect Theory graph</em></p>
<p>People are inconsistent in their choices based on whether decisions result in a loss or gain, as well as how the decisions are framed. There are four key tenets resulting from Prospect Theory that I’ll examine with the lens of infosec:</p>
<ol>
<li><strong>Reference dependence</strong>: decision makers use a reference point to measure relative gains and losses</li>
<li><strong>Loss aversion</strong>: people really don’t like experiencing losses, and losses hurt 2.25x more than gains feel good</li>
<li><strong>Non-linear probability weighting</strong>: people tend to overweight small probabilities and underweight big ones, and they also like certainty</li>
<li><strong>Diminishing sensitivity</strong>: the farther an outcome is above or below the reference point, the less its marginal effect</li>
</ol>
<h2 id="a-namedefense-vs-offenseadefense-vs-offense"><a name="defense-vs-offense"></a>Defense vs. Offense</h2>
<p><img src="/blog/img/bad-cyberart-01.jpg" alt="Toy soliders fighting on a keyboard"><em>Get ready for more terrible cyber art throughout the post</em></p>
<p>Through the lens of Prospect Theory, my own theory is that defenders operate in the “realm of losses” while attackers operate in the “realm of gains.” As shown above, people in the domain of losses tend to be more risk-seeking, while those in the gain domain tend to be risk averse. In fact, losses felt by those in the gain domain are overvalued by 3:1 relative to those in the loss domain. The further defenders get away from their reference point, the more they’ll opt for small probabilities of a big leap closer to it instead of more certain, incremental improvements — that is, become more risk-seeking and pay more attention to potential payoffs rather than probabilistic outcomes.</p>
<p>Defenders take awhile to readjust their point of reference to match the status quo, which can really screw up their decision-making process; if potential outcomes are computed relative to the reference point, an outdated reference point will reinforce risky decision-making as defenders keep trying to jump back up to it. Attackers, on the other hand, will quickly update their reference point to the status quo. Given their predilection towards risk aversion and emphasis on weighing the probability of different outcomes, attackers need a technical and informational advantage to feel confident in their decision.</p>
<h2 id="a-nameinfosec-ref-pointsainfosec-reference-points"><a name="infosec-ref-points"></a>InfoSec Reference Points</h2>
<p><img src="/blog/img/bad-cyberart-02.jpg" alt="Arrows that look oh-so-cyber"><em>Look, they&rsquo;re pointing</em></p>
<p>In order to figure out the behavioral predilections of defenders and attackers within the infosec arena, we need to determine the reference points that guide their behavior. My theory on infosec reference points is the following:</p>
<ul>
<li><strong>Defenders’</strong> reference point is a security posture in which they can only withstand set Z of attacks, do not experience any materially significant breaches (e.g. those requiring disclosure), and spend $X on products to meet minimum compliance standards: Domain of Losses</li>
<li><strong>Attackers’</strong> reference point is successfully compromising a target for $X cost without being caught before achieving their goal with value $Y: Domain of Gains</li>
</ul>
<p>Therefore, we have the following conclusions on losses and gains for each party:</p>
<ul>
<li><strong>Defenders</strong> feel a loss when they are breached with set Z of attacks, experience a significant breach, or spend more on security products than the minimum needed to meet compliance requirements. The gain from spending less than $X to meet compliance standards is realistically trivial. The non-trivial gain is from successfully stopping attacks that are not included in set Z (i.e. those they assume they can’t withstand); for example, an advanced remote code execution exploit involving a sandbox escape, kernel privilege escalation and a payload that disables endpoint protection products.</li>
<li><strong>Attackers</strong> feel a loss whenever they are caught or when their cost of $X is greater than their outcome of $Y, and feel a gain if they either spend less than $X on an attack or have a greater outcome than $Y. Note, a gain here would include exploits that work across multiple platforms or malware that can be repackaged easily, since it’s reducing the marginal cost of $X for crafting each attack and is thus a superior use of the attacker’s development time. For example, an exploit for a design flaw, architectural weakness, or logic-based vulnerability is usually cross-platform, reliable (vs. memory corruption) and very likely will take longer to fix — all of which means it has a larger payoff for the time invested in its development.</li>
</ul>
<h2 id="a-nameinfosec-examplesaempirical-examples-from-infosec"><a name="infosec-examples"></a>Empirical Examples from InfoSec</h2>
<p><img src="/blog/img/threatbutt-map.PNG" alt="Threatbutt&rsquo;s Cyber Attribution Map"><em>ThreatButt: the #1 must-have, best-of-breed, military-grade enterprise cyber defense-in-derpth platform</em></p>
<p>It’s important to highlight some examples of “irrational” behavior within infosec as a frame of reference for general theory, specifically focusing on differences in adoption (and hype) of various defensive security products. Irrational can be a subjective term, so I mean it in both the “counter to one’s own benefit” way and the “most outside observers think this is illogical” way.</p>
<p>Let’s start with EMET, Microsoft’s Enhanced Mitigation Experience Toolkit, a free tool that helps prevent software exploitation on Windows. Installing it and configuring commonly used applications with ASLR, DEP and other countermeasures significantly increases the difficulty of successfully compromising an application. While there are no official statistics, it’s widely accepted that EMET adoption rates are very low, despite it being free and well-tested.</p>
<p>In the years following the initial release of EMET, some of its features and functionality slowly crept into mainstream operating system releases, where their efficacy forced attackers to move to Office macros — a decision that involved attackers accepting the risk of savvy users who wouldn’t enable the macros rather than investing time in developing and retooling exploits to work in a post-EMET world. This is a good example of attacker risk aversion; they prefer to go for the fluffier target that requires less fancy exploitation, but still has a wide impact. Similarly, Java historically made a fantastic target for attackers because of its uniformity. Attackers could simply write their attack once and reuse it, which made it appealing from a ROI perspective.</p>
<p>Two-factor authentication (2FA) is another example of a solution that isn’t “sexy” per se but should receive greater hype relative to its defensive impact. It’s a low cost solution that’s easily deployed (particularly relative to most security products), and meaningfully bolsters account security beyond just passwords. Yet, it’s taken 7 years to get to the point where it is being widely acknowledged as a standard tool to have in the security arsenal — and adoption still isn’t ubiquitous among the largest consumer-facing firms, despite how inexpensive and simple it is.</p>
<p>Just take a look at <a href="https://twofactorauth.org/">the list of the firms who do and don’t have 2FA</a> to see how many notable companies don’t have it yet. And, among the financial services firms who don’t, it’s a somewhat solid bet that they do have a FireEye box, Bromium or some other anti-APT tech which is vastly more expensive and helps against much lower-probability attacks.</p>
<p>The rise of ransomware and how little has been done to preemptively stop its growth and potency is also perplexing. According to PhishMe, 93% of all phishing emails now contain ransomware. McAfee says there were nearly 1.2 million new ransomware kits in Q1 2016 alone, the total nearing 6 million. It’s an unsophisticated attack that can easily be conducted by the 13 year old in Romania using basic malware kits, presenting a high ROI to the attacker. But given the prevalence and impact of ransomware, it seems irrational that companies are not doing more to protect against it.</p>
<p>Part of this is cleverness by the attacker in making the ransom’s cost low enough to not cause their targets to take drastic measures, but high enough that over a big enough target base, it results in lots of cash against a one-time upfront cost they can amortize over the lifetime of the attack. However, it’s more likely an element of defense being slow to update their reference points; companies could still be adopting relatively low-cost solutions and strategies to better defend themselves against ransomware, such as email protection, filesystem canaries, or even just a better backup process. All three of those solutions would benefit any organization beyond just becoming more resilient against ransomware, and yet they remain some of the most “boring,” underlooked categories.</p>
<p>Canaries in general, in fact, are a smart idea. Yet at only 4-figures per box, they are criminally under-adopted relative to 6-figure anti-APT boxes. It’s pretty straightforward: set up something that looks like a juicy target for an attacker, and get alerted when there’s suspicious activity. It helps give you early breach detection, inform your threat model and better understand attacker behaviors, all for a reasonable price. But adoption is very far from ubiquitous. Unfortunately it doesn’t have hand-wavy technology that “stops” advanced attacks — it comes across more like a mouse trap with cheese than a sexy elaborate laser tripwire maze.</p>
<p>As a final example, application whitelisting is a highly effective, albeit mundane technology. Plenty of organizations are still being compromised with new executables running, something easily thwarted by whitelisting. However, there’s a lower probability of catching an “elite” attack, given it’s likely to exploit an application directly. Critics will say that whitelisting reduces flexibility and bears a non-trivial amount of upfront setup, which is fair until you consider how difficult “sexy” tech, commonly using kernel-level modules, is to implement.</p>
<h2 id="a-nameinfosec-incentivesaincentives-in-infosec"><a name="infosec-incentives"></a>Incentives in InfoSec</h2>
<p><img src="/blog/img/bad-cyberart-03.jpg" alt="It&rsquo;s a compass whose needle is pointing to &ldquo;security&rdquo;"><em>Helps determine the direction of a cyber object from the observer</em></p>
<p>With the above as a reference, I’m going to walk through each of the four key tenets and examine their likely implications in infosec, and how they can explain the “irrational” decision making that many bemoan.</p>
<h3 id="reference-dependence">Reference Dependence</h3>
<p>While it’s (mostly) simple accounting for defenders to know how much is spent on compliance, it’s a lot harder to know your organization’s security posture. Attackers can rely on (mostly) simple accounting to tally their cost and probably guesstimate the value of a successful attack, particularly if it’s selling personal data for $X per user vs. a nation state calculating how much crippling an enemy’s nuclear facility is worth to national security. Defenders, in contrast, can’t tally their costs as they go.</p>
<p>Figuring out your security posture is complicated for a few reasons. First, there are no sufficient industry benchmarks for security health against which organizations can compare themselves. Second, it’s highly unlikely that organizations will have full situational awareness to know which attacks are working against them and which they’re successfully thwarting. Third, defenders aren’t always sure what the “spoils of war” are, i.e. what value an attacker gains from hacking them, from customer data, intellectual property even to something like carbon credits. When it’s difficult to know what’s at risk, it’s difficult to weigh risk.</p>
<p>And, updating the reference point is a slow process for defenders. If their reference point is their perception of their security posture from 2014, it’s now outdated by two years at the minimum, during which attackers assuredly developed new techniques. Even once the reference point is updated to the status quo, the uncertainty in measuring organizational security risk and health means the new reference point will be equally as fuzzy. Just think about the ransomware example; if the reference point were based on today’s most probable threats, adopting technologies to prevent it should be a top budget priority.</p>
<p>Attackers, however, are quickly updating their reference points and evolving their methods based on the true status quo rather than their prior perception. Because the reference point serves as the foundation for decision making under prospect theory, the fact that attackers have more timely and accurate reference points gives them a decisive advantage at stage 1 over defenders.</p>
<h3 id="loss-aversion">Loss Aversion</h3>
<p>We know that losses hurt 2.25x more than gains, and that attackers weigh losses 3x as much as defenders; to be a bit simplistic, the attacker’s “exchange rate” for gains and losses is therefore 1: 6.75. Defenders “just” need to make sure that for each additional dollar attackers spend towards breaching them, they’re getting less than $6.75 in additional value (I’ll discuss how defenders can do so in the last section).</p>
<p>As mentioned in the EMET example, attackers were probably inclined to switch to less arduous targets once it was released just based on the assumption that organizations would have adopted it, <em>even though there wasn’t yet evidence of adoption</em>. As a free tool, adopting it couldn’t present an easier, cost-effective opportunity for defenders to play into attacker’s loss aversion.</p>
<h3 id="non-linear-probability-weighting">Non-linear Probability Weighting</h3>
<p>Both sides overweight small probabilities and underweight large ones. Defenders are predisposed towards following small probabilities of a better outcome (risk-seeking) while attackers will care more about certainty and shun options that have smaller probabilities of worse outcomes (risk-averse).</p>
<p>To feel confident in their abilities to pwn their target, attackers need a strong reference point and the ability to calculate the probabilities of different outcomes. The more information the attacker has about the target, the better they can predict probability, and the greater their technical abilities, the better they can minimize the probability of being caught. Consequently, playing with attackers’ sense of certainty is another tactic defenders can use.</p>
<p>In defensive decision making, it’s crucial to understand the impact and probability of an attack on your organization. There’s a reason why there’s been a collection of attempts to come up with a framework for information security risk-weighting — it’s vital, but an arguably unattainable goal. The variables are prohibitively multifarious, from the company’s industry, technology stack, business model, brand power, etc. to attacker motives, current malware landscape, or even geopolitical statuses.</p>
<p>It’s safe to assume that it’s an impossible task to enumerate all attacks and calculate each of their probabilities and impacts. Industry data is pragmatic since it provides a reasonable reflection on what attacks are most likely. There’s also some data to provide historical precedents on impacts; for example, there’s minimal impact to stock prices, but potentially longer-term impact to sales that ends up affecting stock prices (like in Target’s case). This still leaves the defender left to determine whether they’re robust enough to withstand these different types of attacks .</p>
<p>Now, remember that loss domain-ers will overweight small probabilities and my hypothesis that the only “gain” a defender can really have is stopping attacks that they did not think they could. This can easily support why information security is saturated with products that stop APT or “advanced” attacks, while companies are still getting popped with “basic” methods like phishing, simplistic web app vulnerabilities and outdated, repackaged malware. The tools I mentioned above, such as 2FA, canaries and whitelisting help stop the large-probability, quotidian attacks and thus don’t present an opportunity for a “gain.”</p>
<p>Such a limited potential for a gain facilitates greater emotional basis for action as well, such as Clausewitz’s “passionate hatred for the enemy.” It’s no wonder, then, that attribution is so popular while being functionally useless — at least defenders can have some respite that the culprits were found. But I believe it’s more than that; giving a “face” to the attackers provides a greater sense of certainty, however false that feeling might be. And if I’m generous, nicely bound reports on threat group “[clever noun describing the target group] + [noun of Chinese-associated thing]” detailing <a href="https://en.wikipedia.org/wiki/Terrorist_Tactics,_Techniques,_and_Procedures">TTPs</a> might actually help defenders improve their probability weighting of what attacks they’re likely to incur.</p>
<h3 id="diminishing-sensitivity">Diminishing Sensitivity</h3>
<p>As defenders experience losses, they experience less “pain” for each additional instance. A big, acutely painful breach will more likely lead to action (of the risk-seeking kind) rather than death by a thousand paper cuts, which fully plays into diminishing sensitivity — each time a defender is hacked via a “stupid” bug, they’ll care less and less, so they’ll be less inclined to adopt security products that stop the repeated, lesser attacks (such as 2FA or canaries).</p>
<p>Another issue is that the outcome for defenders is often all or nothing. For example, if an attacker bypasses ASLR, the yield is 100% of the app; there’s no gray area where only part of the app is compromised, meaning from the defender’s point of view, it’s either a total loss or no loss. By this I mean, if an attacker has a 1/10 chance of guessing an address layout, the app is not 90% protected, and if an attacker guesses correctly, the app is 100% compromised. Thus, the impact of this 100% loss is the initial hit, and any subsequent hits don’t feel nearly as severe in comparison.</p>
<p>This disparity between losses is why incident response is such a lucrative business; when defenders are violently thrust deeper into the loss domain, they’re much more willing to spend whatever money necessary to get closer to their reference point again. This takes the form of expensive services or products that the IR providers say will help avoid this big, nasty pain they’re feeling…although this dynamic is often decried as predatory.</p>
<p>On the attacker side, achieving increasingly awe-inspiring levels of leetness loses its splendor after awhile; that is, there’s less motivation to strive for either an extra level of cost reduction or getting more value out of the attack. However, the initial gain leap can still be appealing, and is where I’d argue a lot of innovation happens…it’s just that there isn’t much incentive to continue to innovate.</p>
<p>This explains a few observations. First, that you commonly see the same attack being repackaged rather than completely new methods being used during a campaign. Second, wildly innovative, “great leap forward” vulnerability research is more common once some sort of new protection is developed and deployed (like ROP being used to work around a non-executable stack/heap), and less common when the status quo attacks can do just fine (like users plugging in shiny USBs they find in the parking lot).</p>
<p>What this also means, combined with attackers being more risk averse, is that reaching the next gain level will decreasingly justify the risk tradeoff. This is yet another benefit to the defense, since it can help deter ongoing campaigns even after an initial compromise — if you can up the cost of persistence, then developing tools for retaining system access on the target system will feel too risky relative to the lower gain payoff.</p>
<h2 id="a-namefixing-incentivesafixing-incentives"><a name="fixing-incentives"></a>Fixing Incentives</h2>
<p><img src="/img/infosux.png" alt="Infosux comic"></p>
<p>Now that I’ve tried explaining the <em>why</em>, it’s time to discuss how the balance of decision-making power can be shifted in favor of defense and some examples of tech that makes more sense to adopt. Clearly, defense is naturally predisposed to misjudging their real threat model, misallocating resources and miscalculating strategies, resulting in our current industry dystopia of a comically privileged offense, FUD marketing tactics, focus on thwarting sexier “advanced” attacks and a noxious romance with attribution.</p>
<p>Understanding you have a problem, what the problem is, and why you keep having it is step one. I’m not alone in using knowledge of behavioral econ to counter my human instincts towards suboptimal behavior (e.g. <a href="http://waitbutwhy.com/2013/10/why-procrastinators-procrastinate.html">instant gratification monkey</a>). So, I fully believe that defenders can leverage the knowledge of their weaknesses to correct their missteps and start leveraging their adversaries’ weaknesses against them.</p>
<p>If you’ve spoken to anyone in infosec with offensive experience, they’ll agree that “raising the cost of attack” is one of the most effective means of deterrence. I think re-framing it as “raising the stakes of attack” is more descriptive than cost, since it includes the notion of risk. The fact that attackers only care about their own outcome relative to the reference point, are extremely loss averse, prioritize certainty over a more valuable outcome and get less benefit out of successive gains all supports the idea of raising the stakes.</p>
<p>Defenders should prioritize efficiency when raising the stakes. Rather than focusing on less probable attacks, they should think about the commonalities between the technical and informational advantages that the spectrum of attackers possess. For example, a platform like Drawbridge Networks lets you detect and control lateral movement in an internal network, which could limit an attack’s impact in both more advanced attacks and common malware. Defenders often believe that cyber security products focused on countering “advanced” threats also counter more basic attacks, but that’s not always the case. It’s far simpler to raise the level of the lowest common denominator than try to stop each type of “sophisticated” method.</p>
<p>Eroding the informational advantage is the wisest move, since tackling the technical advantage is more of a cat-and-mouse game. “Silent” monitoring tech that gives visibility without informing the attacker can give defense the ability to respond quickly without the attacker realizing that they’ve been caught, so defenders can watch the attacker’s methods and gain valuable threat intelligence (the real kind). In contrast, technologies that use blocking are giving data to attackers that they can use to craft a better attack.</p>
<p>An effective technique that’s gaining some popularity is ensuring that the organization’s infrastructure isn’t static; attackers will have a substantially more difficult time attacking something that is constantly changing. Even more simplistically, setting up honey pots and other types of deception, like <a href="https://canary.tools/">Thinkst’s Canary</a>, can serve to foster uncertainty in the attacker as well as give defense the heads up that something nefarious is happening.</p>
<p>Defenders should also reduce their adversaries’ potential payoff in conjunction with raising the stakes. Having strict access control rules and a more segmented network means that a compromise of an individual machine doesn’t have much value, and attackers will have to expend more resources to get a bigger payoff. For example, deploying Duo Sec’s 2FA to end users reduces the value of their credentials by adding an extra hoop through which attackers must jump to illicitly access accounts.</p>
<p>But to counter their own weaknesses, defenders should take a data-driven approach — although data can have its flaws, it helps provide rational evidence of what the reference point should be. Having an ongoing picture of the “true” threat model may also encourage defenders to update their reference point more quickly, though it will still require some introspection to be aware of their bias towards being slow to change their views. One tech solution with this approach is Signal Sciences, which uses a data-driven approach to web app security by providing a continuously updated reference point of security posture in that area.</p>
<p>There also needs to be a better understanding in defense of how they define a loss. As I theorized earlier, right now it’s mostly “being breached,” and that may indeed have an immediate impact on the security practitioner&rsquo;s job security. However, it’s probable that a nation state attacker will breach a company, exfiltrate some data for espionage purposes, and there will be no real effects felt by the company (particularly short-term). Enhancing the equation of probability * outcome with an improved understanding of the real impact different types of attackers has on the organization would meaningfully improve prioritization of what solutions to adopt from lens of what is bad from the organizational point of view vs. what is bad from an “objective” security point of view.</p>
<h2 id="a-nameconclusionaconclusion"><a name="conclusion"></a>Conclusion</h2>
<p><img src="/blog/img/bad-cyberart-04.gif" alt="A very stupid looking gif of &ldquo;hacking&rdquo;"><em>Real hackers use this leet virtual reality module for their attacks</em></p>
<p>I really believe understanding the motivations behind this “irrational” defensive behavior is empowering. While even I tend to veer towards hyperbole when describing offense’s advantages, the offense isn’t invisible nor is their decision-making flawless, and I think Prospect Theory helps identify those vulnerabilities — so now the challenge is for defense to start exploiting them.</p>
<p>My hope is that rather than telling infosec defenders that they’re being stupid or irrational or that they’re totally crappy at their jobs, the industry can take a more empathetic approach and suggest strategies towards ameliorating counterproductive incentives. I don’t think that will eradicate FUD marketing tactics or snake oil products, but it probably can give solutions that actually help a fighting chance to make a difference.</p>
<p>In conclusion, let’s try to be more of a community and practice some collective mindfulness, and just maybe we can start fixing things.</p>
]]></content>
        </item>
        
        <item>
            <title>WTFunding: Bioinformatics &amp; Genetic Data</title>
            <link>https://swagitda.com/blog/posts/wtfunding-bioinformatics-genetic-data/</link>
            <pubDate>Tue, 17 May 2016 19:35:10 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/wtfunding-bioinformatics-genetic-data/</guid>
            <description>WTFunding is one of my “spare time” projects to delve into tech sectors attracting VC funding that pique my curiosity. I like connecting dots between disparate things, it’s also pretty useful.
Table of Contents:  So what is bioinformatics? What are the applications? What&amp;rsquo;s hindering adoption? Who cares? What are the risks? What&amp;rsquo;s the current scene? Conclusion  So what is bioinformatics? Simply put, bioinformatics is software used to understand biological data, including (but not limited to) genomic sequences.</description>
            <content type="html"><![CDATA[<p><img src="/blog/img/bioinformatics-02.jpg" alt="stylized pic of a double helix"></p>
<p><em>WTFunding is one of my “spare time” projects to delve into tech sectors attracting VC funding that pique my curiosity. I like connecting dots between disparate things, it’s also pretty useful.</em></p>
<h3 id="table-of-contents">Table of Contents:</h3>
<ol>
<li><a href="#so-what-is">So what is bioinformatics?</a></li>
<li><a href="#applications">What are the applications?</a></li>
<li><a href="#adoption">What&rsquo;s hindering adoption?</a></li>
<li><a href="#who-cares">Who cares?</a></li>
<li><a href="#risks">What are the risks?</a></li>
<li><a href="#current-scene">What&rsquo;s the current scene?</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ol>
<h2 id="a-nameso-what-isaso-what-is-bioinformatics"><a name="so-what-is"></a>So what is bioinformatics?</h2>
<p>Simply put, bioinformatics is software used to understand biological data, including (but not limited to) genomic sequences. What’s particularly cool about the field is that it brings in a bunch of expertise and methods from other areas, like statistics and computer science in order to perform analysis and glean insights from this bio data.</p>
<p>If you only care about the business stuff and don’t really care about how it works (and / or hate science), then skip ahead to the <a href="#applications">“What are the Applications?”</a> section.</p>
<h3 id="how-are-living-things-made">How are living things made?</h3>
<p><img src="/blog/img/bioinformatics-01.gif" alt="Mr. DNA from Jurassic Park gif"><em>The <a href="https://www.youtube.com/watch?v=qUaFYzFFbBU">reference</a>, for those who have had the misfortune of never watching “Jurassic Park.”</em></p>
<p>Let’s start with what constitutes life. The simplest unit of a living thing is a cell; some living things just have one cell, whereas others, like humans, have something like 37.2 trillion cells. Each cell has a nucleus, which is home to most of the genetic material within cells. Within the nucleus lies chromosomes, which are made of protein and DNA.</p>
<p>At a lower level you can think of these cells as being made of molecules, which are atoms grouped together by chemical bonds. Cells depend on three macromolecules, or molecules with upwards of 1,000 atoms, to determine the cell’s’ basic functioning and structure: DNA, RNA and proteins. The relationship between them is that DNA makes RNA, and RNA makes proteins (this is the central dogma of molecular biology). For the computer nerds reading, think of DNA like persistent storage, RNA like volatile memory and proteins like executables.</p>
<p>Zooming further in, genes are regions of DNA that is the recipe book, so to speak, for biological function. They’re what gives a living thing its biological traits — for example, I have the “blue eye” gene. For a sense of scale, there are 23 pairs of chromosomes within the human body that include over 20,000 individual genes that are made up of over 3 billion DNA base pairs.</p>
<p>So what are base pairs? The building blocks of each strand within the famous double helix of DNA are called nucleotides. Each of these nucleotide building blocks is made of either guanine, cytosine, adenine or thymine — which are shortened to C, G, A or T. But, these building blocks pair off to form base pairs, and only like the same partners: G always goes with C and A always goes with T (G-C and A-T). So, if you know the blocks in one strand of the double helix, you also know the blocks in the other.</p>
<p>As I said before, DNA makes RNA and RNA makes proteins, but how? DNA contains exons, which get converted to messenger RNA (mRNA), which delivers the message of which proteins are needed in a cell. The official way to describe exons is as “coding” for proteins, since like a computer program, they end up telling the cell what proteins to have.</p>
<p>Introns, in contrast, don’t code for proteins. Their relevance to this discussion is that they happen to also show where individual genes are separated. That isn’t to say that they are useless otherwise — they’re quite important for regulating how proteins show up in cells, but that’s not important for what I’ll be covering.</p>
<p>This is a good illustration of how all these things link:
<img src="/blog/img/bioinformatics-03.png" alt="Reference pic about chromosomes, DNA, nucleosome, etc."></p>
<p>When you put all the genes within a living thing together, you get its genome. You might be familiar with the Human Genome Project, which is an international research body launched in 1990 dedicated towards mapping out the “human genome.” I have “human genome” in quotes because what they mapped out is an amalgamation of genomes — each human being has a unique genome with special variants in genes. They accomplished their goal in 2003, making it a warm and fuzzy example of the world banding together towards the common good.</p>
<p>The project also spurred a lot of innovation in the field. The way they were going about mapping the human genome was through DNA sequencing, the method for which at the time hadn’t evolved since the 1970s, other than getting a boost as computers became more powerful. But, concurrent with the start of the Human Genome Project, new sequencing methods, novelly called “next generation sequencing” methods, or NGS for short, began being developed and had gained a market foothold by the time the project finished. So, what exactly does DNA sequencing entail?</p>
<h3 id="dna-sequencing-process">DNA Sequencing Process</h3>
<p><img src="/blog/img/bioinformatics-04.png" alt="Pic of DNA encoding"></p>
<p>Before you can figure out the purpose of specific genes, the DNA in question must first be sequenced. For simplicity’s sake I’m sticking with DNA sequencing in this section vs. other types of sequencing, because an already lengthy post would have to become a novel.</p>
<p>DNA sequencing just means determining the exact order of the building blocks (nucleotides) within the DNA, and more specifically the order of its bases — the Gs, Cs, As and Ts. I’ll walk you through a next-generation sequencing (NGS) process, since that’s been the catalyst for rapidly decreasing costs of sequencing, although there’s also the Sanger method, which is the “old school” method.</p>
<h4 id="library-preparation">Library Preparation</h4>
<h5 id="1-dna-samples">1. DNA Samples</h5>
<p>First you have to start with some sort of sample from which to extract DNA. It can be from blood, fossils, saliva or tissues, although saliva is now the go-to for collecting samples from humans given its ease of procurement.</p>
<p><img src="/blog/img/bioinformatics-05.jpg" alt="DNA purification"></p>
<h5 id="2-starting-material">2. Starting Material</h5>
<p>But, there’s also a lot of other stuff in saliva (or any of the samples) that needs to be weeded out. Isolating DNA is done by “purifying” it from a sample through lysis, which disrupts the cell in order to release and separate its biological contents. There are physical and chemical methods for performing cell lysis, the coolest of which is probably sonication — harnessing ultrasonic sound energy to fragment the cell.</p>
<p>Once the cell is broken open, the non-DNA contents are removed via chemical methods, like adding detergents to remove the cell’s surface materials and enzymes that break down proteins and RNA. But those chemicals also have to be separated, so some extra chemistry magic happens (or a wash / spin cycle in a centrifuge) to get the DNA to bind together. Now the purified DNA can be extracted as starting material. As with many things in life, the more starting material, the better.</p>
<h5 id="3-fragmentation">3. Fragmentation</h5>
<p>Now, if we’re talking about human DNA, the genome is going to be really long and would thus take a really long time to sequence. So, the next step is cutting the DNA into smaller pieces for sequencing to help speed up the process. These fragments are officially termed “reads,” which I’ll use going forward. And fittingly, the collection of DNA fragments you generate is called a “library.”</p>
<p>But how do you determine how big you want these fragments to be? It largely depends on how the fragments will be sequenced and for what they’re being sequenced. Most NGS methods sequence up to 400 base pairs (“bp”) during one sequence cycle (called a “run”); the old-school Sanger method typically sequences up to 900bp.</p>
<p>The two typical approaches for this are either physical or enzymatic. One example physical method is acoustic shearing, which may be even cooler than sonication; the DNA sample is placed into a glass vial which is then subjected to acoustic energy that continually creates and collapses microbubbles. The process of growing these bubbles and causing them to implode creates shockwaves that have sufficient power to break down the sample DNA into random fragments. The power of the microbubbles fragments DNA pretty quickly with little loss of the DNA sample, and creates fragments ranging from 100bp to 5,000bp.</p>
<p>The other common physical method is nebulization, involving nebulizer devices which use compressed air to convert liquids into a fine mist. DNA is pushed through a small hole in the nebulizer, creating a mist which is then collected. The resulting fragments are typically 500bp to 3000bp, depending on how quickly the DNA is forced through the hole. This method is pretty quick, but can cause DNA to be lost in the process.</p>
<p>Enzymes capable of degrading DNA can also be used to fragment it into smaller pieces. Although it’s more consistent than physical methods, it also has the opportunity to alter the fragment by insertion or deletion. So, your method of choice really depends on your end goal.</p>
<h5 id="4-repairs--adapters">4. Repairs &amp; Adapters</h5>
<p>First, let’s take a look at how a DNA molecule looks, broken apart by its ribbons (or strands):</p>
<p><img src="/blog/img/dna-molecule.png" alt="Diagram of a DNA molecule broken apart by its ribbons / strands, by Kelly Shortridge"></p>
<p>Each arrow represents one strand of DNA; I’ve laid this out linearly, but as you very likely know (and if the abundance of pictures in this post hasn’t reinforced it), the strands twist to form a double helix. The 3’ end of one of the DNA strands aligns with the 5’ end of its partner strand.The way the DNA molecule is “read” is from 5’ to 5’. So, if the 5’ ends of both strands stick out farther than each other, the strands will be “repaired” by combining them together and filling in the gaps (A with T and C with G).</p>
<p>This is crucial for the next step, which is putting “adapters” onto the DNA strands. Adapters are short DNA molecules that have been synthesized specifically to help in the sequencing process. Adapters are generally provided in a kit, and the adapter sequences therein will be added to the 5’ and 3’ ends of every fragment within one library.</p>
<p>Some may help put “primers” into their correct place, while others may help the DNA fragment stick to a surface in what’s called “immobilization.” The primers have to match the beginning and the end of the DNA fragment, since they’ll serve as the guide for what DNA fragment is amplified in the next step. The final step in the library preparation, immobilization, just means that each single DNA molecule is made up by a bead, which is then anchored to some solid surface, like a glass plate.</p>
<h4 id="amplification">Amplification</h4>
<p>Polymerase chain reactions (PCR) is used effectively as a copy machine for a DNA sequence, or what’s known as “amplification.” This thinking is actually somewhat similar to the methods for improving image quality within satellite imagery that <a href="/blog/posts/wtfunding-space-data-satellite-imagery/">I discussed in my prior post</a>. If you think of the target DNA as an object to be captured within a landscape, it’s far easier to take a bunch of quick pictures of it than take one big, detailed picture of the landscape and try to extract the object from it.</p>
<p>This process follows an exponential curve, too, since you’re making copies of the copies. After just 6 cycles, you have 64 copies of the target gene. After ten, you have 1,024. These copies then make up a “DNA colony” to be sequenced.</p>
<h4 id="sequence-reaction">Sequence Reaction</h4>
<p><img src="/blog/img/bioinformatics-06.gif" alt="DNA sequencing gif"><em>Note: this is a sequencing UI from a TV show and thus should be disregarded entirely as resembling reality</em></p>
<p>NGS is also known as high-throughput sequencing, which just means that there’s tons more data that comes out of the sequencing process, and it’s due to parallelization. There are a few different sub-methods of NGS, the most common of which seems to be Illumina’s sequencing by synthesis (SBS) — though the others also depend on the sort of library preparation and amplification discussed above.</p>
<p>In SBS, the immobilized DNA is “washed” with one of the four nucleotide bases (either T, A, C or G) at a time to see which gets incorporated. For example, if the fragment’s template is GCGAATCG, and your wash is “A”, both of the A’s in the middle will incorporate the wash and the others will be washed away. Then, using the power of lasers and fluorescence, a machine can record which part of the fragment incorporated the base, showing _ _ _ A A _ _ _.Then, the “A” dye would be chemically removed so the next cycle can start, a “G” wash would be used, the laser magic happens, and the machine would record G _ G A A _ _ G, and so forth one nucleotide at a time until the sequence is complete.</p>
<p>For frame of reference, these machines are really, really expensive. At the low end, Illumina’s Miniseq “benchtop” sequencer is about $50,000 and produces an output of up to 7.5GB in just 24 hours. But at the high end, its heavy-duty sequencer, the HiSeqX, is sold for $10 million and only in units of 10, producing an output of up to 1.8TB in less than three days. Even despite their hefty price-tag, it’s still far cheaper and faster than Sanger sequencing (the “old school” method).</p>
<h4 id="sequence-assembly">Sequence Assembly</h4>
<p>The process above generates sequencing “reads,” but not the genome itself — which is where sequence assembly comes in, and is also where data science starts to get involved. De novo sequence assembly, which seems to be the most commonly used, reconstructs an organism’s likely genome sequence based on the reads. The word “likely” here is important, since there’s no guarantee that it’s correct, but instead is approximating the source of these fragments.</p>
<p>As you might guess, this leaves some room for error, which I’ll touch on in the “what’s hindering adoption” section. Errors can be in the form of false negatives, such as thinking a fragment is a mistake or just a repeat, or the fragments could just be linked up together in the wrong spots…plus there’s no guarantee that there weren’t errors in the sequencing process itself. To better illustrate why this process is so tricky, Wikipedia has a great analogy:</p>
<blockquote>
<p>The problem of sequence assembly can be compared to taking many copies of a book, passing each of them through a shredder with a different cutter, and piecing the text of the book back together just by looking at the shredded pieces. Besides the obvious difficulty of this task, there are some extra practical issues: the original may have many repeated paragraphs, and some shreds may be modified during shredding to have typos. Excerpts from another book may also be added in, and some shreds may be completely unrecognizable.</p>
</blockquote>
<p>One example algorithm used in de novo assembly is overlap-layout-consensus (OLC), which leverages a graph to represent the reads. First, overlaps between fragments are computed, and then each fragment is connected by an edge if there are indeed overlaps. The computing problem then becomes how to navigate through the graph in a way that still contains each fragment, which involves a lot of graph theory.</p>
<p>The other primary assembly algorithm is the de Bruijn graph (DBG), which also is based on graph theory. First, the reads are broken into smaller pieces of the same size (called k-mers). Then, the graph is created by ordering from the pieces that overlap at the beginning of the sequence to those that overlap at the end. This sounds linear, but isn’t.</p>
<p>The image below should help visualize each algorithm and compare how they differ:
<img src="/blog/img/overlap-consensus-de-bruijn-graph.png" alt="Visualizing the de Bruijn graph and overlap-layout-consensus algorithms, by Kelly Shortridge"></p>
<p>To move on, let’s assume for now you’ve done a pretty good job sequencing and assembling the DNA in question. It’s not just there to be admired, but to gain something useful out of it, which leads into sequence analysis.</p>
<p><img src="/blog/img/velociraptor-dna.jpg" alt="Raptor with DNA overlayed"><em>An example of a DNA sequence and foreshadowing of my “what are the risks” section</em></p>
<h3 id="sequence-analysis">Sequence Analysis</h3>
<p>Sequence analysis is where the startup software solutions addressing bioinformatics begin to appear. This is the process of taking the sequenced DNA and applying meaning to it — determining and reporting what the genes are and what is their purpose.</p>
<h4 id="homology-search">Homology Search</h4>
<p>“Homology searching” is a fancy way of saying looking for similarity between sequences, and is step one (at least to try) towards getting to the end goal of understanding the genes you’ve just sequenced. “Homology” itself means shared ancestry between genes in different species — after all, all species evolved from the same ancestors. So, when sequences between two distinct species are similar, you can argue that there’s homology.</p>
<p>If you are able to search a database of known sequences to see where they might be similar to your sequence, then you can much more easily identify certain genes and their functions, as well as speculate on evolutionary relationships. In an ideal scenario, if the results of your homology searches cover all the genes you need identified, and they already describe what the genes are for, then you’ve arrived at your end-result. You’ve also saved yourself a lot of other potential steps, which are described right after this.</p>
<p>So how do researchers compare sequences? It involves a lot of data science and also necessitates having a rigorous dataset with which to compare. The more genes are identified on other species, such as mice, the greater ability there is to search human DNA sequences for similar genes.</p>
<p>The most commonly used tool for homology search is BLAST, for “Basic Local Alignment Search Tool,” which is favored due to its speed, at the expense of some accuracy. For those familiar with statistics, it’s a heuristic algorithm. The way it compares a query sequence to a sequence database is by finding “high-scoring pairs,” or HSPs for short, which represent overlaps that seem statistically significant. The speed comes from creating “words” within a sequence, which are generally 11 letters long in DNA sequences, and running the search on each word, narrowing down which HSPs fit as the search moves through the letters. This constitutes a substitution matrix, and would look something like this in BLAST:</p>
<p><img src="/blog/img/substitution-matrix-dna.png" alt="An illustration of a substitution matrix for DNA sequence analysis, by Kelly Shortridge"></p>
<p>While BLAST is the current market leader, improving upon it is clearly an area of interest within academia. Like in many data science projects, making an algorithm both faster and more accurate is the holy grail. For projects with lots of sequence data, BLAST becomes computationally expensive — and given the explosion of sequence data in recent years, researchers have developed and proposed alternatives that potentially offer greater efficiency and ameliorate computational cost concerns. I could publish an academic journal on all the approaches proposed, but I’ll explain one I find particularly neat and badassly-named, GHOSTX.</p>
<p>GHOSTX’s speed advantage is by analyzing both length and match score — the algorithm will only ingest sequences that are both close to the appropriate length of the target sequence and deemed to be statistically similar content-wise. To oversimplify a bit, it’s able to do this by using suffix arrays, an example of which is below:</p>
<p><img src="/blog/img/suffix-array-dna.png" alt="An illustration of GHOSTX and suffix arrays for DNA sequence analysis, by Kelly Shortridge"></p>
<p>This is much more efficient for searching, since now you just have an array with pointers to text snippets (suffixes) that are sorted in alphabetical order. So, what’s being stored isn’t “A$,” “ATA$” and so forth, but “7” or “5”, that is, what’s stored is only the code for where in the list the suffix lies. In other words, you now have an index for all the different suffixes, making it easy to find where your sequence matches others in the database.</p>
<p>Using these various methods, even if you find a matching result for a gene, there still may be insufficient data on what the gene does (i.e. lacking gene annotation, which I’ll describe in a bit). In those cases, and others in which homology search doesn’t complete the puzzle, you’ll have to pursue the following steps in addition.</p>
<h4 id="gene-identification">Gene Identification</h4>
<p>If the homology search fails, or for whatever reason you just don’t want to perform a homology search, gene identification is the next step. What you’ll be looking for is the region of DNA that specifically codes for its function, i.e. codes for protein. These are called open reading frames (ORF), which you can think of as triplets of base nucleotides (again: A, T, C or G), and researchers use them to initially identify regions that probably show what the gene is.</p>
<p>Fancy data science can be involved in this step, too, as gene prediction (which is just the predictive form of gene identification). There are three primary methods of doing so, which include statistical, comparative or empirical methods (i.e. homology, which I went through above).</p>
<p>As an example of a statistical method, gene prediction programs using neural networks can be trained on the organism whose DNA is in question and then applied to the target sequence. Hidden Markov Models (HMMs) also use training data to return the most likely structure of a gene, which is useful if there’s no gene in a sequence or only a partial gene.</p>
<p>Comparative methods use DNA from another species to help predict gene function, since there’s a lot of overlap in how our genes work. The common example is using mouse DNA to determine genes in human DNA; after all, we’re a lot more like a mouse than we are a plant. In fact, 95% of genes that actually code for a biological function match one for one between mice and humans. The theory behind this is that evolutionary pressures led to a general, optimized blueprint for how mammals should function.</p>
<p>However, both these methods still require experimentation to verify that the gene prediction is accurate…at least for now, until these methods (particularly statistical) become more accurate.</p>
<h4 id="translation--database-search">Translation &amp; Database Search</h4>
<p>Once you have identified your gene, whether through homology search or gene identification, you need to translate that gene into its proteins — the stuff that brings to life whatever the genes have blueprinted. These translators are pretty easily found on various academic websites. For example, the sequence I’ve been using in my examples throughout, “CATCATATCAGTCATAGT,” by pure luck happens to have an ORF (the region that actually codes for proteins). It’s in “ATGACTGATATGATG,” which is in the “opposite” DNA strand of my sequence (specifically, the opposite of “CATCATATCAGTCATAGT”).</p>
<p>Once you have your ORFs, you can search them against protein databases to see if there’s already data on them. If there is, it’ll help enormously in the next and crucial step, gene annotation, since you’ll have a head start on knowing what purpose the gene serves.</p>
<h4 id="gene-annotation">Gene Annotation</h4>
<p>Gene annotation is the process in which a specific gene is assigned a specific functional or physical feature. This ideally is largely automated and just enhanced with human expertise, because it would take a very long time for one person to manually annotate a DNA sequence.The functional features generally are drawn from a specific vocabulary to form an ontology, or a formal method of naming and defining things.</p>
<p>There are two components of annotation: the gene’s structure and its function. Structure mostly just determines which regions code for proteins, while functional annotation records the gene’s biological and biochemical functions. Its function just means what proteins are there, or what proteins are hypothetically there (such as predicted by gene finding programs), which engenders how the gene influences an organism’s operations. The gene is also given a name, whether unknown or known based on being identical to a previously documented gene.</p>
<p>Automated annotation uses data science in order to help predict the relevant gene annotations, like its functions. Bayesian networks and similar statistical methods are used by learning from prior annotations, but doesn’t help with finding new gene functions. Automated annotation certainly helps speed up the process, but it’s basically impossible to be accurate on the whole genome, so manual annotation is still needed to clean up any errors or fill in the gaps.</p>
<p>Annotation is one of those things that sounds really easy to do (“just write down what the gene does!”), but is actually really tricky in process. The quality of annotation is largely dependent on the quality of the process before it. If the gene prediction was faulty, or if the sequencing shoddy, it will result in greater difficulty and / or error in annotation.</p>
<h4 id="upload--stop-collaborate-and-listen">Upload &amp; Stop, Collaborate and Listen</h4>
<p><img src="/blog/img/cold-storage-dino-dna.jpg" alt="Cold storage of dino DNA"><em>This is not the sort of DNA data storage I mean.</em></p>
<p>Once the DNA has been sequenced and annotated, it has to be stored…which sounds simple enough, but isn’t quite. In a brief crossover to my industry, security and compliance is actually pretty important when considering biological storage; after all, someone’s genome is extremely private information (though admittedly a mouse probably doesn’t care if their genomic data gets hacked).</p>
<p>Adding to the complexity of storage, there are various types of databases for genomic data — some that contain empirical genomic data, predicted genomic data or structural data. It might also have just the raw sequencing data, or data that’s been cleaned up a bit. Some are publicly available, but some aren’t. The databases also have to be able to facilitate search across sequences, too.</p>
<p>While databases may be a bit passé in other areas of tech, this is actually a reasonably hot area within bioinformatics. Making it easy for customers to search and combine different types of genomic data, such as via an API, is hugely useful in bioinformatics applications, but even helping them manage their data is a plus as well, such as through versioning control (since this sort of data is always being updated). Some startups are also focused on unifying this data with other sorts of medical data, such as patient outcomes, which helps streamline their customer’s processes considerably by not requiring them to visit lots of different databases and tools.</p>
<p>Collaboration is another key part of the bioinformatics end-stage. For example, when designing a pharmaceutical drug, the R&amp;D team needs to collaborate with the clinical trials team, who needs to collaborate with the clinical team in order to maintain a complete feedback loop. So, bioinformatics software is also about optimizing workflows to produce more robust results — which may sound ridiculously outmoded to techies at the cutting edge, but, well, there it is.</p>
<p><img src="/blog/img/ian-malcolm-there-it-is.gif" alt="Ian Malcolm gif saying &ldquo;Well, there it is&rdquo;"><em>The O.G. thought leader.</em></p>
<p>Now with these query-able databases of annotated genes, i.e. you have your sequenced DNA handy and know more or less what the random letters mean in a biological sense, you can now get to work on using them towards a variety of use cases.</p>
<hr>
<h2 id="a-nameapplicationsawhat-are-the-applications"><a name="applications"></a>What are the applications?</h2>
<p>While genes really shouldn’t be thought of based on what diseases they cause, the most obvious applications of bioinformatics revolve around discerning better treatments of diseases. The ability to map out genes and relevant mutations of complex and pervasive diseases such as cancer, diabetes or those that cause infertility could help research in which drugs or other forms of therapy might alleviate — or even eliminate — them.</p>
<p>With that lens, there are three major areas that can benefit the most from bioinformatics: pharmaceuticals, personalized medicine and genetic testing.</p>
<h3 id="pharmaceuticals">Pharmaceuticals</h3>
<p><img src="/blog/img/bioinformatics-07.JPG" alt="Pharmaceutical person doing something"></p>
<p>Pharmaceutical companies can leverage bioinformatics for a variety of applications, from target discovery and drug design to improving the efficacy of existing drugs.</p>
<p>Pharmacogenomics studies how people’s responses to drugs are affected by their genes towards a more tailored approach to pharmaceuticals. You also might hear the term “pharmacogenetics,” which is typically used interchangeably with pharmacogenomics but does have a slight difference. Pharmacogenomics involves looking for differences between people at the genetic level that can explain drug response, while pharmacogenetics involves looking for a genetic reason for why there is a specific drug response. So think of pharmacogenomics as a whole-genome approach while pharmacogenetics deals with just one interaction between a drug and genes.</p>
<p>Right now most medications take a “one size fits all” approach, when in reality a person’s genetic makeup may determine how beneficial a drug is or what side effects they experience. In the future, this means doctors could analyze your genome against a variety of drugs for a specific condition to optimize your therapy — part of personalized medicine, which I’ll discuss in greater detail below.</p>
<p>This type of “predictive” approach would be a big benefit to patients, as they would theoretically no longer have to suffer through a trial and error period that can sometimes come with harmful reactions. Everything from the type of drugs to the dose amount could be tailored based on your predicted reaction to the medication. And, when the data on your response based on this predicted approach is recorded, it would help improve prescription algorithms, resulting in a huge data-network-effect.</p>
<p>For example, at least one in ten Americans takes antidepressants. Which antidepressant and dosage works for some people vs. others currently is more art than science. Further, these medications can often come with adverse side effects that reduce the patient’s quality of life — from insomnia to emotional numbness — or even make their depression worse. If instead their genome could be used to accurately predict which drug and how much of it would improve their depression the most, or at least cause them to suffer the least, their outcomes would be far more quickly and painlessly reached.</p>
<p>So how would pharmaceutical companies reach this stage? Genetic data could be used to isolate a particular protein related to a disease and conduct research towards finding a drug effective against this protein. Or, they could use genetic data to better understand receptors (such as a protein) so they know which would be the best target for their drug molecule. There’s also plenty of room for improvement with existing drugs; oftentimes drugs are effective against conditions for reasons that aren’t well understood, and bioinformatics could help determine why that is.</p>
<p>Ultimately, the real dream for the future of pharmaceuticals is a combination of bioinformatics-informed drug development with a feedback loop of patient outcomes to continually inform and improve drug design. This would likely serve as the cornerstone of personalized medicine, which leads us to…</p>
<h3 id="precision--personalized-medicine">Precision / Personalized Medicine</h3>
<p><img src="/blog/img/bioinformatics-08.jpg" alt="Doctor with an adorable puppy"><em>In 2030, scientists will discover the key to all health issues is giving someone a puppy.</em></p>
<p>“Personalized” or “precision” medicine is all about tailoring treatment and prevention based on an individual’s unique characteristics, including their genes. It’s unrealistic (or so my 2016 brain believes) to assume that in 2100 AD there will be a unique drug for each person and their conditions, but it is realistic to assume, even in the nearish future, that populations can be segmented in a way to substantially improve treatment. This isn’t just about drugs, either — it extends to medical devices along with prevention of diseases, too.</p>
<p>Part of this nearish future is improving the clinical trials process, the experiments performed with human participants to test the efficacy and safety of treatment methods. As discussed in the pharmaceutical example above, having a record of genetic compositions of potential trial participants can help improve the decision-making behind who should be included in the trial. With the clinical trials market estimated to reach $72 billion by 2020, you can see why having the ability to more carefully select trial participants in order to optimize clinical trial outcomes is worthwhile.</p>
<p>In a somewhat extreme case, Estonia is using a government-driven approach for furthering along these initiatives — it’s collecting DNA of all its citizens to create a genetic biobank. While right now the use case is primarily genomic research, farther down the line, having a strong sense of the average genetic “posture,” so to speak, of the Estonian population could help inform public health policy and population-wide personalized medicine.</p>
<p>Here in the United States, Obama created the Precision Medicine Initiative (PMI) in January 2015 within the Health and Human Services (HHS) department, primarily led by the National Institutes of Health (NIH). Its goal is simply to do away with the aforementioned “one size fits all” approach to improve medical outcomes for patients. It’s still in its early innings and has a somewhat slow timeline; in February of this year, NIH announced that it will study the genomes of one million volunteers by 2019.</p>
<p>The hope is the PMI will help kickstart precision medicine both by collecting a large swath of data as well as through developing improved analysis capabilities. It’s likely that everyday citizens won’t see the fruits of personalized medicine until quite a bit after 2019, as personalized treatments will require research, development and testing time, even once the genetic data collection and analysis methods improve. The presumable safety regulations around personalized medicine also may cause snags and delays, which I’ll discuss a bit more in the next section.</p>
<h3 id="genetic-testing">Genetic Testing</h3>
<p><img src="/blog/img/bioinformatics-09.jpg" alt="Newborn baby&rsquo;s foot"></p>
<p>Genetic testing arguably must serve as the basis for any personalized medicine initiative, as only by knowing an individual’s genes can any treatment plans be tailored. A genetic test is simply a test that identifies either the person’s genes or changes in their genes (including proteins). There are currently a few uses for genetic tests, or at least uses cases leveraged in marketing.</p>
<p>Parents or couples considering becoming parents can use genetic testing to evaluate what sort of genes they will pass along to their offspring, generally with the goal of identifying genetic disorders. For couples pursuing in vitro fertilization (IVF), genetic testing can also find defects within the embryos created via IVF before they are implanted into the carrier, which increases the the embryo’s viability.</p>
<p>Individuals can test their own susceptibility to disorders and see what sort of mutated genes they have, or use it as a diagnostic test if they have a currently unidentified ailment. Or, more humorously, as I heard from a friend, being able to tell a sibling that you have less Neanderthal DNA than they have. This, in theory, helps individuals take preventative actions to stave off diseases or illnesses later in life.</p>
<p>While most genetic tests are currently based on DNA, longer-term there will likely be tests involving RNA and proteins. As discussed in the first section, DNA is the blueprint; this means it’s potentially a decent predictor of genetic risks, but not great at measuring the body’s current state for diagnostic purposes.</p>
<h3 id="genome-editing">Genome Editing</h3>
<p>While this isn’t a major application (yet), it’s pretty cool and a company doing it (Intellia) just IPO’d, so I want to touch on it briefly. Turns out you can also leverage DNA sequences and knowledge of genes’ functions in order to modify an organism’s DNA sequence, such as a virus.</p>
<p>The key tech enabler here has been CRISPR, or “clustered regularly interspaced short palindromic repeats,” which actually is part of a bacterial immune system. To use a reverse analogy from my industry, it’s a bit like most anti-virus software, where “signatures” of viruses are kept around so the system knows how to defend against it in the future.</p>
<p>The next part is using CRISPR-associated proteins, or “Cas,” that will actually chop virus DNA in half like a pair of scissors upon confrontation, the result being that the virus can no longer replicate.</p>
<p><img src="/blog/img/crispr.gif" alt="Gif of how Crispr works"></p>
<p>This is pretty cool stuff, and while most of the research leveraging this technology is towards curing diseases, this could make the “designer baby” fears a reality, or even facilitate genetically engineered bioweapons (more on the latter in the “risks” section).</p>
<hr>
<h2 id="a-nameadoptionawhats-hindering-adoption"><a name="adoption"></a>What&rsquo;s hindering adoption?</h2>
<p><img src="/blog/img/bioinformatics-12.jpg" alt="A faceless person in a latex suit with DNA printed on them"><em>In the future, apparently we’ll be featureless and wear latex suits with our genomes printed on them.</em></p>
<p>Now that sequencing costs have decreased, what are the other barriers to progress? A common theme that’s emerging from these WTFunding pieces it that being able to manage and analyze a lot of complex data turns out to be really hard…and bioinformatics is not different.</p>
<p>While it’s now far cheaper to generate genomic data, there’s still no guarantee that it’s accurate. Since gene annotation is still performed by humans, at least to some degree, there’s still plenty of room for human error — not to mention oftentimes the annotations are simply incomplete. You can play a “fun” game if you want and keep backing up the chain I walked you through earlier to spot the numerous chances for error to be incorporated, sequence assembly and sequencing itself being the most likely candidates.</p>
<p>You might have also caught while reading the “how it works” part that the algorithms for various processes require a lot of computational resources. Obviously the past decade has seen enormous strides in the availability of computing power, but it’s still reasonably time and cost prohibitive given the sheer size of genomic data. Someone else has already done the math on the size of the human genome in digital terms, and it’s <a href="https://medium.com/precision-medicine/how-big-is-the-human-genome-e90caa3409b0#.fstnfweh1">roughly 200GB of raw sequencing data</a> because, as explained before, you need a bunch of “reads” of the sequence.</p>
<p>On the data management side, a big question is how do you make genomic data easily accessible and combinable with other types of health data (such as patient outcomes), since that’s a key to unlocking a larger addressable market. There are startups addressing precisely this issue, in figuring out how to sensible combine different data types and link them up in an intuitive manner, but it’s safe to say that data harmony hasn’t yet been reached industry-wide.</p>
<p>The analysis portion specifically presents two big challenges. First, in a fragmented market for tools and algorithms and other analysis methods, how do you figure out what to use? Second, how do you know you’re not just seeing patterns in data that aren’t actually there? Many analysis tools are written with a single application in mind, and from what I gather, they aren’t very well-written, either. So organizations that could potentially benefit from bioinformatics may not be willing to dip their toe in the water until a discernable market with user-friendly software emerges.</p>
<p>And on the genetic testing side, the main questions are: Who pays for the tests? Who advises individuals on their test results? How does the data easily get to health care providers? While I’ll get into the incentive problems within genetic testing later, part of the problem currently is that genetic tests are still somewhat expensive for individuals. Will the government? With health insurance providers? It presents a bit of a chicken and egg problem, given patients need to be genetically tested in order to gain benefits from tailored pharmaceuticals or personalized medicine, but neither of those benefits are yet in a mature enough stage to incentivize people taking the tests.</p>
<hr>
<h2 id="a-namewho-caresawho-cares"><a name="who-cares"></a>Who cares?</h2>
<p><img src="/blog/img/bioinformatics-11.jpg" alt="Image of pills over twenty dollar bills"><em>Pillz on ya billz</em></p>
<p>VCs love numbers, so I’m going to present the big, high-level ones first:</p>
<ul>
<li>Global pharmaceutical industry = ~$1 trillion annually</li>
<li>U.S. pharma industry = ~$400 billion annually</li>
<li>Global healthcare industry = ~$3 trillion annually</li>
</ul>
<p>So combined, looking at a $4 trillion global market, which should assuage any VC’s fears of insufficient market size since grabbing 1% of the market gets you $40 billion in revenue. For reference, Pfizer has just about 5% of pharma market share and has a market capitalization of just over $200 billion.</p>
<p>But, the clever VC says, the initial markets will just be those with the highest pain points, not the entire industry! Those top therapy classes would be oncology (cancer), diabetes and mental health. So here are more numbers:</p>
<ul>
<li>Cancer drug spending in the U.S. = ~$42 billion annually (in 2014)</li>
<li>Direct medical costs of diagnosed diabetes in the U.S. = ~$176 billion annually (in 2013)</li>
<li>Direct cost of mental illness in the U.S. = ~$147 billion annually (in 2009)</li>
</ul>
<p>VCs should still be quite happy, since combined (and given inflation), this is likely nearing a $400 billion market, and just in the U.S. alone. With the 1% market share goal, you’re still looking at $4 billion in revenue today.</p>
<p>Obviously, it isn’t just VCs who care about the big, shiny numbers. The aforementioned pharma companies likely get cartoon-dollar-sign-eyes contemplating the ability to charge more for genomic-data-driven drugs tackling these illnesses. Medical providers could also pad their pockets by leveraging personalized medicine to differentiate from the competition and thus create the ability to markup prices.</p>
<p>But on a less cynical note, there’s the real chance that genome-based personalized treatments won’t be solely a marketing shtick and actually result in significantly better outcomes for patients. So anyone suffering from an illness could potentially see benefits from personalized medicine. Further, there are many illnesses where the current understanding of what causes them can be summed up by ¯\_(ツ)_/¯, and bioinformatics could potentially lead to breakthroughs that would give hope of proper treatment and prevention to those afflicted.</p>
<hr>
<h2 id="a-namerisksawhat-are-the-risks"><a name="risks"></a>What are the risks?</h2>
<p><img src="/blog/img/ian-malcolm-warning.gif" alt="Ian Malcolm saying &ldquo;yeah, yeah, but your scientists were so preoccupied with whether or not they could that they didn&rsquo;t stop to think if they should&rdquo;"><em>And we all know how well Jurassic Park turned out</em></p>
<p>There’s a pretty clear incentive problem on the pharmaceutical side. Pharma companies’ goal is to have more people buy their drugs. One way to incentivize more people to buy your drugs is by recommending certain drugs based on a person’s genetic profile. In a world in which genetic testing was performed by an altruistic, neutral third party, people might only be prescribed the drugs they need. In a world in which pharma companies have massive budgets, particularly for marketing, it isn’t difficult to imagine that they might “sponsor” genetic testing recommendations to ensure that their drugs are recommended.</p>
<p>As with any industry with a growing reliance on data-driven and increasingly automated approaches, there’s the potential for error as well. Relying too much on data models could mean that there is less caution than today towards prescribing treatments, which could result in disastrous “black swan” type events. Though, as I mentioned, it’s far more probable that healthcare providers will instead commit the error of seeing patterns that don’t actually exist, the implications of which could range from unnecessary and costly treatments to wrong and costly treatments that set back the patient’s progress, or even harm them.</p>
<p>Taking a look at another risk angle, the recent <a href="http://www.wsj.com/articles/theranos-is-subject-of-criminal-probe-by-u-s-1461019055">Theranos debacle</a> is now a cautionary tale for medical startups. Many of the startups in bioinformatics are just in the software part of the space, so have less potential of scientific blundering like Theranos, since they’re instead helping with the data management, analysis and workflow portion.</p>
<p>But startups in the genetic testing area should definitely be heeding the lamentable tale of the “blood unicorn.” As I probably have made abundantly clear by this point, there’s room for error at nearly every step of the process, so there’s a non-trivial chance that end users might get inaccurate results that could have pernicious impacts on their health.</p>
<p>Let’s also not forget the cautionary tale of Jurassic Park, in which dinosaurs (which, spoiler alert, are extinct) are brought back to life through the power of DNA for the purposes of creating a theme park. Then everything goes to shit and people die. I’m pretty skeptical that anyone will be so silly as to bring back dinosaurs, but the general lesson of considering long-term implications is an important one. While the current research focus may be on disease prevention, there could be a future in which you can “enhance” yourself (or your offspring, like the “designer babies” I mentioned earlier) through genetic modification. It sounds really cool, but it could also be really, really disastrous and have far-reaching consequences not just health-wise, but societally (for anyone who has played Bioshock, think of ADAM).</p>
<p>On a geopolitical note, improvements in understanding the human genome also open up nefarious applications. At the “mildly evil” end of the evil scale, there’s genetic modification to win sporting events like the Olympics; at the “really evil” end of the evil scale, there’s creating highly targeted biological weapons to conduct warfare against a specific subpopulation, i.e. biological genocide. In fact, this year the U.S. Intelligence Community added gene editing to its <a href="https://www.dni.gov/files/documents/SASC_Unclassified_2016_ATA_SFR_FINAL.pdf">“Worldwide Threat Assessment”</a> report.</p>
<p><img src="/blog/img/bioinformatics-10.jpg" alt="Snake with needles for fangs, it&rsquo;s pretty weird"><em>Implanting needles in snakes’ mouths as fangs is clearly the most efficient bioweapon distribution mechanism…</em></p>
<p>Heretofore, the scale needed for biological weapons has limited it due to the rigorous research and development process that synthetic pathogens require. But thanks to improvements in sequencing technology and analysis, it’s far easier to sequence viruses, which means it’s potentially easier to create new viruses, too!</p>
<p>While it’s probably an exaggeration to say that most people could now make a bioweapon in their backyard, as the availability of genomic databases and computing power increases, and the cost of equipment continues to decrease, it will certainly be accessible to well-funded terrorist organizations (if not already).</p>
<p>I definitely don’t think it’s too tin-foil-y to suggest that most of the current world powers have synthetic bioweapons at their disposal already. However, it may be a bit more tin-foily to say that the population’s increasing reliance on antibiotics really doesn’t help proactively defend against some sort of biological attack.</p>
<p>Hopefully these bioweapons, like nuclear weapons, aren’t ever deployed in-the-wild and are instead more about deterrence. In any case, this sort of subject could make for thrilling TV.</p>
<hr>
<h2 id="a-namecurrent-sceneawhats-the-current-scene"><a name="current-scene"></a>What&rsquo;s the current scene?</h2>
<p>There are a number of startups scattered about the various areas within the bioinformatics chain, most of which seem to have early leaders emerging within them. As far as incumbents, there’s Illumina and Qiagen in the NGS part, CLC bio (owned by Qiagen) in bioinformatics analysis, Bina Technologies (owned by Roche) and Genomic Health in data management and most recently, Intellia in gene editing. I’ve segmented out the startups based on the different sub-areas below:</p>
<h3 id="data-management">Data Management</h3>
<ul>
<li>DNAnexus</li>
<li>Genome Compiler</li>
<li>Genospace</li>
<li>MediSapiens</li>
<li>SolveBio</li>
<li>Benchling</li>
<li>Omicia</li>
</ul>
<h3 id="genomic-analysis">Genomic Analysis</h3>
<ul>
<li>Biomatters</li>
<li>BioNano Genomics</li>
<li>CancerIQ</li>
<li>Maverix Biomics</li>
<li>One Codex</li>
<li>Onramp BioInformatics</li>
<li>Spiral Genetics</li>
<li>Syapse</li>
<li>Tute Genomics</li>
</ul>
<h3 id="genome-editing-1">Genome Editing</h3>
<ul>
<li>Caribou</li>
<li>CRISPR Therapeutics</li>
<li>Desktop Genetics</li>
<li>Homology Medicines</li>
</ul>
<h3 id="genetic-testing-1">Genetic Testing</h3>
<ul>
<li>23andMe</li>
<li>Cofactor Genomics</li>
<li>Color Genomics</li>
<li>Counsyl</li>
<li>NextGxDX</li>
<li>Recombine</li>
</ul>
<p>There isn’t one major investor that’s all over this space, though in the lead is definitely Google Ventures. Below is the list of the major institutional and corporate VCs that have played in this space in some form:</p>
<ul>
<li>Andreessen Horowitz</li>
<li>Data Collective</li>
<li>Felicis Ventures</li>
<li>First Round</li>
<li>Formation 8</li>
<li>Google Ventures</li>
<li>Johnson &amp; Johnson</li>
<li>Khosla Ventures</li>
<li>Mohr Davidow Ventures</li>
<li>New Enterprise Associates</li>
<li>Novartis Venture Fund</li>
<li>SV Angel</li>
<li>WuXi Healthcare Ventures</li>
<li>Y Combinator</li>
</ul>
<hr>
<h2 id="a-nameconclusionaconclusion"><a name="conclusion"></a>Conclusion</h2>
<p><img src="/blog/img/life-finds-a-way.gif" alt="Ian Malcolm saying &ldquo;Life finds a way&rdquo;"><em>Bioinformatics startups will find a way</em></p>
<p>The implications of a more mature bioinformatics industry are pretty radical — from curing cancer to having vastly improved patient outcomes resulting from personalized medicine. I think it’s evident from the simplicity of some current solutions, such as basic data management and collaboration tools, that there’s a long way to go until this area becomes sufficiently sophisticated and automated.</p>
<p>While the error problem throughout the bioinformatics chain will certainly hinder adoption of end-applications, I think the truly massive dollar size amounts behind those applications will spur along innovation sooner rather than later. Perhaps even some of the washed out founders and engineers who are victims of the current market correction will apply their computer and data science skills towards this area — it seems a more easily accessible industry than others, with collaborative incumbents.</p>
<p>I think the biggest long-term opportunities are in what is some of the traditionally “boring” application infrastructure software — data management, collaboration, workflow management, etc. — both in pharmaceutical research and for healthcare providers. If I were a healthcare data platform like Flatiron Health or Health Catalyst, I might be looking to scoop up some of these companies early with the long-term vision of an integrated genomic and clinical data platform.</p>
<p>In any case, the companies that create this sort of middleware can use those data-driven underpinnings to very easily reach up into the sexier analytics and visualization plays. I honestly wouldn’t be shocked if some of these data management software startups become the SAP or Oracle of Bioinformatics.</p>
<p>In contrast, I think genetic testing will eventually become a commodity, which in my opinion doesn’t justify the level of risk that startups face with it today. Admittedly, it’s a crucial part of unlocking the potential of personalized medicine, but my gut feeling is that there will just end up being a Quest Diagnostics and Laboratory Corp. of genetic testing one day. For comparison, Quest has a market cap of ~$10 billion and Laboratory has one of ~$13 billion, while SAP has one of ~$95 billion and Oracle one of ~$163 billion (not to mention all of their competitors). So I think on the whole, the software bet is the smarter one given the risk / reward trade off.</p>
<p>Finally, I think we’re not at all yet prepared for the ethical challenges that will arise from bioinformatics applications…but that’s another long-read post for a different time.</p>
]]></content>
        </item>
        
        <item>
            <title>Apple vs. FBI: Privacy &amp; Inequality</title>
            <link>https://swagitda.com/blog/posts/apple-vs-fbi-privacy-inequality/</link>
            <pubDate>Thu, 17 Mar 2016 19:29:13 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/apple-vs-fbi-privacy-inequality/</guid>
            <description>In recent news, there’s been a fiery public relations battle between the FBI and Apple. While there has been vocal protest by the technology community, and particularly the information security community, against the FBI’s request, it has largely been rooted in (very valid) concerns over the degradation of software security, national security and privacy in a general sense. However, there’s a larger societal concern that cannot be ignored.
By way of brief background, the gist of the legal fight is that the FBI wants Apple to create a custom version of its operating system for iPhones, iOS, that would allow it to circumvent the safety measure of reducing the frequency with which the device’s passcode can be guessed when locked.</description>
            <content type="html"><![CDATA[<p><img src="/blog/img/apple-privacy-scales.png" alt="Scales of justice, with an iPhone on one side"></p>
<p>In recent news, there’s been a fiery public relations battle between the FBI and Apple. While there has been vocal protest by the technology community, and particularly the information security community, against the FBI’s request, it has largely been rooted in (very valid) concerns over the degradation of software security, national security and privacy in a general sense. However, there’s a larger societal concern that cannot be ignored.</p>
<p>By way of brief background, the gist of the legal fight is that the FBI wants Apple to create a custom version of its operating system for iPhones, iOS, that would allow it to circumvent the safety measure of reducing the frequency with which the device’s passcode can be guessed when locked. The FBI wants this in order to access the contents of the San Bernardino shooter’s personal device, although this software, if created, would in fact allow them to circumvent the safety measure of any iPhone. I recommend viewing <a href="https://www.youtube.com/watch?v=zsjZ2r9Ygzw">John Oliver’s segment</a> on the debate for an accessible, but more comprehensive overview.</p>
<p>The issue itself, I fear, is representative of the early stages of a dichotomy between the “haves” and “have nots,” but for privacy. This is more important than I believe many realize as far as deepening inequality and injustice. This isn’t just about protecting photos of your children, or keeping secret the absurd questions you type into Google.</p>
<p>This is about the fact that devices are now an integral part of our digital identities; that, as dictated by the Constitution, all citizens have a right to privacy; and that, while not necessarily the norm, there are very real abuses of power within the law enforcement and legal system and bias against underprivileged groups.</p>
<p>Society and technology are now in an entrenched dependency; tech inequality will progressively manifest as socioeconomic inequality. The stratification of tech knowledge between higher and lower socioeconomic groups is leading to the latter’s vicissitudes in education and employment opportunities, but I also argue that the Apple vs. FBI case is the start of the age in which it manifests in legal rights as well.</p>
<p>Even if Apple wins, they will continue their invigorated efforts towards ensuring that any requests for customer data by law enforcement simply cannot be fulfilled. This will be a fantastic result — for those who can afford an iPhone. The reality is that owning an Android is a less expensive option, but does not come with these protections and is unlikely to in the near future.</p>
<p>Apple can enforce this level of security because it manufactures both the device and develops its operating system. Google could do the same with its own line of Nexus devices, but otherwise there would need to be a collaboration across all the various manufacturers of Android devices in order for it to happen. Even if such a collaboration does happen, it will take time and likely still command a price premium in the market for these efforts.</p>
<p>While there are a number of security measures individual Android users can take to reproduce most of Apple’s protections, they require a higher degree of tech ability than most consumers, not to mention lower socioeconomic groups, possess. So even though it is technologically feasible, the nature of socio-tech inequality as it relates to education still creates a substantial hurdle towards an accessible method of ensuring privacy.</p>
<p>Less affluent consumers are thus left without these protections, the protections that protect our private data on our mobile devices from law enforcement and enforce the Fourth Amendment. These less affluent consumers, particularly those belonging to racial minorities, are also much more likely to be accused of criminal activity.</p>
<p>There are two key disadvantages in this arena that underprivileged consumers subject to discrimination face, which I’ll illustrate by way of analogy (which may seem superficial at first blush). In Jay-Z’s song <a href="https://www.youtube.com/watch?v=32Xh9L-AqA8">“99 Problems,”</a> he raps that, when asked by a police officer to search his car, he retorts, <a href="http://genius.com/17560/Jay-z-99-problems/Well-my-glove-compartment-is-locked-so-is-the-trunk-in-the-back-and-i-know-my-rights-so-you-gon-need-a-warrant-for-that">“Well, my glove compartment is locked, so is the trunk in the back / And I know my rights, so you gon’ need a warrant for that.”</a></p>
<p>First, underprivileged people may not have the ability to “lock” the digital versions of their glove compartments and trunks, because they cannot afford the luxury of privacy via strong security. Second, Jay-Z is aware of his rights and the need for the officer to have a warrant, and such knowledge is invaluable in maintaining his privacy — more importantly, his innocence — in the face of accusatory and biased law enforcement. However, the knowledge and understanding of digital privacy rights, and how to protect them, is barely existent among even affluent, highly-educated groups, so consumers with greater resource constraints are even less likely to have satisfactory awareness.</p>
<p>With many highly public instances of abuse of power by law enforcement, it would be naive to assume, should the FBI win this case, that the power that having full access to the contents of a mobile device brings would not have the same potential to be similarly abused. When you consider that divulging passwords is protected by the Fifth Amendment as “knowledge,” having an easy technology option — simply automatically updating the device with law enforcement’s proprietary version of the operating system, thereby removing passcode protections — is understandably seductive.</p>
<p><a href="https://en.wikipedia.org/wiki/Parallel_construction">Parallel construction</a> is a very real concern among groups subject to routine discrimination, and it isn’t difficult to imagine law enforcement illegally unlocking phones, searching for the evidence they want and retroactively claiming that this data was the cause for the suspicion. This includes liberal interpretations of incriminating evidence — jokes could potentially be purposefully misconstrued as evidence, with the defendants facing racial or socioeconomic bias that would make it difficult for them to contest.</p>
<p>The combination of pervasive smartphone cameras and the viral nature of social media has helped foment the recent outrage against transgressions by law enforcement. Knowing that data recorded on smartphones now has the potential to highlight unprofessional and illegal conduct, it also not difficult to imagine that law enforcement would desire the ability to easily circumvent security protections to prevent such ignominy.</p>
<p>Even with these examples, it’s essential that we not forget that privacy is granted to us as a fundamental right, and that even the potential for its violation is worthy of outrage, regardless of cause. Rights are meant to be for all citizens, but in a FBI-wins world, only those who can afford the efforts of Apple’s R&amp;D department will be able to buy their rights back in a depressingly simoniacal manner.</p>
<p>Though it may appear hyperbolic, this case may be one that has a resounding impact in shaping our society going forward. Even though many will still be unable to afford the luxury of privacy, at least in the short-term, even if Apple wins, their prospects are far more dire if Apple loses. Should the FBI win, we are unequivocally cementing this inequality and further disenfranchising those who cannot afford the luxury of privacy.</p>
<p>I like to think that the United States, at its best, can serve as a role model for innovation to the rest of the world. Is the sort of society in which only those who are well-off can realize their right to privacy the one we want to build?</p>
]]></content>
        </item>
        
        <item>
            <title>WTFunding: Space Data (Satellite Imagery)</title>
            <link>https://swagitda.com/blog/posts/wtfunding-space-data-satellite-imagery/</link>
            <pubDate>Mon, 04 Jan 2016 18:49:24 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/wtfunding-space-data-satellite-imagery/</guid>
            <description>WTFunding is one of my “spare time” projects to delve into tech sectors attracting VC funding that pique my curiosity. I like connecting dots between disparate things, it’s also pretty useful.
Table of Contents:  So what is &amp;ldquo;space data&amp;rdquo; and &amp;ldquo;satellite imagery&amp;rdquo;? What are the applications? What&amp;rsquo;s hindering adoption? Who cares? What are the risks? What&amp;rsquo;s the current scene? Conclusion   So what is &amp;ldquo;space data&amp;rdquo; and &amp;ldquo;satellite imagery&amp;rdquo;?</description>
            <content type="html"><![CDATA[<p><img src="/blog/img/satellite-01.jpg" alt="Satellite observing Earth"></p>
<p><em>WTFunding is one of my “spare time” projects to delve into tech sectors attracting VC funding that pique my curiosity. I like connecting dots between disparate things, it’s also pretty useful.</em></p>
<h3 id="table-of-contents">Table of Contents:</h3>
<ol>
<li><a href="#so-what-is">So what is &ldquo;space data&rdquo; and &ldquo;satellite imagery&rdquo;?</a></li>
<li><a href="#applications">What are the applications?</a></li>
<li><a href="#adoption">What&rsquo;s hindering adoption?</a></li>
<li><a href="#who-cares">Who cares?</a></li>
<li><a href="#risks">What are the risks?</a></li>
<li><a href="#current-scene">What&rsquo;s the current scene?</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ol>
<hr>
<h2 id="a-nameso-what-isaso-what-is-space-data-and-satellite-imagery"><a name="so-what-is"></a>So what is &ldquo;space data&rdquo; and &ldquo;satellite imagery&rdquo;?</h2>
<p>I derive a lot of pleasure by calling it “space data,” but it is more accurately termed satellite or geospatial imagery, and the analysis thereof. This is all about image data collected by satellites about the Earth’s surface and the software that helps make these images useful to humans.</p>
<p>To get to the final, useful image, there are three main steps: launching a satellite into orbit, collecting the images of the Earth’s surface, then processing and analyzing the images. While image processing &amp; analysis, with the goal of gleaning intelligence from satellite imagery, is drawing the most VC funding at the moment, it’s important to understand each step to get both the opportunities and risks startups face within this sub-sector.</p>
<p>If you are more of a <a href="https://en.wikipedia.org/wiki/Wikipedia:Too_long;_didn%27t_read">tl;dr</a> person, you might want to skip down the page a bit to the next section, <a href="#applications">“What are the Applications?”</a> and continue from there.</p>
<h3 id="step-1-launch-to-orbit">Step 1: Launch to Orbit</h3>
<p><img src="/blog/img/satellite-02.jpg" alt="Landsat 8, an Earth Observation satellite operated by NASA"><em>Landsat 8, an Earth Observation satellite operated by NASA.</em></p>
<p>I’ll be focusing on remote sensing satellites, but there are also communications and weather satellites and reconnaissance (aka spy) satellites and maybe even satellites that can shoot lasers out of the sky (<a href="https://commons.wikimedia.org/wiki/File:Nothing_is_beyond_our_reach.svg">nothing is beyond their reach</a>, after all). First, let’s cover some basics about satellites.</p>
<p>Rockets are the things who take satellites on their journey into Earth’s orbit. Earth’s gravity is what keeps satellites in orbit, just like how gravity causes the Moon to orbit us. Satellites are fitted with gyroscopes, spinning discs that leverage the Earth’s magnetic field to keep the satellites on course. Solar panels power the satellites once they’re in their proper orbit, since they have nice access to the Sun’s rays.</p>
<p>There are three different types of orbit: geostationary, geosynchronous and polar (or sun synchronous). Geostationary means that the satellite is stationary relative to the Earth’s surface. Communication and weather satellites use this orbit, staying way above the Earth at a specific point on the Equator (way above = 30k+ km). Polar (aka sun synchronous) means the satellite orbits at an altitude at which it will consistently pass over a given location at the same local time. This is what remote sensing satellites use, and are typically closer to the Earth’s surface than the communications satellites (only hundreds of km above).</p>
<h3 id="step-2-data-collection">Step 2: Data Collection</h3>
<p>Objects on Earth reflect energy from the Sun. This energy is in different “bands,” typically visible, infrared and water vapor. Each object reflects a different amount of energy, giving them a “spectral signature.” “Remote sensing” is how satellites collects these reflections — and just means sensing the energy bands from a remote place (like the Earth’s orbit).</p>
<p><img src="/blog/img/energy-reflection.png" alt="How remote sensing works, diagram by Kelly Shortridge"><em>How remote sensing works (no animals were harmed in the making of this image).</em></p>
<p>Satellites carry sensors that allow them to do this remote sensing. Passive sensors just collect the reflections (radiation) that are emitted from Earth, using the Sun’s energy as its source of electromagnetic radiation. Active sensing systems carry their own source of electromagnetic radiation, which is directed to the Earth’s surface. Just like the passive sensing system, it then measures the amount of energy that is reflected back.</p>
<p>Different sensors are designed to measure different parts of the electromagnetic spectrum. For example, the 450nm - 495nm wavelength band would measure the visible color blue. The 570nm - 590nm wavelength band would measure the visible color yellow. And near-infrared is the ~700nm - 1mm wavelength band.</p>
<p><img src="/blog/img/EM-spectrum.png" alt="The Electromagnetic Spectrum"><em>The Electromagnetic Spectrum</em></p>
<p>Luckily, the electromagnetic spectrum is pretty handy for identifying objects. The way objects reflect back energy is consistent and tends to be unique. Water doesn’t reflect much visible or infrared energy, but vegetation strongly reflects infrared.</p>
<p>Satellites can even be used for things like detecting gravitational pull on the Earth’s surface. If you have two satellites, one leading and one following, when the lead passes over an area with high gravitational pull, it’ll start speeding up (and slow down over areas with weaker gravitational pull). NASA launched twin satellites in 2002 to do just that (GRACE mission). Being able to detect gravity helps map out areas below the Earth’s surface, from tunnels to potential oil wells.</p>
<p>Capturing lots of energy/wavelength bands creates what are called “multispectral images.” This means that the final image contains a few layers of images that each capture a different energy band. For example, one layer might capture the infrared band while another might capture the green band. You can even have superspectral and hyperspectral, but that just means there are lots and lots of layers with different energy bands. The more bands, the more opportunity for differentiation of objects on the ground. On the opposite side of the spectrum (pun intended), panchromatic images capture a single band of energy in black and white (and shades of grey).</p>
<p>As the satellite orbits around the Earth, it looks at a small chunk of the planet at a time. Even if it goes around the Earth every few hours, it is only capturing as little as less than 1% of the Earth each time. This small chunk is represented by a pixel, just like on your TV or computer monitor. For example, one pixel could represent 50x50m on Earth. Different types of sensors allow for different pixel sizes, typically from 5m to 1km — though some have pixel sizes as small as the micrometer scale (and tend to capture a smaller portion of the Earth as a result).</p>
<p>As the satellite orbits, it has to capture as many pixels as it can. However, even if pixel size is the same among different sensors, this doesn’t mean the resolution is as well. Higher resolution is indicated with a smaller physical measurement; for example, an image with a pixel size of 5m will look much clearer with a resolution of 5m vs. 20m.</p>
<p>According to one news report, in 2013 a spy satellite was launched in California capable of “snapping pictures detailed enough to distinguish the make and model of an automobile hundreds of miles below.” Given the length of a car is approximately 5m, let’s assume that the resolution needs to be 10% of that in order to see the necessary level of detail about the car, so 0.5m or smaller. And we’d likely assume that it isn’t just panchromatic since the government likely also wants to know the color of the car. This makes it quite a bit more powerful than most commercially available multispectral resolutions. As a frame of reference, DigitalGlobe’s satellite scheduled to be launched in September 2016, the WorldView-4, will have a multispectral resolution of 1.2m.</p>
<p>When reading about a satellite’s imagery capabilities, it’s crucial to understand that pixels and resolution are not the same thing. The difference between a pixel and resolution is that resolution is the size of the smallest detectable feature captured whereas a pixel is the size of the smallest physical area captured (or in other words, the smallest unit of the image).</p>
<p>There are also different types of resolution. Spatial resolution depends on what’s called the sensor’s “Instantaneous Field of View” (IFOV), which just means the visibility the sensor has at a particular altitude at a particular moment in time. Spectral resolution just means which parts of the electromagnetic spectrum the sensor can capture; higher spectral resolution indicates a narrower band of wavelengths captured. Radiometric resolution measures how many shades of grey there are between black and white, measured in bits; an 8-bit radiometric resolution means the sensor can measure 256 unique shades of gray. And temporal resolution is the length of time it takes for the satellite to complete one orbit; for example, some satellites may capture the same area every 5 days, while for others it will be every 15 days.</p>
<p>Another important thing to keep in mind is that satellites are not necessarily taking photographs; these sensors are not cameras (though those spy satellites sometimes do use long-focus lenses). The mechanism is through sensing energy bands. Hence the industry lingo is remote sensing. Each image represents a lot of pixels arranged in rows and columns — think of it like putting a fragment of an image into 1,000 rows by 1,000 columns in Excel, and then zooming way out to see the full picture.</p>
<p><img src="/blog/img/pixel.png" alt="One pixel example"></p>
<p>To continue that analogy, that Excel file would then represent what’s called a “scene.” Scenes can represent over 2,000km on each side. These scenes are what most people buy since they want the “big picture,” not a tiny snippet of whatever is being observed.</p>
<p><img src="/blog/img/pixel-to-scene.png" alt="Showing how one pixel becomes a scene"></p>
<p>Again, this scene represents a physical object on the Earth’s surface. In our cat’s case, let’s say it’s just over a foot tall sitting upright, which is about 0.33m. In the scene, we can see the entire physical object (the cat) and features as small as its nose, so using its nose as a proxy for the smallest detectable feature, our resolution is approximately 0.01m — meaning we’re likely using a super secret spy satellite to spot Mr. Whiskers.</p>
<p><img src="/blog/img/pixel-and-resolution.png" alt="Showing how pixel and resolution relate"></p>
<p>Multispectral scenes can represent a large amount of data, often with tens of millions of bytes (10MB+) per scene. This is because the intensity of each pixels is stored as a single byte (an 8-bit digital number), and there are typically millions of pixels in any given scene. Recorded video can hog even more data, and high quality video is a more newly available product — and typically no longer than two minutes. How video can be used to track objects on the ground is a longer discussion that mostly talks about error correction.</p>
<h3 id="step-3-image-processing--analysis">Step 3: Image Processing &amp; Analysis</h3>
<p>This is just where the fun begins! Now the imagery needs to be processed, in what’s novelly called “image processing.” This just means a human uses a computer to work with the images. Having higher spatial resolution and more data doesn’t mean you’ll necessarily get more information out of the images — and that’s why image processing is so important.</p>
<p>Why is there a human required, you might ask? While it’d be fantastic to have automated image analysis software that can intelligently scan images and highlight relevant objects or issues, that’s not the current state of things at all. Humans still sadly need to be involved to help with filtering and classification based on their project goals.</p>
<p><img src="/blog/img/satellite-03.png" alt="Satellite imagery of wildfires in Idaho"><em>Satellite imagery of wildfires in Idaho</em></p>
<p>Processing is part of image analysis, which requires special types of statistics and analytical methods that are tailored for spatial data — though primarily anchored around interpolation (predicting new, unknown data points within a group of some known data points). There’s an emphasis in geostatistics in being able to estimate how much the gaps that are filled in via prediction might be wrong; things like elevation for 3D modeling are particularly tricky to determine aerially, so there is ripe opportunity for error. One example method is kriging, which helps predict the appropriate values in unobserved locations by using a weighted average of surrounding areas and estimating its accuracy.</p>
<p>For satellite imagery, there are software tools that have been developed with the specific use case of geospatial imagery processing and analysis in mind. These tools are called geographical information systems (GIS for short). The usual aim of image processing is to create an image that makes sense to a human — in essence, make the energy band sensing look more like a photograph. Or more simply put, “what the heck is in this spot?”</p>
<p>At a higher level, the end goal from all of this is information extraction. Even with basic mapping (like Google Maps), the point of the image is to gain some insight about stuff here on the ground. The type of information that is desired can be different between applications (which I’ll discuss later), and very rarely is available with just the basic image taken. Thus, humans need tools to help extract information from the images.</p>
<p>The typical chain of image processing is data import, image restoration &amp; rectification, image enhancement and information extraction. The methods for performing this processing chain have been shifting somewhat in recent years. Now, satellite data can be retrieved via APIs and similarly are various tools for processing made available via APIs. But, to understand some of the challenges, it’s important to walk through these steps.</p>
<p><img src="/blog/img/image-processing-chain.png" alt="Showing the steps in satellite image processing"></p>
<h4 id="data-import">Data Import</h4>
<p>While spy satellites might take actual film, eject it and have it intercepted by military aircraft, the process to transmit imagery back to Earth isn’t quite as cool for commercial satellites. As the satellites orbit around the Earth, they send data down (“downlinked”) via directional antennae to receiving stations on Earth. They can also receive instructions on what to capture, which are sent up from Earth (“uplinked”). These communications are conducted over the X-band, a specific frequency range.</p>
<p>The images the satellites take are generally compressed on-board, with their total storage nearing a terabyte. Some can even perform image fusion (which is discussed shortly) before transmission to help improve the image’s resolution.</p>
<p>There are various GIS data formats and different types of data that can be imported. Much like <a href="/blog/posts/wtfunding-industrial-manufacturing-analytics/">in my prior post</a>, a number of different vendors have their own data formats, and they are often proprietary, making a lot of big data analysis stuff a lot harder. There are also unique data formats for specific parts of imagery – such as the feature geometry, feature attributes, topology, etc.</p>
<p>Satellite imagery is commonly stored in digital numbers (DN), which means each pixel gets a value in 8-16 bits for a physical value (like color or temperature). This helps minimizing the storage volume.</p>
<p>There are a number of geospatial-specific database management systems (DBMS), which is software used to store GIS data to allow it to be later retrieved and modified – essentially the tool that helps organize data. This is actually an important part of image processing, since it allows for querying and comparisons across different pieces of data.</p>
<p>Most of the time, this data is stored in distributed systems, which just means it isn’t all in one database. Distributed databases optimize scalability, which is why they are used in this use case, due to geospatial data’s typically large file sizes.</p>
<p>The relational database model is the one that is primarily used for GIS data. I’ll skip an explanation and discussion of the various database systems and types for now, but if you aren’t familiar with them, <a href="https://en.wikipedia.org/wiki/Database">here’s a link to the Wiki</a>.</p>
<p>Analysis techniques are used to create and define models of relationships between different data sets. The traditionally used technique is the entity-relationship model. In this, there are specific entities, like buildings, forests, and agricultural land, which have different attributes and “members” of the entities (like government, residential or religious buildings). The relationship part of entity-relationship just means members of these entities are compared; for example, you could compare different residential buildings in New York City to determine what attributes they have in common (perhaps they have rooftop gardens, are thinner, etc.).</p>
<img style="float: right;" src="/blog/img/relational-model.png" alt="relational database model"/>
<p>The relational model works well for this sort of data, since it allows for different datasets to be compared. The key (pun intended) here is that there are keys for each entry in the data sets that link the data sets between each other.</p>
<p>Using a relational model for databases allows the humans to make queries with the Structured Query Language (known best by its acronym, SQL). You can make a query such as: select all buildings with rooftops within 100km of Union Square in Manhattan. Each building will have a specific coordinate (i.e. spatial relation), and (which we’ll cover in a few paragraph), can be marked as having a rooftop. Geographic search is the most important query out of these, and a large part of why there are geospatial-specific DBMS.</p>
<p>There are two types of data stored in these systems: spatial or attribute data. Spatial meaning “georeference” (i.e. location on Earth), and attribute meaning feature-related data (normally stored in tables). From the example above, the building coordinates are within the spatial data, and whether they have rooftops is within attribute data.</p>
<p>Spatial data has two further subcategories: vector and raster. Vector data deals with geometry in a few different ways. Think 2D, like boundaries of forests, or 1D (lines), like following the path of a river. You can also have specific spatial points that represent a particular item, and they are technically 0D. Raster data represents surfaces, but not just as far as 3D things like elevation; it can also show things like population density or temperature.</p>
<p>Raster data is where our spectral data comes in, along with the actual imagery and topography. Each cell (remember, this means pixel) gets assigned a specific value based on its primary feature. For example, one cell may have vegetation assigned to it, while another may have water.</p>
<p>GIS software will link all this data and create these models with a specific structure. Typically, it will start with geometrical information, then add topological and finally thematic (the raster data). This order is logical since geometrical represents the physical form and position of objects, topological is about relational position (intersections of objects), and thematic adds in the detail about objects (typically in layers).</p>
<p>There’s some trickiness in importing and managing this data, however. The data needs to be both accurate, meaning the map needs to match real world values, and precise, meaning described as exactly as possible. The distinction is important; you can have a map perfectly overlaid on real coordinates (accurate), but showing “this area is green” rather than a breakdown by type of vegetation (imprecise). Similarly, you could have detail down to different types of weeds (precise), but your coordinates are a mile off (inaccurate).</p>
<p>I’ll get into more of the challenges later, but it’s important to touch on how these errors happen, most of which are during processing. Formatting data can cause scaling to change, the data can be outdated, or there could even be an errant sensor. There are issues even with positional accuracy as far as non-land things go — it’s a lot easier to accurately determine the boundaries of a lake than the boundaries of population density.</p>
<p>There will also be labeling errors, whether by humans or automated processing. If I saw an image showing there was a Magnolia tree forest in some region of China, I’m unlikely to know if that is the correct type of tree in the forest or not.</p>
<p>These errors can snowball and ultimately make the entire analysis worthless, which is why they are such a big deal. A mining company starting a drilling project for gold in a specific spot will be none too pleased when the imagery they used actually was kilometers off, or showing the wrong type of mineral.</p>
<p>Some can be mitigated by supervised classification, in which a human selects an area of land they do know a lot about so that the software can then classify other areas accordingly. But that’s an inefficient and time-consuming process that requires domain expertise — so, far from ideal.</p>
<p>There are new sorts of structures being developed to improve object retrieval from satellite imagery databases. Some involve automatically extracting objects from imagery, then encoding their descriptors into much smaller (&lt;1% of original imagery) sizes. This allows for very fast retrieval by object shapes, which seems like a nice improvement.</p>
<h4 id="image-restoration--rectification">Image Restoration &amp; Rectification</h4>
<p>Processing might start with getting true color on the images (i.e. making it look like a photograph, with blue water, green forests, etc.). You might be familiar with RGB values, (255, 255, 255 being white), which represent an 8-bit image color range. Sometimes it’s better to have false color, which just means using unnatural colors to help highlight differences between energy bands. If your goal is to see levels of vegetation, then you may prefer a false-color composite (FCC) that lets the infrared bands really pop.</p>
<p><img src="/blog/img/satellite-04.png" alt="False color satellite imagery"><em>False color imagery</em></p>
<p>After that, you might want to make sure your image is accurate, or what is called “georectification.” You can use what are called ground control points (GCP), which just means using the coordinates of known locations on a map in order to make sure the image’s coordinates map the real physical location. There’s also “orthorectification,” which removes issues of scale by accounting for different tilts and terrains — the more diverse the Earth’s surface is, the more likely there will be distortions in the image.</p>
<p>There are a few different ways images can be distorted or have irregularities, and thus different techniques to help restore them. One such technique is resampling, in which a pixel gets assigned a DN based on the DN’s of its neighbor pixels. Another is radiometric pre-processing, in which corrections are made to handle noise or irregularities generated from the sensors so that only the actual reflected radiation shows on the image.</p>
<p>Since satellites can’t control the weather (and weather modification is banned), there’s often the need for atmospheric correction, such as cloud removal. Since remote sensing is based off of how the sun reflects off objects, there can also be variations in the angle of the sun that need to be taken into account.</p>
<h4 id="image-enhancement">Image Enhancement</h4>
<p>The image enhancement phase is to improve the quality of the imagery. Some enhancements are familiar due to their use in photography, such as contrast enhancement to help highlight the differences within an image. Spatial filtering involves directly manipulating pixels for some effect. If you’ve ever played around with filters in Photoshop, or even on your phone, you get the picture. These can include image sharpening or softening, embossing, etc.</p>
<p><img src="/blog/img/satellite-imagery-fusion.png" alt="Satellite image fusion diagram by Kelly Shortridge"></p>
<p>A common technique for enhancement is image fusion, which seeks to create a single, more detailed image out of multiple images. It’s also one of the ways that the tradeoff between spatial and spectral resolution can be solved.</p>
<p>There are a few different levels at which image fusion can be performed. First is at the pixel level, comparing pixels in different images to figure out how to pack in more detail into a pixel. Second is at the feature level, comparing sizes, lengths, shapes, etc. of the same geographic area and using statistics to combine the highest-intensity features out of different images. Third is object-level, the highest-level type of image fusion, in which images are processed separately and then combined using fancy algorithms to help maximize intensity.</p>
<p>There are limitations of image fusion, such as color distortion and poor quality when dealing with high resolution images, but apparently these problems are expected to be alleviated as technology improves.</p>
<h4 id="information-extraction">Information Extraction</h4>
<p>Image classification is the largest part of information extraction, and means each pixel (or, more recently, object) in an image is categorized. This is important to distinguish different objects within an image and ultimately extract information from the image. For example, if you are measuring how quickly a city is expanding, you’ll want to be able to classify buildings, or even particular types of buildings.</p>
<p>Classification typically involves the computer (or software tool) automatically distinguishing different types of objects — like water, grass, urban areas, forests, etc. These tools aren’t perfect, not only as a function of pixel size but also that the bands of energy that objects emit may be too similar to properly distinguish them.</p>
<p>For pixels, there’s unsupervised and supervised classification — if you’re familiar with machine learning, you’ll already get what that means. The shortest difference is that unsupervised classification involves examining unknown pixels in an image, while supervised means examining known pixels.</p>
<p>Unsupervised classification will compare the unknown data with reference data as a way to figure out the category of the unknown sub-area. It’s a manual process, with the user having to choose how many clusters, or groups with similar properties, to be generated, and then match clusters with classes. It’s arguably more accurate than supervised classification, but it’s also more tedious due to its more manual nature.</p>
<p>Supervised classification will take the known data in an image, compare it with reference data and use it to extrapolate categories for the unknown parts of the image. The process is typically “training” the classification engine on sample imagery, selecting specific features, applying the right algorithm, then determining how well it worked or not.</p>
<p>Some issues with classification are similar to those in machine learning — you need reliable comparison data and strong sampling data in order for it to work, which is why unsupervised is often preferred.</p>
<p>There’s also object-oriented image classification, or “multi-resolution segmentation,” which is a non-traditional approach (meaning it’s only come into use in the past decade or so). As the name suggests, it creates objects by grouping pixels rather than classifying individual pixels. The resulting objects have different shapes and scales, and thus can be classified more flexibly using different image layers (e.g. population density, infrared, elevation, etc.). The user is still doing supervised classification using samples and fancy algorithms, but with more accuracy when dealing with objects vs. individual pixels.</p>
<p><img src="/blog/img/satellite-05.jpg" alt="Example of how object-based image analysis works."><em>Example of how object-based image analysis works.</em></p>
<p>The general rule of thumb is that object-oriented classification is best for higher spatial resolution, since objects might consist of multiple pixels, and the other methods work fine for lower resolution (in which objects are just a pixel). Of course, as spatial resolution improves, this means that object-oriented classification might be increasingly adopted in kind.</p>
<p>The type of algorithm matters, too. For example, a highly tailored algorithm might eliminate any false classifications due to shadows by incorporating into its model the position of the sun and relevant ground elevations in the area based on the image’s location and time.</p>
<p>At the forefront of research are different automation techniques to help extract features. Methods leveraging machine vision are one example, as well as methodologies that allow for more variables for classification while maintaining a high level of accuracy (90%+). It’ll likely take a few years for commercially available products to catch up to the research (along with bugs that come out when scaling to product-level use), but highly accurate automation within 5 years doesn’t seem preposterous.</p>
<p>Once features are classified, information can be extracted for its desired purpose. Which leads to the various applications of geospatial analysis.</p>
<hr>
<h2 id="a-nameapplicationsawhat-are-the-applications"><a name="applications"></a>What are the applications?</h2>
<p>There are a bunch of industries that benefit from using satellite-based imagery — particularly for anything in which physical trends over time are needed or they want to see stuff below the Earth’s surface. The number of applications is expanding as imaging capability improves, since higher resolution images provide a more granular view of what’s happening on Earth.</p>
<p>Even though purchasing multispectral imagery can be high in absolute dollar terms, relative to the cost of physical exploration, it is inexpensive. But for non-profit or applications without this high cost of physical capital on the line, the reward isn’t necessarily as high.</p>
<p>Also, assume for any of the following applications, traders can use similar information to inform their financial bets. For example, if satellite imagery suggests that the rate of construction in China is slowing down, they might short construction materials firms or commodities as a result. Of course, this has some intriguing implications for the efficient-market hypothesis, if investors have information on a company’s operations that even the company itself might not possess.</p>
<p>The government has a variety of applications for geospatial imagery, and has been leveraging it as a source of intelligence for half a century. But, I’ll just be focusing on applications within commercial industries.</p>
<h3 id="current-applications">Current Applications</h3>
<h4 id="agriculture">Agriculture</h4>
<p>It can be hard to measure agricultural trends on the ground, so satellite imagery is immensely helpful in assessing crop health and yields, environmental changes and trends pertaining to livestock. Even when planning and maintaining agricultural sites, this imagery can map irrigation and analyze soil — even showing variations in soil’s organic matter.</p>
<p><img src="/blog/img/satellite-06.jpg" alt="Imagery highlighting irrigation"><em>Imagery highlighting irrigation.</em></p>
<p>Aside from optimizing costs and boosting productivity at large agricultural companies, there’s a general global need for improved agricultural production and better utilization of resources. Having a better sense of what and where these resources are to improve their management has significant benefits on a macro scale.</p>
<h4 id="engineering--construction">Engineering &amp; Construction</h4>
<p>Along with companies in the mining and oil &amp; gas industries, engineering &amp; construction companies have high capital costs relating to physical projects. So, geospatial imagery can help these companies visualize their projects, not just for evaluating and planning construction sites, but also for maintaining them. This helps reduce construction costs and also minimize environmental impact.</p>
<p><img src="/blog/img/satellite-07.jpg" alt="Digital elevation model of a construction site"><em>Digital elevation model of a construction site.</em></p>
<p>Being able to model construction sites in 3D is crucial for planning purposes, but also ensuring ongoing safety. And for certain project types, like airstrips, dams, power plants and sewers, you need data beyond just the visual. For example, when building an airport, not only do you need to make sure the terrain is appropriate for an airstrip, but also have 3D models for flight simulation to make sure pilots aren’t going to run into recurring issues.</p>
<h4 id="environmental-monitoring">Environmental Monitoring</h4>
<p>On the “save the world,” side of things, environmental monitoring helps assess damage from natural disasters as well as help manage natural resources. Governments can use satellite imagery to help develop disaster response plans, as well as improve environmental planning and conservation.</p>
<p><img src="/blog/img/satellite-08.jpg" alt="Imagery highlighting deforestation"><em>Imagery highlighting deforestation.</em></p>
<p>Being able to see high-level trends, like deforestation, is helpful to monitor local environmental health but even more so to evaluate potential long-term impacts. After all, trees don’t grow back overnight, so excessive “forest farming” can have devastating effects on future generations’ economic wellbeing. Not to mention being a harbinger of global climate change.</p>
<h4 id="logistics-shipping--maritime">Logistics (Shipping &amp; Maritime)</h4>
<p>Logistics and shipping companies, port operators, fishers, trade organizations and governments all have an interest in geospatial imagery relating to maritime and weather patterns. On the pure logistics side, being able to track ships in transit is highly useful, as tracking systems can fail when far enough away from ports. Weather patterns and other spatial data (like terrain mapping) can also help optimize shipping routes.</p>
<p><img src="/blog/img/satellite-09.png" alt="Search for MH370 by satellites"><em>Search for MH370; odd given the number of global recon satellites that it’s still missing.</em></p>
<p>Being able to monitor trading, spot illegal fishing or piracy, and help with search and rescue missions are of particular importance from a global trade perspective. Even the “little guy” can win — local fishers and fisheries are often put out of business by illegal fishing, which is more widespread than you might think.</p>
<h4 id="mining">Mining</h4>
<p>Multispectral satellite imagery has the ability to differentiate between different types of rocks, vegetation and soil, which helps mining and geology projects in a few different ways.</p>
<p><img src="/blog/img/satellite-10.jpg" alt="Imagery optimized to show rare earth elements"><em>Imagery optimized to show rare earth elements.</em></p>
<p>First and most obviously, this imagery can help identify clays, oxides and soils for mineral mapping and exploration. This is in contrast to most humans, who would walk to the location and say, “yep, that looks like ground.” All the different energy bands will show both different types of rocks and elements as well as structural aspects of the Earth’s surface that may influence ease of mining.</p>
<p>Second, it helps plan out mining projects. Digging into the ground isn’t the only challenge; mining companies also have to worry about how to get access to the mine and what infrastructure would be required to support the project. And, they also need to estimate what sort of impact the project will have on the surrounding area from a human and environmental perspective.</p>
<h4 id="oil--gas">Oil &amp; Gas</h4>
<p>Satellite imagery can help oil and gas companies reduce risk in oil exploration as well as monitor ongoing projects. The level of detail is pretty impressive, from generally detecting areas that are most productive down to even detecting seismic lines or offshore oil seepage.</p>
<p><img src="/blog/img/satellite-11.jpg" alt="Deepwater Horizon oil spill by satellite"><em>The Deepwater Horizon spill being just a bit more than seepage.</em></p>
<p>But not only does it help find areas most likely to be rich with oil, but it also helps these companies assess the potential costs and pitfalls associated with drilling in a particular area. For example, satellite imagery shows which areas have rock formations, heavy forest coverage, unfavorable weather conditions and whether they are in more remote or developed locations.</p>
<h3 id="future-applications">Future Applications</h3>
<p>In the next section I’ll talk about some of the challenges that have hindered adoption to date, but if geospatial imagery becomes more widely available and easier to leverage for business and operational intelligence, other industries may become customers in addition to those above.</p>
<p>One potential area is physical retail. A super cool application might be looking at the surrounding area and weather patterns of store locations to see what types of goods might resonate best with local customers. For example, imagery could show the levels and types of vegetation in nearby residential areas to see if stocking more garden supplies makes sense. If imagery can be updated quickly enough, retail companies could see how many cars are at a given location in order to estimate growth or decline. They could also plan new locations based on factors like accessibility or even locations that have lots of cars parked at their competitors’ stores.</p>
<p>In that vein, real estate is another potential application area. Much like for construction projects, real estate developers can improve planning their projects by being able to optimize residential appeal — whether by accessibility, proximity to natural spaces or avoiding high-risk zones. And the same goes for city and urban planners.</p>
<p>The advertising industry could leverage different types of data towards better ad targeting. Someone like Facebook could use satellite imagery to generate a wealth of data about a user’s specific location, that they can then provide as part of their user targeting suite for their customers. This could include the example above of measuring vegetation in residential areas to advertise garden supplies, or knowing proximity to mountains and trails to advertise hiking gear or mountain bikes.</p>
<p>As I’ll discuss a bit later, there’s also the potential that space data startups generate and sell intelligence directly to end customers, which could open up an even wider set of potential applications.</p>
<hr>
<h2 id="a-nameadoptionawhats-hindering-adoption"><a name="adoption"></a>What&rsquo;s hindering adoption?</h2>
<p>There isn’t necessarily one thing hindering adoption of geospatial imagery and intelligence. It’s a combination of availability, costs, latency, quality and usability. All these issues in conjunction means there’s a barrier for many commercial enterprises to using geospatial data to their advantage.</p>
<p>Getting satellites into orbit so there is more imagery available is step one. The goal of many of these imagery companies is to have a constellation of satellites in orbit to allow for daily imaging of the whole planet. Launching these satellites into orbit is currently expensive, and ups the cost of the end imagery (which thereby reduces the potential customer set). So, a lot depends on SpaceX’s (and others’) ability to cut down on the cost of satellite launches. The recent successful Falcon 9 launch and landing will very likely pave the way for rocket reuse, which will help bring down these costs substantially.</p>
<p><img src="/blog/img/rocketlaunch.gif" alt="Cinemagraph of the American flag waving while a rocket launches"><em>Obligatory cinemagraph in the name of ‘Murica.</em></p>
<p>The delivery of imagery is historically quite slow as well. Not only do satellites capture a small part of the Earth at a time, but there’s also the issue of sending down large file sizes over transmissions speeds that are just in the hundreds of MB per second range. Assuming there’s no pre-processing before the customer receives the image, the customer still has to download the image for themselves, which takes time…and any processing work needed only adds to that time. This is starting to change, as images are increasingly available online and some images are pre-processed, saving customers from having to do the image processing themselves.</p>
<p>Of course, images will only realistically be “near real-time,” given the transmission delay. But getting down to a matter of minutes, or even hours, is an improvement over the traditional daily or longer wait times. Faster transmission speeds could help improve the speed at which images are received as well.</p>
<p>Launching a satellite into space is no cheap feat, not to mention costs of ongoing operations, resulting in imagery pricing that is quite expensive. Pricing can range from $20 to $25 per square km, and there are often minimum order sizes of 25 square km a pop (meaning $500+).</p>
<p>On the satellite design side, more development is needed in the miniaturization of components. For example, Planet Labs’ satellites are cutely described as “baguette”-size, and that’s the general trend — 172 satellites weighing 100kg (~220lbs) or less were launched in 2014. There are also sensor-related challenges, most which can’t be remediated at the source, putting more onus on the image processing part of the chain. There are multiple tradeoffs within sensors that affect quality: spectral resolution vs. signal to noise ratio (SNR), radiometric resolution vs. SNR, data size vs. spatial resolution, and spatial resolution vs. spectral resolution.</p>
<p>So, there’s a long way to go with image processing software as well, particularly as it pertains to information extraction. Better automation seems to be the path forward towards improving this software, though that isn’t particularly easy, either. It isn’t surprising that automation is perhaps the biggest area of focus among many of the startups in the field. The automation is primarily in the pre-processing (rectification and restoration phase), but also through easier integration (API all the things).</p>
<p>While I wasn’t able to find these claims specifically, after looking at a bunch of traditional GIS software, it has the GUI sophistication of Minesweeper from Windows 95. While I’m sure for users familiar with these interfaces it makes sense and works fine, I can’t help but imagine that a more intuitive and “typical user”-friendly UX might allow for more widespread adoption.</p>
<hr>
<h2 id="a-namewho-caresawho-cares"><a name="who-cares"></a>Who cares?</h2>
<p>The government has cared a lot for a long time, and I’d have to assume they’d be a little nervous about a bunch of new satellites being sent into orbit that may risk having spy satellites uncovered. But, they would also be able to benefit from innovations, particularly on the software-side, that are spurred by greater commercial adoption. Though based on how homely most government-facing software looks, maybe government analysts would disprove of UI improvements.</p>
<p><img src="/blog/img/satellite-12.jpg" alt="Satellite imagery via the CIA of Osama bin Ladin’s compound."><em>Satellite imagery via the CIA of Osama bin Ladin’s compound.</em></p>
<p>Any of the commercial industries from earlier might care, as it can help them cut costs, curtail risks and arguably even improve revenues. So, they care to the extent that better satellite imagery and analysis can help them optimize their business, but the degree to which it does may vary. I’d imagine it’s a “nice to have,” maybe even “would love to have,” but not a “necessary to have” in most of these cases.</p>
<p>As described above, there are a lot of “save the world” use cases that could legitimately help improve the environment and even potentially human rights. But generally those budgets are much thinner than for-profit industries.</p>
<p>On the darker side of things, there’s the potential for invasion of privacy. This currently pertains to sub-orbit, but high altitude aircraft (as far as we, the unknowing public, knows), but it certainly isn’t a stretch to imagine being able to detect individuals by thermal spectrum within specific buildings. Or, to watch their patterns of life via satellite — though that could more easily be done by gaining access to their phone’s GPS and location data.</p>
<p>With the <a href="https://www.washingtonpost.com/news/the-switch/wp/2015/05/22/the-house-just-passed-a-bill-about-space-mining-the-future-is-here/">recent bill passed to allow companies to retain profits from space mining activities</a>, improvements in these technologies could potentially help these companies scout asteroids and other celestial objects containing valuable elements. It might be tricky from the satellite positioning perspective, but would cut down on the exploration costs enormously if companies could make “sure bets.”</p>
<hr>
<h2 id="a-namerisksawhat-are-the-risks"><a name="risks"></a>What are the risks?</h2>
<p><img src="/blog/img/satellite-13.jpg" alt="How a satellite constellation looks"><em>How a satellite constellation looks.</em>
A lot depends on getting satellites into orbit, at least to make this a huge opportunity. The successful Falcon 9 launch and re-landing helps mitigate those risks a bit, but that happened only weeks ago. So, to get more satellites into orbit, thus increasing not only the amount of imagery, but quality of imagery, you have to hope that SpaceX really has their stuff together and in a hurry. You actually probably need to hope that more than just SpaceX does rocket reuse successfully.</p>
<p>Satellite imagery, at least as it stands today, also isn’t that big of an industry. The satellite industry as a whole is a hefty market ($200 billion), particularly because of consumer communications and entertainment. But right now the Earth Observation (EO) market, which includes the satellite imagery portion, is still quite small.</p>
<p>Specifically, the EO market size is just about $2 billion today, which doesn’t leave a lot of room for new players to make a killing. DigitalGlobe and Esri, arguably the largest satellite imagery providers, only made about $650mm and $950mm in revenue in 2014, respectively. Some of the estimates, like from Northern Sky research, put the EO market hitting $3.5 billion in 2020, and $4.5 billion by 2024.</p>
<p>An alternative is betting that even if the imagery part doesn’t grow that quickly, better software and analytics still has the opportunity for significant growth. After all, these tools would help companies get a better bang for their buck when purchasing satellite imagery. But is it a 10x better bang for the buck than it stands today? That’s up for debate, and largely depends on use case. But that’s not the sort of “sure bet” most VCs like.</p>
<p>On the other hand, if the monetization of satellite imagery isn’t via the imagery or software itself, but via the resulting data streams, then there’s arguably less risk. If you’re just selling what would essentially be business intelligence, but collected from Earth’s orbit, you’d undoubtedly find additional interested customers due to the more immediate value proposition. However, companies pursuing this would probably have to control the whole chain — satellites, imagery, processing, etc. — to have differentiated and high-quality data streams, which requires a ton of capital to pursue. So VCs would need to clutch their talismans and hope the all-in bet pays off.</p>
<hr>
<h2 id="a-namecurrent-sceneawhats-the-current-scene"><a name="current-scene"></a>What&rsquo;s the current scene?</h2>
<p>There are not too many startups specifically in the satellite-imagery arena, though there are a few more in the satellite and space category more generally (most notably SpaceX). The ones who are in what I’d call the “geospatial big data” arena are:</p>
<ul>
<li>Analyze</li>
<li>Aquila Space</li>
<li>BlackSky Global</li>
<li>CartoDB</li>
<li>Descartes Labs</li>
<li>Iceye</li>
<li>MapBox</li>
<li>Planet Labs</li>
<li>Orbital Insight</li>
<li>Skybox Imaging (acquired by Google)</li>
<li>Spire</li>
<li>TellusLabs</li>
<li>UrtheCast</li>
</ul>
<p>There are some sub-categories, like tracking weather and maritime conditions (Analyze, Spire), or mapping services (CartoDB, Mapbox). But for the most part there isn’t much overlap between the companies, other than at the highest level. You’ll see terms like “tracking,” “data streams,” and so forth, but they all self-describe quite differently.</p>
<p>The more notable VC funds that have funded some of these ventures are:</p>
<ul>
<li>Accel Partners</li>
<li>Draper Fisher Jurvetson</li>
<li>Earlybird Venture Capital</li>
<li>Felicis Ventures</li>
<li>Founders Fund</li>
<li>Foundry Group</li>
<li>Lux Capital</li>
<li>Promus Ventures</li>
<li>Razors Edge Ventures</li>
<li>Rothenberg Ventures</li>
<li>RRE Ventures</li>
</ul>
<p>There are also a few larger companies that do provide either satellite imagery, GIS software, or geospatial database management systems, including:</p>
<ul>
<li>Autodesk</li>
<li>Bentley Systems</li>
<li>DigitalEye</li>
<li>Esri</li>
<li>Exelis</li>
<li>Hexagon Geospatial</li>
<li>Teradata</li>
</ul>
<p>There are also a number of open source projects, from software to SDKs and libraries, that are released by non-profit organizations and universities. But they rarely have the same breadth of features, nor the number of capabilities, as the paid software.</p>
<hr>
<h2 id="a-nameconclusionaconclusion"><a name="conclusion"></a>Conclusion</h2>
<p><img src="/blog/img/satellite-14.jpg" alt="Satellite looking over Earth at night">
There’s a reason why I like using the term “space data” — this is really cool stuff. But, there are huge capital costs involved for a market that as of yet isn’t very big at all. Or, for companies that are improving just the software part, there’s a lot of reliance on third parties to provide the actual imagery.</p>
<p>Automation does seem like the most legitimate opportunity for a 10x improvement on what is available today, so that companies don’t need GIS experts in-house to still glean intelligence from satellite imagery. It seems like this software vertical is particularly behind in many of the infrastructure developments made in the past decade, so there’s certainly room for disruption just in that regard.</p>
<p>But, what are companies’ ongoing needs for satellite imagery? Many of the applicable industries suggest a per-project need rather than the sort of continuous need best met via SaaS. At the very least, the government is likely willing to throw some money towards better software, but relying on that revenue is unlikely to produce a blockbuster VC return.</p>
<p>The most viable proposition in my eyes is in eliminating the need for companies to have to even touch satellite imagery and give them the information they need to know, i.e. the data stream approach. It feels like a truly modern way of approaching business and operational intelligence with a large potential audience. And hedge funds would probably eat it up.</p>
<p>My main hesitation here would be in vertical-specific needs, and to a lesser extent, in pricing. My gut feeling is that, at least in early days, the data received by customers would require a heavy level of customization based on their needs, making the business almost like a software and data-enabled consultancy (which is arguably working out for Palantir). And as a result, the pricing might still be prohibitive to many customers — not to mention the initial and ongoing costs of maintaining a constellation of satellites.</p>
<p>My prediction is that many of the software-only companies will remain quite small, while those pursuing the entire chain (like Planet Labs) have a good shot at a big long-term payoff (with bigger capital requirements, of course). DigitalGlobe itself only has a $1 billion market cap, with about $100mm cash, so they can’t just gobble up the new software companies. There’s always the chance a cash-rich tech giant like IBM or Facebook decides they’re interested in the space data game, too. Or perhaps I’m wrong and space mining comes sooner rather than later, with space data crucial for any level of success.</p>
<p><img src="/blog/img/satellite-15.jpg" alt="Rendering of asteroid mining"><em>Asteroid mining — the not so distant future?</em></p>
]]></content>
        </item>
        
        <item>
            <title>WTFunding: Industrial / Manufacturing Analytics</title>
            <link>https://swagitda.com/blog/posts/wtfunding-industrial-manufacturing-analytics/</link>
            <pubDate>Tue, 13 Oct 2015 17:24:07 -0400</pubDate>
            
            <guid>https://swagitda.com/blog/posts/wtfunding-industrial-manufacturing-analytics/</guid>
            <description>WTFunding is one of my “spare time” projects to delve into tech sectors attracting VC funding that pique my curiosity. I like connecting dots between disparate things, it’s also pretty useful.
Table of Contents:  So what is &amp;ldquo;industrial / manufacturing analytics&amp;rdquo;? What are the applications? What&amp;rsquo;s hindering adoption? Who cares? What are the risks? What&amp;rsquo;s the current scene? Final thoughts   So what is “industrial / manufacturing analytics”? There doesn’t seem to be a great catch-all term for it yet, but there are a few different terms for and related to the sector I’m discussing: smart manufacturing, infrastructure analytics, manufacturing analytics, industrial analytics and, though it’s a broader term, IoT analytics.</description>
            <content type="html"><![CDATA[<p><img src="/blog/img/sparks.jpg" alt="Image of Sparks"></p>
<p><em>WTFunding is one of my “spare time” projects to delve into tech sectors attracting VC funding that pique my curiosity. I like connecting dots between disparate things, it’s also pretty useful.</em></p>
<h3 id="table-of-contents">Table of Contents:</h3>
<ol>
<li><a href="#so-what-is">So what is &ldquo;industrial / manufacturing analytics&rdquo;?</a></li>
<li><a href="#applications">What are the applications?</a></li>
<li><a href="#adoption">What&rsquo;s hindering adoption?</a></li>
<li><a href="#who-cares">Who cares?</a></li>
<li><a href="#risks">What are the risks?</a></li>
<li><a href="#current-scene">What&rsquo;s the current scene?</a></li>
<li><a href="#conclusion">Final thoughts</a></li>
</ol>
<hr>
<h2 id="a-nameso-what-isaso-what-is-industrial--manufacturing-analytics"><a name="so-what-is"></a>So what is “industrial / manufacturing analytics”?</h2>
<p>There doesn’t seem to be a great catch-all term for it yet, but there are a few different terms for and related to the sector I’m discussing: smart manufacturing, infrastructure analytics, manufacturing analytics, industrial analytics and, though it’s a broader term, IoT analytics.</p>
<p>My preference is towards “infrastructure analytics,” but when I use those terms interchangeably throughout, know I mean the same thing (and it’s also helpful to keep an eye out for that range of terms in your own reading). The one sub-sector I’ve seen broken out the most is predictive maintenance, but otherwise startups in this space use some selection of the terms above when self-describing.</p>
<p>Gartner’s definition says, “providers that help manufacturers support variable product content through the manufacturing process and improve the visibility and analysis of manufacturing performance.” Other research creates some beautiful imagery like, “removing the barrier between physical and information flows,” and, “translating the physical world into a model accessible by IT.” Or that, you know, this is all about “IoT orchestration” and “big-data-driven manufacturing.”</p>
<p>My <a href="https://www.urbandictionary.com/define.php?term=ELI5">ELI5</a> definition, that makes me want to stab my eyes out less, is, “providers that help manufacturers manufacture better, and for less money, using data from machines.” They listen to all the stuff the manufacturers’ machines have to say, figure out what part of the stuff shows that things are going wrong or things could be done better, and show the manufacturers pretty pictures and clear advice on how to fix machines or make the machines do things better.</p>
<p>Industry people refer to this data as generated “on the edge,” which just means at the sensor or machine level. As I’ll talk about farther down, there are lots of machines that provide data for solutions to leverage. To visualize the different types of machines, here are some pictures along with what they are:</p>
<table>
<thead>
<tr>
<th style="text-align:center"><img src="/blog/img/industrial-01.png" alt="machine vision systems"></th>
<th style="text-align:center"><img src="/blog/img/industrial-02.png" alt="RFID/barcode scanners"></th>
<th style="text-align:center"><img src="/blog/img/industrial-03.png" alt="welding machines"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Machine vision systems</td>
<td style="text-align:center">RFID/barcode scanners</td>
<td style="text-align:center">Welding machines</td>
</tr>
</tbody>
</table>
<p>*</p>
<table>
<thead>
<tr>
<th style="text-align:center"><img src="/blog/img/industrial-04.jpeg" alt="PLCs"></th>
<th style="text-align:center"><img src="/blog/img/industrial-05.jpeg" alt="Robots"></th>
<th style="text-align:center"><img src="/blog/img/industrial-06.jpg" alt="Plasma cutters"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">PLCs</td>
<td style="text-align:center">Robots</td>
<td style="text-align:center">Plasma cutters</td>
</tr>
</tbody>
</table>
<p>Oh, and don’t forget “factory-floor software” like MES (manufacturing execution system) and ERP (enterprise resource planning).</p>
<p>Let’s walk through an example manufacturing process to get a sense of what data is generated; for example, putting together the chassis (the car’s frame) on an automobile.</p>
<img style="float: right; max-width:50%; padding: 5px" src="/blog/img/industrial-07.png">
<p>Robots will put together the chassis by welding different parts together. Then, the robots will typically put in the engine, transmission and suspension. Building the rest of the body operates in much the same way — putting in parts and welding them together (some human interaction is still involved).</p>
<p>Tracking temperature abnormalities can help cut down on defects and, once enough data is analyzed, potentially speed up production time as well. But, what is arguably even more valuable is tracking the robots themselves. The data generated from their operations allows better forecasting of production time, maximizing uptime, performing predictive maintenance, spotting quality issues and generating insights into how processes might be improved.</p>
<p>So, this software mines information across the manufacturing floor from all those machines, sensors, devices, etc. But how is that done?</p>
<p>The data is typically either collected via a gateway device that’s located on the factory floor or via a local node that transfers the collected data to a central gateway device. Then, the data needs to be made usable, or “transformed” (as is true for traditional data analytics), so there needs to be cleansing, normalizing and organizing.</p>
<p>This transformed data is then analyzed, either on-prem or cloud-based, using industry-specific data models. These include those tailored towards discrete, batch and process manufacturing. Since VC’s ❤ KPI’s, some of the common ones from these analytics are performance, uptime, quality, cycle time, OEE (overall equipment effectiveness), along with reasons for defects and downtimes.</p>
<p>The results of this analysis and the KPI’s are then shown to the customer that is (ideally) highly understandable and conducive to informing decision-making and action. Which brings us to what sorts of decisions and actions can be informed by this analysis.</p>
<hr>
<h2 id="a-nameapplicationsawhat-are-the-applications"><a name="applications"></a>What are the applications?</h2>
<p>I’m not the first to suggest that there’s a big resource allocation problem across a number of industries due to prioritization of “collect all the things” (the NSA approach) rather than finding the “why” first and narrowing down what needs to be collected from there. Perhaps as a result of the jubilant headlines on how revolutionary big data is, it often seems that data collection serves primarily as a signal for organizations to show that they’re doing something about big data.</p>
<p>It’s a similar conundrum to my company’s industry, information security, in which most organizations care foremost about showing they care about security, and vendors are happy to be providing something that sounds really cool but doesn’t solve anything real. But companies showing that they care about security ends up being expensive not just financially, but also time, resource and user experience-wise (something my company is attempting to change) — and the same is largely true for companies attempting to “do something” with the big data they’ve now spent a lot of money to collect and store.</p>
<p>Going into researching this smart manufacturing area, I assumed there would exist roughly the same narrative. Tons of data is given off by sensors, which is being collected and now companies are searching for applications to show that their investments into collecting and storing all this data have not been fruitless.</p>
<p>However, to a large extent this is not the case. As I’ll get to in the next section, a big problem is actually in the data collection itself. And companies have some pretty crystalline use-cases in mind that would materially — perhaps even disruptively — enhance their operations, and the challenge is how to get the right data to do so in a non-cost-prohibitive manner.</p>
<p>At the highest level, the primary application is “optimizing operations.” For a tech startup, that can mean reducing downtime, maximizing processing speed, and so forth. For a manufacturing floor, the implications are enormous. I had the pleasure of seeing a manufacturing floor up-close when I was very young, and it’s one of the clearest of my early memories. But for those who may not have before, here are a few pictures as a guide (in addition to all the lovely machines from earlier):</p>
<table>
<thead>
<tr>
<th style="text-align:center"><img src="/blog/img/industrial-08.png" alt="PLCs"></th>
<th style="text-align:center"><img src="/blog/img/industrial-09.png" alt="Robots"></th>
<th style="text-align:center"><img src="/blog/img/industrial-10.png" alt="Plasma cutters"></th>
</tr>
</thead>
</table>
<p>As you can see, there are lots of machines, and different types of them. This means that there’s a lot of opportunity for malfunctioning, misbehaving, slowing down, speeding up and so forth. Identifying and fixing these issues costs money, and before they’re fixed, there are also potential losses from downtime and quality issues as well.</p>
<p>As a result, there is, in fact, a long list of potential applications of being able to analyze data from these machines, including, but not limited to (and with some overlap):</p>
<ul>
<li>Improving quality</li>
<li>Identifying issues in real-time</li>
<li>Minimizing operational variability</li>
<li>Reducing waste of raw materials</li>
<li>Reducing unplanned downtime</li>
<li>Reducing scrap rates</li>
<li>Identifying opportunities for process improvements</li>
<li>Increasing production speed</li>
<li>Predicting supply needs</li>
<li>Synthesizing visibility of operations across plants</li>
<li>Reducing compliance costs</li>
<li>Improving auditability</li>
</ul>
<p>The impact of these applications is huge in an industry with slim margins. Being able to better predict, streamline and “smooth out” operations results in significant savings at scale.</p>
<hr>
<h2 id="a-nameadoptionawhats-hindering-adoption"><a name="adoption"></a>What&rsquo;s hindering adoption?</h2>
<p><img src="/blog/img/industrial-11.jpeg" alt="Image of a man watching a car fly through a screen"><em>Maybe one day humans can just think of a bunch of dots and have it turn into a sportscar that shoots out of random screens, disrupting manufacturing entirely.</em></p>
<p>As foreshadowed above, one of the largest barriers to adoption of these technologies is in data collection. Though it can be treated as a distinct part of the big data chain, the “data cleanup” aspect is extremely challenging, as it is difficult to combine and centralize sensor data emanating from disparate machines and devices.</p>
<p>And, that’s not to mention the sheer amount of data causes some hefty storage requirements, and the pace at which data is generated means that solutions have to be able to keep up. There are also challenges like needing to make sure sensors and communications hardware can survive potentially rough environments, but it seems like people know more or less how to accomplish that.</p>
<p>The most-repeated challenge in realizing the “Fourth Industrial Revolution” is that there needs to be a standard data architecture across vendors. Lacking a global government to decree all vendors must adhere to a certain data architecture or perish, most of the people who cite this challenge have suggestions to ameliorate it along the lines of ¯\_(ツ)_/¯.</p>
<p>As a result, current capabilities are pretty okay at helping solve basic problems but not great at solving tricky, complex and big problems. Most of the time, being able to solve those hard problems comes with a big price tag and requires a lot of human input.</p>
<p>When you visualize the manufacturing floor, it becomes super easy to understand why this is the state of the world. Ignoring the fact that there are lots of different kinds of machines involved in any particular manufacturing process, individual machines themselves will have different types of sensors recording tons of data points on different things involved in its operation. Considering then that an individual machine will have thousands of data points in a single operation, an entire manufacturing floor will have millions — so just imagine the sheer scale of how much data is generated from ongoing operations.</p>
<p align="center"><img src="/blog/img/industrial-12.jpg"/ alt="Spock sobbing mathematically"></p>
<p>It’s a frustrating realization, and if you’re like me, then your mind begins to furtively think of how to fix it. Starting at a small scale, theoretically vendors could ensure that all sensor data generated from a single machine adhered to the same data architecture. Let’s be bold and optimistic and even say that a vendor could ensure that all their different machines adhered to the same data architecture, so if you had a floor with only their equipment, you could collect and combine all this juicy data with ease.</p>
<p>But in the real world, making sure all the sensor data has the same architecture is decidedly not trivial. What incentives does the vendor have to implement this extra process when designing their products? Do customers really care so much about the data that they’re willing to pay a premium for machines with a common data architecture?</p>
<p>This results in first-mover disadvantages both on the vendor and customer side. For vendors, they don’t want to be the dopes that were first to put all this effort into having this gorgeous, seamlessly combinable spring of sensor data from their machines that customers end up not buying because it’s more expensive than that of their Tower of Babel-esque competitors. For customers, they don’t want to be the dopes that were first to pay a premium for this theoretically awesome tech that turns out not to generate such actionable insights after all, or worse, isn’t as easily collected and synthesized as promised. Not to mention the customers will still need to buy or develop the analytics that leverage this data.</p>
<p>It’s going to take a risky bet on one side or the other. My personal bet is on the customer side, which will (hopefully) put pressure on vendors. Why? Because the customers (the manufacturers) may be able to sell some of the insights they gain to their own customers as part of a value-added offering. For example, they can differentiate from their competition by suggesting data-supported ways for their customers to improve the quality of their products or speed at which their products can get to market. While helping bottom-line by reducing their downtime, use of raw materials, etc. is all well and good, there’s nothing like a boost to the top-line to really cultivate interest.</p>
<p>This still doesn’t solve the problem of how standardization will actually be accomplished. It doesn’t do a ton of good if each vendor standardizes within itself but makes it even harder for manufacturers to combine data from machines across different vendors. Very few vendors will make all of the machines and devices manufacturers need to run their operations, so it is realistic to assume that broader standardization is essential.</p>
<p>There is some evidence of the government looking to help facilitate standardization, but I, for one, have little faith in how quickly any initiative might be accomplished in that manner. Realistically, the GE’s and other titan industrial firms will throw a lot of money at figuring this out and monetize it as something like IoTAaaS, but those will likely be in areas away from the manufacturing part of “industrial” and instead in use-cases where their machine or part can serve as a strong sole-source of data (e.g. sensors on jet engines to help optimize fuel efficiency).</p>
<p>What I’d love to see is an approach similar to what the founders of Flatiron Health performed in its earliest days. The lore is they traveled around the country speaking with cancer specialists and treatment centers to better understand the challenges they faced, what sort of data was relevant, how it was currently being shared, etc. From gathering those insights first-hand, they developed a solution that has been very sincerely described as “fighting cancer with big data.” There are meaty enough sub-sectors within the industrial space that I strongly believe something similar could be accomplished and help leap over the standardization hurdle to the phase where meaningful insights can be generated with ease.</p>
<p>But, I’m only half joking when I think that maybe this whole problem will be solved if Google open sources whatever software it develops as it builds its self-driving cars and/or AI-driven robot and drone army, <em>ahem</em>, logistics network, then executes its Order 66 to have the global leaders it’s funded and seeded mandate Google’s way as the standard.</p>
<hr>
<h2 id="a-namewho-caresawho-cares"><a name="who-cares"></a>Who cares?</h2>
<p>Luckily from a “who cares” perspective, the field of potential customers is actually enormous. Manufacturing spans behemoth industries, including pharmaceuticals, transportation, aerospace and defense, oil and gas, electronics and chemicals. And within each industry is a chunky supply chain full of many vendors, from raw materials to packaging. Being the go-to operational analytics solution provider for any one of these industries alone would very likely result in a hefty amount of revenue.</p>
<p>From the VC perspective, it’s pretty obvious why there’d be interest in investing in this area, particularly if you’re an investor for a corporate VC arm who happens to be a part of the manufacturing or industrial supply chain. It also heavily touches on IoT, which is an area still attracting a considerable amount of interest, but has crossover appeal to enterprise software investors who are familiar with more general analytics and business intelligence companies.</p>
<hr>
<h2 id="a-namerisksawhat-are-the-risks"><a name="risks"></a>What are the risks?</h2>
<p><img src="/blog/img/more-sparks.jpg" alt="more sparks"><em>Our lizard brains are programmed to like pictures of sparks.</em></p>
<p>Being early to the party is no fun, and even though the “Fourth Industrial Revolution” has had its cue music on for a while, it’s still extremely early and somewhat speculative. Nanotechnology is an example industry that’s had an excessively long drumroll, to the point that now legitimately exciting advances are met by many with indifference. And many of the early “plays” in it never took off or lived up to the hype.</p>
<p>To generalize, VC’s like taking “safe risks.” What this means is that they typically like to fund new companies in markets somewhere between totally unproven and super saturated. So where does the infrastructure analytics market fall?</p>
<p>On the one hand, it’s sort of a “no duh” that companies want this operational intelligence, for all the potential applications described earlier. On the other, will these companies buy these sorts of from startups? And can these startups prove that their solutions provide disruptive-level value early enough? Those are questions that are true for a lot of enterprise solution providers, but I feel are magnified given the higher-stakes of the physical realm.</p>
<p>There’s also the uncertainty of standardization. Can companies actually extract the value they promise in a world with that many disparate types of data? There’s potentially the question of whether their value is eroded a bit if standardization happens, and thus it becomes substantially easier to use existing data science methods to garner operational intelligence, but I personally think that’s a lesser risk (and definitely cart before horse).</p>
<p>As in my Flatiron Health analogy earlier, a startup that cataloged all the different machines and things involved in the processes of a specific sub-sector in industrial analytics might have the potential to do exceptionally well. That level of granularity may be necessary to truly crack the code on how to most efficiently and meaningfully collect, combine and analyze this data. But it would involve a longer time horizon and doing Paul Graham’s “things that don’t scale,” both which add execution risk that might be insurmountable in an investors’ eyes.</p>
<hr>
<h2 id="a-namecurrent-sceneawhats-the-current-scene"><a name="current-scene"></a>What&rsquo;s the current scene?</h2>
<p>There are a handful of startups that are already operating in this arena (and I have no doubt I’m missing some and quite a few are in stealth). They self-describe in roughly four buckets:</p>
<ul>
<li><strong>Manufacturing Analytics/Intelligence</strong> — Hai, Northwest Analytics, OFS Systems, Optimal+, SightMachine</li>
<li><strong>Predictive Maintenance</strong> — Augury, DecisionIQ, Maintenel, Predikto</li>
<li><strong>Industrial Analytics</strong> — Seeq</li>
<li><strong>IoT Analytics</strong> — Decisyon, mnubo</li>
</ul>
<p>Some of the more notable VC funds that have invested in these companies include:</p>
<ul>
<li>First Round</li>
<li>Formation 8</li>
<li>IA Ventures</li>
<li>Lerer Hippeau</li>
<li>Madrona Venture Group</li>
<li>O’Reilly Alpha Tech</li>
<li>Orfin Ventures</li>
<li>…and KKR</li>
</ul>
<p>There are a number of industrial conglomerates that have created data science wings, realizing the potential of the space, such as the list below. They tend to self describe as “industrial analytics” or “process analytics.”</p>
<ul>
<li>ABB</li>
<li>Dionex</li>
<li>GE (Predix)</li>
<li>Genpact</li>
<li>Honeywell</li>
<li>Siemens</li>
</ul>
<p>Along with analytics and consulting incumbents spreading out into industry-specific solutions, including the list below. In contrast to the industrial conglomerates above, they come up if you search for “manufacturing analytics.”</p>
<ul>
<li>Ayasdi</li>
<li>CSC</li>
<li>Datawatch</li>
<li>Deloitte</li>
<li>Oracle</li>
<li>ParStream</li>
<li>Predixion</li>
<li>Tableau</li>
<li>TIBCO</li>
<li>Wipro</li>
</ul>
<hr>
<h2 id="a-nameconclusionafinal-thoughts"><a name="conclusion"></a>Final Thoughts</h2>
<p>I think the issue with the industrial analytics sector isn’t level of VC interest, but instead that the pipeline of companies is really small; so even if investors wanted to take a gamble, there hasn’t been much opportunity to do so. After all, the “right” founders will have come from working in the industrial sector, and if they have the level of data science expertise required to create a novel startup in this space, I’d suspect they’re really well paid (especially if in oil and gas). More typical SV data science founder-types may be apprehensive of tackling this problem space as well given the domain expertise required, which seems to be tricky to acquire without access to industrial equipment.</p>
<p>My prediction is we’ll see some of the incumbent analytics players creating industry-specific modules at first along with the big industrial companies creating analytics solutions. And from there, I hope (and I suspect VC’s hope as well) there are defectors that take the risk to create a pure-play company that takes the big leap forward rather than incremental shuffles.</p>
]]></content>
        </item>
        
    </channel>
</rss>
